{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f55485-2c52-452f-88eb-da6bebedc5ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/m20180848/.local/lib/python3.12/site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /home/m20180848/.local/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/anaconda/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/anaconda/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/anaconda/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc70e70-3388-48a1-9891-528c5230273f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m20180848/.conda/envs/pytorch_p310/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from inference import *\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Model imports\n",
    "from model import SmartContractTransformer\n",
    "\n",
    "# Optional but useful imports\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # for progress bars\n",
    "import logging\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import re\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33baac5-1132-4019-9a19-9de07ce9f3fe",
   "metadata": {},
   "source": [
    "# 0. AUX Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abf829a4-aab2-4666-9d54-1f5ed0de035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def parse_solidity_to_ast(code: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parse Solidity code into a simplified AST structure\n",
    "    \"\"\"\n",
    "    def extract_contract_info(code: str) -> Dict[str, Any]:\n",
    "        # Extract contract name\n",
    "        contract_match = re.search(r'contract\\s+(\\w+)', code)\n",
    "        contract_name = contract_match.group(1) if contract_match else \"Unknown\"\n",
    "        \n",
    "        # Extract functions\n",
    "        functions = []\n",
    "        function_pattern = r'function\\s+(\\w+)\\s*\\(([^)]*)\\)\\s*(?:public|private|internal|external)?\\s*(?:view|pure|payable)?\\s*(?:returns\\s*\\(([^)]*)\\))?\\s*{'\n",
    "        for match in re.finditer(function_pattern, code):\n",
    "            func_name = match.group(1)\n",
    "            params = match.group(2).split(',') if match.group(2) else []\n",
    "            returns = match.group(3).split(',') if match.group(3) else []\n",
    "            \n",
    "            functions.append({\n",
    "                'name': func_name,\n",
    "                'parameters': [p.strip() for p in params],\n",
    "                'returns': [r.strip() for r in returns]\n",
    "            })\n",
    "        \n",
    "        # Extract state variables\n",
    "        variables = []\n",
    "        var_pattern = r'(?:uint|address|string|bool|mapping)\\s+(?:\\w+)\\s+(\\w+)'\n",
    "        for match in re.finditer(var_pattern, code):\n",
    "            variables.append(match.group(1))\n",
    "        \n",
    "        return {\n",
    "            'type': 'Contract',\n",
    "            'name': contract_name,\n",
    "            'functions': functions,\n",
    "            'variables': variables\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        # Clean the code\n",
    "        code = re.sub(r'//.*?\\n|/\\*.*?\\*/', '', code)  # Remove comments\n",
    "        code = re.sub(r'\\s+', ' ', code)  # Normalize whitespace\n",
    "        \n",
    "        # Parse the code\n",
    "        ast = extract_contract_info(code)\n",
    "        return ast\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing code: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def prepare_code2vec_input(ast: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Convert AST to codeBert input format\n",
    "    \"\"\"\n",
    "    paths = []\n",
    "    \n",
    "    def extract_paths(node: Dict[str, Any], current_path: List[str] = None):\n",
    "        if current_path is None:\n",
    "            current_path = []\n",
    "            \n",
    "        # Add current node to path\n",
    "        if 'name' in node:\n",
    "            current_path.append(node['name'])\n",
    "            \n",
    "        # Process functions\n",
    "        if 'functions' in node:\n",
    "            for func in node['functions']:\n",
    "                func_path = current_path + [func['name']]\n",
    "                paths.append(' '.join(func_path))\n",
    "                \n",
    "                # Add parameter paths\n",
    "                for param in func['parameters']:\n",
    "                    param_path = func_path + [param]\n",
    "                    paths.append(' '.join(param_path))\n",
    "                \n",
    "                # Add return paths\n",
    "                for ret in func['returns']:\n",
    "                    ret_path = func_path + [ret]\n",
    "                    paths.append(' '.join(ret_path))\n",
    "        \n",
    "        # Process variables\n",
    "        if 'variables' in node:\n",
    "            for var in node['variables']:\n",
    "                var_path = current_path + [var]\n",
    "                paths.append(' '.join(var_path))\n",
    "    \n",
    "    extract_paths(ast)\n",
    "    return paths\n",
    "\n",
    "class SmartContractVulnerabilityDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        max_length: int = 1024,\n",
    "        split: str = \"train\",\n",
    "        vulnerability_types: List[str] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_path: Path to the CSV file containing the dataset\n",
    "            tokenizer: Tokenizer for encoding the source code\n",
    "            max_length: Maximum sequence length\n",
    "            split: \"train\" or \"val\" to specify which split to load\n",
    "            vulnerability_types: List of vulnerability types to consider\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.split = split\n",
    "        self.vulnerability_types = vulnerability_types or [\n",
    "            'ARTHM', 'DOS', 'LE', 'RENT', 'TimeM', 'TimeO', 'Tx-Origin', 'UE'\n",
    "        ]\n",
    "        \n",
    "        # Load the dataset\n",
    "        self.data = self._load_dataset(data_path)\n",
    "        \n",
    "    def _load_dataset(self, data_path: str) -> List[Dict]:\n",
    "        \"\"\"Load and preprocess the dataset from CSV\"\"\"\n",
    "        dataset = []\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(data_path)\n",
    "        \n",
    "        # Split into train/val if needed\n",
    "        if self.split == \"train\":\n",
    "            df = df.sample(frac=0.8, random_state=42)\n",
    "        else:\n",
    "            df = df.sample(frac=0.2, random_state=42)\n",
    "        \n",
    "        # Process each contract\n",
    "        for _, row in df.iterrows():\n",
    "            try:\n",
    "                source_code = row['source_code']\n",
    "                contract_name = row['contract_name']\n",
    "                \n",
    "                # Parse AST and get paths\n",
    "                ast = parse_solidity_to_ast(source_code)\n",
    "                ast_paths = prepare_code2vec_input(ast) if ast else []\n",
    "                ast_path_text = ' '.join(ast_paths)\n",
    "                \n",
    "                # Split source code into lines\n",
    "                lines = source_code.split('\\n')\n",
    "                \n",
    "                # Create token-to-line mapping\n",
    "                token_to_line = []\n",
    "                current_line = 0\n",
    "                \n",
    "                # Tokenize each line separately to maintain mapping\n",
    "                for line in lines:\n",
    "                    line_tokens = self.tokenizer.encode(line, add_special_tokens=False)\n",
    "                    token_to_line.extend([current_line] * len(line_tokens))\n",
    "                    current_line += 1\n",
    "                \n",
    "                # Add special tokens\n",
    "                token_to_line = [0] + token_to_line + [0]  # [CLS] and [SEP] tokens\n",
    "                \n",
    "                # Truncate if too long\n",
    "                if len(token_to_line) > self.max_length:\n",
    "                    token_to_line = token_to_line[:self.max_length]\n",
    "                \n",
    "                # Pad if too short\n",
    "                if len(token_to_line) < self.max_length:\n",
    "                    token_to_line.extend([0] * (self.max_length - len(token_to_line)))\n",
    "                \n",
    "                # Create multi-label line labels for each vulnerability type\n",
    "                line_labels = self._create_multi_label_line_labels(source_code, row)\n",
    "                \n",
    "                # Create contract-level vulnerability labels\n",
    "                contract_labels = self._create_contract_vulnerability_labels(row)\n",
    "                \n",
    "                # Tokenize the source code\n",
    "                encoding = self.tokenizer(\n",
    "                    source_code,\n",
    "                    max_length=self.max_length,\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                # Tokenize AST paths\n",
    "                ast_encoding = self.tokenizer(\n",
    "                    ast_path_text,\n",
    "                    max_length=self.max_length,\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                # Convert line labels to tensor and ensure consistent shape\n",
    "                vuln_tensor = torch.zeros((len(self.vulnerability_types), self.max_length), dtype=torch.long)\n",
    "                for i, labels in enumerate(line_labels):\n",
    "                    if len(labels) > self.max_length:\n",
    "                        labels = labels[:self.max_length]\n",
    "                    vuln_tensor[i, :len(labels)] = torch.tensor(labels, dtype=torch.long)\n",
    "                \n",
    "                # Convert contract labels to tensor\n",
    "                contract_vuln_tensor = torch.tensor(contract_labels, dtype=torch.long)\n",
    "                \n",
    "                # Convert token_to_line to tensor\n",
    "                token_to_line_tensor = torch.tensor(token_to_line, dtype=torch.long)\n",
    "                \n",
    "                # Ensure attention masks are boolean\n",
    "                attention_mask = encoding['attention_mask'].squeeze(0).bool()\n",
    "                ast_attention_mask = ast_encoding['attention_mask'].squeeze(0).bool()\n",
    "                \n",
    "                # Ensure input_ids are the right length\n",
    "                input_ids = encoding['input_ids'].squeeze(0)\n",
    "                ast_input_ids = ast_encoding['input_ids'].squeeze(0)\n",
    "                \n",
    "                if len(input_ids) > self.max_length:\n",
    "                    input_ids = input_ids[:self.max_length]\n",
    "                if len(ast_input_ids) > self.max_length:\n",
    "                    ast_input_ids = ast_input_ids[:self.max_length]\n",
    "                \n",
    "                # Pad if necessary\n",
    "                if len(input_ids) < self.max_length:\n",
    "                    input_ids = torch.nn.functional.pad(input_ids, (0, self.max_length - len(input_ids)))\n",
    "                if len(ast_input_ids) < self.max_length:\n",
    "                    ast_input_ids = torch.nn.functional.pad(ast_input_ids, (0, self.max_length - len(ast_input_ids)))\n",
    "                \n",
    "                dataset.append({\n",
    "                    'input_ids': input_ids,\n",
    "                    'attention_mask': attention_mask,\n",
    "                    'ast_input_ids': ast_input_ids,\n",
    "                    'ast_attention_mask': ast_attention_mask,\n",
    "                    'vulnerable_lines': vuln_tensor,\n",
    "                    'contract_vulnerabilities': contract_vuln_tensor,\n",
    "                    'token_to_line': token_to_line_tensor,\n",
    "                    'source_code': source_code,\n",
    "                    'contract_name': contract_name\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing contract {contract_name}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    def _create_contract_vulnerability_labels(self, row: pd.Series) -> List[int]:\n",
    "        \"\"\"Create contract-level vulnerability labels\"\"\"\n",
    "        contract_labels = []\n",
    "        for vuln_type in self.vulnerability_types:\n",
    "            # Check if contract has this vulnerability type\n",
    "            vuln_lines = row[f'{vuln_type}_lines']\n",
    "            if isinstance(vuln_lines, str):\n",
    "                try:\n",
    "                    vuln_lines = eval(vuln_lines)\n",
    "                except:\n",
    "                    vuln_lines = [vuln_lines]\n",
    "            \n",
    "            # Contract is vulnerable if it has any vulnerable lines\n",
    "            has_vulnerability = len(vuln_lines) > 0\n",
    "            contract_labels.append(1 if has_vulnerability else 0)\n",
    "        \n",
    "        return contract_labels\n",
    "    \n",
    "    def _create_multi_label_line_labels(self, source_code: str, row: pd.Series) -> List[List[int]]:\n",
    "        \"\"\"Create multi-label line labels for each vulnerability type\"\"\"\n",
    "        total_lines = len(source_code.split('\\n'))\n",
    "        line_labels = {vuln_type: [0] * total_lines for vuln_type in self.vulnerability_types}\n",
    "        \n",
    "        # Process each vulnerability type\n",
    "        for vuln_type in self.vulnerability_types:\n",
    "            vuln_lines = row[f'{vuln_type}_lines']\n",
    "            if isinstance(vuln_lines, str):\n",
    "                try:\n",
    "                    vuln_lines = eval(vuln_lines)\n",
    "                except:\n",
    "                    vuln_lines = [vuln_lines]\n",
    "            \n",
    "            # Process each vulnerable line/snippet\n",
    "            for line_or_snippet in vuln_lines:\n",
    "                if isinstance(line_or_snippet, int):\n",
    "                    # If it's a line number, mark that line\n",
    "                    if 0 <= line_or_snippet < total_lines:\n",
    "                        line_labels[vuln_type][line_or_snippet] = 1\n",
    "                else:\n",
    "                    # If it's a code snippet, find matching lines\n",
    "                    source_lines = source_code.split('\\n')\n",
    "                    for i, line in enumerate(source_lines):\n",
    "                        # Clean both the line and snippet for comparison\n",
    "                        clean_line = re.sub(r'\\s+', ' ', line.strip())\n",
    "                        clean_snippet = re.sub(r'\\s+', ' ', str(line_or_snippet).strip())\n",
    "                        if clean_snippet in clean_line:\n",
    "                            line_labels[vuln_type][i] = 1\n",
    "        \n",
    "        # Convert to list format\n",
    "        return [line_labels[vuln_type] for vuln_type in self.vulnerability_types]\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict:\n",
    "        return self.data[idx]\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle variable length inputs\n",
    "    \"\"\"\n",
    "    # Get the maximum length in this batch for each type of tensor\n",
    "    max_input_len = max(item['input_ids'].size(0) for item in batch)\n",
    "    \n",
    "    # Pad all tensors to their respective maximum lengths\n",
    "    padded_batch = {\n",
    "        'input_ids': torch.stack([\n",
    "            torch.nn.functional.pad(item['input_ids'], (0, max_input_len - item['input_ids'].size(0)))\n",
    "            for item in batch\n",
    "        ]),\n",
    "        'attention_mask': torch.stack([\n",
    "            torch.nn.functional.pad(item['attention_mask'], (0, max_input_len - item['attention_mask'].size(0)))\n",
    "            for item in batch\n",
    "        ]),\n",
    "        'ast_input_ids': torch.stack([item['ast_input_ids'] for item in batch]),\n",
    "        'ast_attention_mask': torch.stack([item['ast_attention_mask'] for item in batch]),\n",
    "        'vulnerable_lines': torch.stack([item['vulnerable_lines'] for item in batch]),\n",
    "        'contract_vulnerabilities': torch.stack([item['contract_vulnerabilities'] for item in batch]),\n",
    "        'token_to_line': torch.stack([item['token_to_line'] for item in batch]),\n",
    "        'source_code': [item['source_code'] for item in batch],\n",
    "        'contract_name': [item['contract_name'] for item in batch]\n",
    "    }\n",
    "    \n",
    "    return padded_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d92266a-e5c0-47bc-9d78-5b478d9c4d34",
   "metadata": {},
   "source": [
    "# 0 Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24465794-d11b-40f6-97a3-a41d831968de",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"contract_sources_with_vulnerabilities_2048_token_size.csv\"\n",
    "MODEL_PATH = \"checkpoints_v5_2048_output/best_model_augmented_gan_epoch_91.pt\"\n",
    "TOKENIZER_NAME = \"microsoft/codebert-base\"\n",
    "VULNERABILITY_TYPES = ['ARTHM', 'DOS', 'LE', 'RENT', 'TimeM', 'TimeO', 'Tx-Origin', 'UE']\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "MODEL_LINE_CODE_VULNERABILITY_THRESHOLD = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06292e0-265d-4a18-bf13-872a78843c25",
   "metadata": {},
   "source": [
    "# 1 Load Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "335b0e10-576d-42f7-830a-ce60b449e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(\n",
    "    data_path: str,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    batch_size: int = 8,\n",
    "    max_length: int = 1024,\n",
    "    num_workers: int = 4,\n",
    "    vulnerability_types: List[str] = None\n",
    ") -> Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
    "    \n",
    "    val_dataset = SmartContractVulnerabilityDataset(\n",
    "        data_path=data_path,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=max_length,\n",
    "        split=\"val\",\n",
    "        vulnerability_types=vulnerability_types\n",
    "    )\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "    \n",
    "    return  dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bea9d5c-1371-4d31-9b39-d84ae55e03f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m20180848/.conda/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME)\n",
    "\n",
    "val_dataloader = create_dataloaders(\n",
    "    data_path=DATA_PATH,\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=8,\n",
    "    max_length=1024,\n",
    "    vulnerability_types=VULNERABILITY_TYPES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b43db63-0e15-4e48-b9ec-399aa5c68e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataloader.dataset.data[0]['vulnerable_lines'][7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea56f5f-154f-4ffe-9360-3a227bada3e1",
   "metadata": {},
   "source": [
    "## 1.1. ML performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c1ac1b8-f16f-46da-a408-9b08360d6b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(true_labels: np.ndarray, pred_labels: np.ndarray) -> float:\n",
    "    \"\"\"Calculate precision for vulnerability detection.\"\"\"\n",
    "    if np.sum(pred_labels) == 0:\n",
    "        return 0.0\n",
    "    return np.sum((true_labels == 1) & (pred_labels == 1)) / np.sum(pred_labels)\n",
    "\n",
    "def calculate_recall(true_labels: np.ndarray, pred_labels: np.ndarray) -> float:\n",
    "    \"\"\"Calculate recall for vulnerability detection.\"\"\"\n",
    "    if np.sum(true_labels) == 0:\n",
    "        return 0.0\n",
    "    return np.sum((true_labels == 1) & (pred_labels == 1)) / np.sum(true_labels)\n",
    "\n",
    "def calculate_f1_score(precision: float, recall: float) -> float:\n",
    "    \"\"\"Calculate F1 score.\"\"\"\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def calculate_line_accuracy(true_line_vulns: np.ndarray, pred_line_vulns: Dict) -> float:\n",
    "    \"\"\"Calculate line-level accuracy (simplified).\"\"\"\n",
    "    try:\n",
    "        # Convert predicted line vulnerabilities to array format\n",
    "        pred_array = np.zeros_like(true_line_vulns)\n",
    "        for line_num, line_vulns in pred_line_vulns.items():\n",
    "            if line_num < pred_array.shape[0]:\n",
    "                for vuln_idx, is_vuln in enumerate(line_vulns.values()):\n",
    "                    if vuln_idx < pred_array.shape[1]:\n",
    "                        pred_array[line_num, vuln_idx] = 1 if is_vuln else 0\n",
    "        \n",
    "        return np.mean(pred_array == true_line_vulns)\n",
    "    except:\n",
    "        return 0.\n",
    "\n",
    "def get_vulnerability_details(analyzer, true_vulns: np.ndarray, pred_vulns: np.ndarray, \n",
    "                            probabilities: List[float]) -> Dict[str, Any]:\n",
    "    \"\"\"Get detailed vulnerability analysis.\"\"\"\n",
    "    details = {}\n",
    "    for i, vuln_type in enumerate(analyzer.vulnerability_types):\n",
    "        details[vuln_type] = {\n",
    "            'true_positive': bool(true_vulns[i] == 1 and pred_vulns[i] == 1),\n",
    "            'false_positive': bool(true_vulns[i] == 0 and pred_vulns[i] == 1),\n",
    "            'false_negative': bool(true_vulns[i] == 1 and pred_vulns[i] == 0),\n",
    "            'true_negative': bool(true_vulns[i] == 0 and pred_vulns[i] == 0),\n",
    "            'probability': probabilities[i],\n",
    "            'true_label': int(true_vulns[i]),\n",
    "            'predicted_label': int(pred_vulns[i])\n",
    "        }\n",
    "    return details\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c7b4c3-0222-4a37-82e9-f96522cc4d2d",
   "metadata": {},
   "source": [
    "## 1.2 Load Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d960e29-408a-48a5-86b7-88d2b4fa1837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m20180848/.conda/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_path=MODEL_PATH\n",
    "device = DEVICE\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3952e977-40fd-49fa-9fa4-1355f445fdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m20180848/.conda/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Initialized line feature extractor layer 1 with small random weights\n",
      "DEBUG: Initialized line feature extractor layer 3 with small random weights\n",
      "DEBUG: Initialized custom line feature extractor with small weights\n"
     ]
    }
   ],
   "source": [
    "model = SmartContractTransformer(\n",
    "        d_model=768,\n",
    "        nhead=8,\n",
    "        num_encoder_layers=6,\n",
    "        num_decoder_layers=6,\n",
    "        dim_feedforward=2048,\n",
    "        dropout=0.1,\n",
    "        max_length=1024,\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        num_vulnerability_types=8,\n",
    "        use_gan=True \n",
    "    )\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10970a5c-cfbb-4825-9269-35d3548b74e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from checkpoints_v5_2048_output/best_model_augmented_gan_epoch_91.pt\n",
      "Training epoch: 91\n",
      "Best validation loss: 0.83826167229563\n",
      "Training config: GAN=True\n"
     ]
    }
   ],
   "source": [
    "if 'model_state_dict' in checkpoint:\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "    print(f\"Training epoch: {checkpoint.get('epoch', 'Unknown')}\")\n",
    "    print(f\"Best validation loss: {checkpoint.get('val_loss', 'Unknown')}\")\n",
    "    print(f\"Training config: GAN={checkpoint.get('use_gan', 'Unknown')}\")\n",
    "else:\n",
    "    # Direct state dict\n",
    "    model.load_state_dict(checkpoint)\n",
    "    print(f\"Model loaded from {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "065c78e5-1607-40b8-9bf4-52de0ee19987",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "    \n",
    "vulnerability_types = [\n",
    "    'ARTHM', 'DOS', 'LE', 'RENT', 'TimeM', 'TimeO', 'Tx-Origin', 'UE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83e4baff-1b79-47bd-b80a-89d9d490f9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/**\n",
      " * Source Code first verified at https://etherscan.io on Tuesday, December 18, 2018\n",
      " (UTC) */\n",
      "\n",
      "pragma solidity ^0.4.23;\n",
      "\n",
      "library SafeMath {\n",
      "\n",
      "  /**\n",
      "  * @dev Multiplies two numbers, throws on overflow.\n",
      "  */\n",
      "  function mul(uint256 a, uint256 b) internal pure returns (uint256 c) {\n",
      "\n",
      "    if (a == 0) {\n",
      "      return 0;\n",
      "    }\n",
      "\n",
      "    c = a * b;\n",
      "    assert(c / a == b);\n",
      "    return c;\n",
      "  }\n",
      "\n",
      "  /**\n",
      "  * @dev Integer division of two numbers, truncating the quotient.\n",
      "  */\n",
      "  function div(uint256 a, uint256 b) internal pure returns (uint256) {\n",
      "\n",
      "    return a / b;\n",
      "  }\n",
      "\n",
      "  /**\n",
      "  * @dev Subtracts two numbers, throws on overflow (i.e. if subtrahend is greater than minuend).\n",
      "  */\n",
      "  function sub(uint256 a, uint256 b) internal pure returns (uint256) {\n",
      "    assert(b <= a);\n",
      "    return a - b;\n",
      "  }\n",
      "\n",
      "  /**\n",
      "  * @dev Adds two numbers, throws on overflow.\n",
      "  */\n",
      "  function add(uint256 a, uint256 b) internal pure returns (uint256 c) {\n",
      "    c = a + b;\n",
      "    assert(c >= a);\n",
      "    return c;\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "contract ERC20Basic {\n",
      "    \n",
      "  function totalSupply() public view returns (uint256);\n",
      "  function balanceOf(address who) public view returns (uint256);\n",
      "  function transfer(address to, uint256 value) public returns (bool);\n",
      "  event Transfer(address indexed from, address indexed to, uint256 value);\n",
      "  \n",
      "}\n",
      "\n",
      "contract ERC20 is ERC20Basic {\n",
      "    \n",
      "  function allowance(address owner, address spender)\n",
      "    public view returns (uint256);\n",
      "\n",
      "  function transferFrom(address from, address to, uint256 value)\n",
      "    public returns (bool);\n",
      "\n",
      "  function approve(address spender, uint256 value) public returns (bool);\n",
      "  event Approval(\n",
      "    address indexed owner,\n",
      "    address indexed spender,\n",
      "    uint256 value\n",
      "  );\n",
      "}\n",
      "\n",
      "contract DetailedERC20 is ERC20 {\n",
      "  string public name;\n",
      "  string public symbol;\n",
      "  uint8 public decimals;\n",
      "\n",
      "  constructor(string _name, string _symbol, uint8 _decimals) public {\n",
      "    name = _name;\n",
      "    symbol = _symbol;\n",
      "    decimals = _decimals;\n",
      "  }\n",
      "}\n",
      "\n",
      "/**\n",
      " * @title 实现ERC20基本合约的接口 \n",
      " * @dev 基本的StandardToken，不包含allowances.\n",
      " */\n",
      "contract BasicToken is ERC20Basic {\n",
      "  using SafeMath for uint256;\n",
      "\n",
      "  mapping(address => uint256) balances;\n",
      "\n",
      "  uint256 totalSupply_;\n",
      "  \n",
      "  function totalSupply() public view returns (uint256) {\n",
      "    return totalSupply_;\n",
      "  }\n",
      "\n",
      "  function transfer(address _to, uint256 _value) public returns (bool) {\n",
      "    require(_to != address(0));\n",
      "    require(_value <= balances[msg.sender]);\n",
      "    balances[msg.sender] = balances[msg.sender].sub(_value);\n",
      "    balances[_to] = balances[_to].add(_value);\n",
      "    emit Transfer(msg.sender, _to, _value);\n",
      "    return true;\n",
      "  }\n",
      "\n",
      "  function balanceOf(address _owner) public view returns (uint256) {\n",
      "    return balances[_owner];\n",
      "  }\n",
      "\n",
      "}\n",
      "\n",
      "contract StandardToken is ERC20, BasicToken {\n",
      "  mapping (address => mapping (address => uint256)) internal allowed;\n",
      "\n",
      "  /**\n",
      "   * @dev 从一个地址向另外一个地址转token\n",
      "   * @param _from 转账的from地址\n",
      "   * @param _to address 转账的to地址\n",
      "   * @param _value uint256 转账token数量\n",
      "   */\n",
      "  function transferFrom(\n",
      "    address _from,\n",
      "    address _to,\n",
      "    uint256 _value\n",
      "  )\n",
      "    public\n",
      "    returns (bool)\n",
      "  {\n",
      "    // 做合法性检查\n",
      "    require(_to != address(0));\n",
      "    require(_value <= balances[_from]);\n",
      "    require(_value <= allowed[_from][msg.sender]);\n",
      "    balances[_from] = balances[_from].sub(_value);\n",
      "    balances[_to] = balances[_to].add(_value);\n",
      "    allowed[_from][msg.sender] = allowed[_from][msg.sender].sub(_value);\n",
      "    emit Transfer(_from, _to, _value);\n",
      "    return true;\n",
      "  }\n",
      "\n",
      "  function approve(address _spender, uint256 _value) public returns (bool) {\n",
      "    allowed[msg.sender][_spender] = _value;\n",
      "    emit Approval(msg.sender, _spender, _value);\n",
      "    return true;\n",
      "  }\n",
      "\n",
      "  function allowance(\n",
      "    address _owner,\n",
      "    address _spender\n",
      "   )\n",
      "    public\n",
      "    view\n",
      "    returns (uint256)\n",
      "  {\n",
      "    return allowed[_owner][_spender];\n",
      "  }\n",
      "\n",
      "}\n",
      "\n",
      "contract BurnableToken is BasicToken {\n",
      "\n",
      "  event Burn(address indexed burner, uint256 value);\n",
      "\n",
      "}\n",
      "\n",
      "contract MintableToken is StandardToken {\n",
      "  event Mint(address indexed to, uint256 amount);\n",
      "  event MintFinished();\n",
      "\n",
      "  bool public mintingFinished = false;\n",
      "\n",
      "\n",
      "  modifier canMint() {\n",
      "    require(!mintingFinished);\n",
      "    _;\n",
      "  }\n",
      "\n",
      "\n",
      "  /**\n",
      "   * @dev Function to stop minting new tokens.\n",
      "   * @return True if the operation was successful.\n",
      "   */\n",
      "  function finishMinting() public  canMint returns (bool) {\n",
      "    mintingFinished = true;\n",
      "    emit MintFinished();\n",
      "    return true;\n",
      "  }\n",
      "}\n",
      "\n",
      "contract StandardBurnableToken is BurnableToken, StandardToken,MintableToken {\n",
      "\n",
      "\n",
      "  \n",
      "}\n",
      "\n",
      "contract valuehometoken is StandardBurnableToken {\n",
      "    string public name = 'value home token';\n",
      "    string public symbol = 'VHT';\n",
      "    uint8 public decimals = 8;\n",
      "    uint256 public INITIAL_SUPPLY = 50000000000000000; \n",
      "    \n",
      "  constructor() public {\n",
      "    totalSupply_ = INITIAL_SUPPLY;\n",
      "    balances[msg.sender] = INITIAL_SUPPLY;\n",
      "  }\n",
      "\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(val_dataloader.dataset.data[5]['source_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e1f6b03-4942-49bd-a54a-65e109c1b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_code = val_dataloader.dataset.data[5]['source_code']\n",
    "ast = parse_solidity_to_ast(contract_code)\n",
    "ast_paths = prepare_code2vec_input(ast) if ast else []\n",
    "ast_path_text = ' '.join(ast_paths)\n",
    "\n",
    "# Tokenize inputs\n",
    "contract_encoding = tokenizer(\n",
    "    contract_code,\n",
    "    max_length=1024,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "ast_encoding = tokenizer(\n",
    "    ast_path_text,\n",
    "    max_length=1024,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11c677cc-df34-4c73-a891-addfc77b7c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: input_ids shape: torch.Size([1, 1024])\n",
      "DEBUG: actual sequence length: 1024\n"
     ]
    }
   ],
   "source": [
    "input_ids = contract_encoding['input_ids'].to(device)\n",
    "attention_mask = contract_encoding['attention_mask'].to(device)\n",
    "ast_input_ids = ast_encoding['input_ids'].to(device)\n",
    "ast_attention_mask = ast_encoding['attention_mask'].to(device)\n",
    "\n",
    "print(f\"DEBUG: input_ids shape: {input_ids.shape}\")\n",
    "print(f\"DEBUG: actual sequence length: {input_ids.shape[1]}\")\n",
    "\n",
    "# Create proper token-to-line mapping that matches the actual tokenization\n",
    "lines = contract_code.split('\\n')\n",
    "token_to_line = []\n",
    "current_line = 0\n",
    "\n",
    "# Add [CLS] token mapping (line 0)\n",
    "token_to_line.append(0)\n",
    "\n",
    "for line in lines:\n",
    "    line_tokens = tokenizer.encode(line, add_special_tokens=False)\n",
    "    # Map all tokens in this line to the same line number\n",
    "    token_to_line.extend([current_line] * len(line_tokens))\n",
    "    current_line += 1\n",
    "\n",
    "# Add [SEP] token mapping (line 0)\n",
    "token_to_line.append(0)\n",
    "\n",
    "# FIXED: Ensure the mapping matches the actual tokenized length\n",
    "actual_seq_len = input_ids.shape[1]  # Get the actual sequence length from input_ids\n",
    "if len(token_to_line) > actual_seq_len:\n",
    "    token_to_line = token_to_line[:actual_seq_len]\n",
    "elif len(token_to_line) < actual_seq_len:\n",
    "    token_to_line.extend([0] * (actual_seq_len - len(token_to_line)))\n",
    "\n",
    "token_to_line = torch.tensor(token_to_line, dtype=torch.long).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1782adde-6ce8-4f27-9d5a-c844c0cd83f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 18 is vulnerable:\n",
      "  ARTHM: 0.1058\n",
      "Line 43 is vulnerable:\n",
      "  ARTHM: 0.3970\n",
      "Line 44 is vulnerable:\n",
      "  ARTHM: 0.1128\n",
      "Line 66 is vulnerable:\n",
      "  TimeM: 0.1090\n",
      "Line 67 is vulnerable:\n",
      "  ARTHM: 0.1214\n",
      "Line 92 is vulnerable:\n",
      "  TimeM: 0.1630\n",
      "Line 122 is vulnerable:\n",
      "Line 123 is vulnerable:\n",
      "Line 124 is vulnerable:\n",
      "Line 125 is vulnerable:\n",
      "Line 126 is vulnerable:\n",
      "Line 127 is vulnerable:\n",
      "Line 128 is vulnerable:\n",
      "Line 129 is vulnerable:\n",
      "Line 130 is vulnerable:\n",
      "Line 131 is vulnerable:\n",
      "Line 132 is vulnerable:\n",
      "Line 133 is vulnerable:\n",
      "Line 134 is vulnerable:\n",
      "Line 135 is vulnerable:\n",
      "Line 136 is vulnerable:\n",
      "Line 137 is vulnerable:\n",
      "Line 138 is vulnerable:\n",
      "Line 139 is vulnerable:\n",
      "Line 140 is vulnerable:\n",
      "Line 141 is vulnerable:\n",
      "Line 142 is vulnerable:\n",
      "Line 143 is vulnerable:\n",
      "Line 144 is vulnerable:\n",
      "Line 145 is vulnerable:\n",
      "Line 146 is vulnerable:\n",
      "Line 147 is vulnerable:\n",
      "Line 148 is vulnerable:\n",
      "Line 149 is vulnerable:\n",
      "Line 150 is vulnerable:\n",
      "Line 151 is vulnerable:\n",
      "Line 152 is vulnerable:\n",
      "Line 153 is vulnerable:\n",
      "Line 154 is vulnerable:\n",
      "Line 155 is vulnerable:\n",
      "Line 156 is vulnerable:\n",
      "Line 157 is vulnerable:\n",
      "Line 158 is vulnerable:\n",
      "Line 159 is vulnerable:\n",
      "Line 160 is vulnerable:\n",
      "Line 161 is vulnerable:\n",
      "Line 162 is vulnerable:\n",
      "Line 163 is vulnerable:\n",
      "Line 164 is vulnerable:\n",
      "Line 165 is vulnerable:\n",
      "Line 166 is vulnerable:\n",
      "Line 167 is vulnerable:\n",
      "Line 168 is vulnerable:\n",
      "Line 169 is vulnerable:\n",
      "Line 170 is vulnerable:\n",
      "Line 171 is vulnerable:\n",
      "Line 172 is vulnerable:\n",
      "Line 173 is vulnerable:\n",
      "Line 174 is vulnerable:\n",
      "Line 175 is vulnerable:\n",
      "Line 176 is vulnerable:\n",
      "Line 177 is vulnerable:\n",
      "Line 178 is vulnerable:\n",
      "Line 179 is vulnerable:\n",
      "Line 180 is vulnerable:\n",
      "Line 181 is vulnerable:\n",
      "Line 182 is vulnerable:\n",
      "Line 183 is vulnerable:\n",
      "Line 184 is vulnerable:\n",
      "Line 185 is vulnerable:\n",
      "Line 186 is vulnerable:\n",
      "Line 187 is vulnerable:\n",
      "Line 188 is vulnerable:\n",
      "Line 189 is vulnerable:\n",
      "Line 190 is vulnerable:\n",
      "Line 191 is vulnerable:\n",
      "Line 192 is vulnerable:\n",
      "Line 193 is vulnerable:\n",
      "Line 194 is vulnerable:\n",
      "Line 195 is vulnerable:\n",
      "Line 196 is vulnerable:\n",
      "Line 197 is vulnerable:\n",
      "Line 198 is vulnerable:\n",
      "Line 199 is vulnerable:\n",
      "Line 200 is vulnerable:\n",
      "Line 201 is vulnerable:\n",
      "Line 202 is vulnerable:\n",
      "Line 203 is vulnerable:\n",
      "Line 204 is vulnerable:\n",
      "Line 205 is vulnerable:\n",
      "Line 206 is vulnerable:\n",
      "Line 207 is vulnerable:\n",
      "Line 208 is vulnerable:\n",
      "Line 209 is vulnerable:\n",
      "Line 210 is vulnerable:\n",
      "Line 211 is vulnerable:\n",
      "Line 212 is vulnerable:\n",
      "Line 213 is vulnerable:\n",
      "Line 214 is vulnerable:\n",
      "Line 215 is vulnerable:\n",
      "Line 216 is vulnerable:\n",
      "Line 217 is vulnerable:\n",
      "Line 218 is vulnerable:\n",
      "Line 219 is vulnerable:\n",
      "Line 220 is vulnerable:\n",
      "Line 221 is vulnerable:\n",
      "Line 222 is vulnerable:\n",
      "Line 223 is vulnerable:\n",
      "Line 224 is vulnerable:\n",
      "Line 225 is vulnerable:\n",
      "Line 226 is vulnerable:\n",
      "Line 227 is vulnerable:\n",
      "Line 228 is vulnerable:\n",
      "Line 229 is vulnerable:\n",
      "Line 230 is vulnerable:\n",
      "Line 231 is vulnerable:\n",
      "Line 232 is vulnerable:\n",
      "Line 233 is vulnerable:\n",
      "Line 234 is vulnerable:\n",
      "Line 235 is vulnerable:\n",
      "Line 236 is vulnerable:\n",
      "Line 237 is vulnerable:\n",
      "Line 238 is vulnerable:\n",
      "Line 239 is vulnerable:\n",
      "Line 240 is vulnerable:\n",
      "Line 241 is vulnerable:\n",
      "Line 242 is vulnerable:\n",
      "Line 243 is vulnerable:\n",
      "Line 244 is vulnerable:\n",
      "Line 245 is vulnerable:\n",
      "Line 246 is vulnerable:\n",
      "Line 247 is vulnerable:\n",
      "Line 248 is vulnerable:\n",
      "Line 249 is vulnerable:\n",
      "Line 250 is vulnerable:\n",
      "Line 251 is vulnerable:\n",
      "Line 252 is vulnerable:\n",
      "Line 253 is vulnerable:\n",
      "Line 254 is vulnerable:\n",
      "Line 255 is vulnerable:\n",
      "Line 256 is vulnerable:\n",
      "Line 257 is vulnerable:\n",
      "Line 258 is vulnerable:\n",
      "Line 259 is vulnerable:\n",
      "Line 260 is vulnerable:\n",
      "Line 261 is vulnerable:\n",
      "Line 262 is vulnerable:\n",
      "Line 263 is vulnerable:\n",
      "Line 264 is vulnerable:\n",
      "Line 265 is vulnerable:\n",
      "Line 266 is vulnerable:\n",
      "Line 267 is vulnerable:\n",
      "Line 268 is vulnerable:\n",
      "Line 269 is vulnerable:\n",
      "Line 270 is vulnerable:\n",
      "Line 271 is vulnerable:\n",
      "Line 272 is vulnerable:\n",
      "Line 273 is vulnerable:\n",
      "Line 274 is vulnerable:\n",
      "Line 275 is vulnerable:\n",
      "Line 276 is vulnerable:\n",
      "Line 277 is vulnerable:\n",
      "Line 278 is vulnerable:\n",
      "Line 279 is vulnerable:\n",
      "Line 280 is vulnerable:\n",
      "Line 281 is vulnerable:\n",
      "Line 282 is vulnerable:\n",
      "Line 283 is vulnerable:\n",
      "Line 284 is vulnerable:\n",
      "Line 285 is vulnerable:\n",
      "Line 286 is vulnerable:\n",
      "Line 287 is vulnerable:\n",
      "Line 288 is vulnerable:\n",
      "Line 289 is vulnerable:\n",
      "Line 290 is vulnerable:\n",
      "Line 291 is vulnerable:\n",
      "Line 292 is vulnerable:\n",
      "Line 293 is vulnerable:\n",
      "Line 294 is vulnerable:\n",
      "Line 295 is vulnerable:\n",
      "Line 296 is vulnerable:\n",
      "Line 297 is vulnerable:\n",
      "Line 298 is vulnerable:\n",
      "Line 299 is vulnerable:\n",
      "Line 300 is vulnerable:\n",
      "Line 301 is vulnerable:\n",
      "Line 302 is vulnerable:\n",
      "Line 303 is vulnerable:\n",
      "Line 304 is vulnerable:\n",
      "Line 305 is vulnerable:\n",
      "Line 306 is vulnerable:\n",
      "Line 307 is vulnerable:\n",
      "Line 308 is vulnerable:\n",
      "Line 309 is vulnerable:\n",
      "Line 310 is vulnerable:\n",
      "Line 311 is vulnerable:\n",
      "Line 312 is vulnerable:\n",
      "Line 313 is vulnerable:\n",
      "Line 314 is vulnerable:\n",
      "Line 315 is vulnerable:\n",
      "Line 316 is vulnerable:\n",
      "Line 317 is vulnerable:\n",
      "Line 318 is vulnerable:\n",
      "Line 319 is vulnerable:\n",
      "Line 320 is vulnerable:\n",
      "Line 321 is vulnerable:\n",
      "Line 322 is vulnerable:\n",
      "Line 323 is vulnerable:\n",
      "Line 324 is vulnerable:\n",
      "Line 325 is vulnerable:\n",
      "Line 326 is vulnerable:\n",
      "Line 327 is vulnerable:\n",
      "Line 328 is vulnerable:\n",
      "Line 329 is vulnerable:\n",
      "Line 330 is vulnerable:\n",
      "Line 331 is vulnerable:\n",
      "Line 332 is vulnerable:\n",
      "Line 333 is vulnerable:\n",
      "Line 334 is vulnerable:\n",
      "Line 335 is vulnerable:\n",
      "Line 336 is vulnerable:\n",
      "Line 337 is vulnerable:\n",
      "Line 338 is vulnerable:\n",
      "Line 339 is vulnerable:\n",
      "Line 340 is vulnerable:\n",
      "Line 341 is vulnerable:\n",
      "Line 342 is vulnerable:\n",
      "Line 343 is vulnerable:\n",
      "Line 344 is vulnerable:\n",
      "Line 345 is vulnerable:\n",
      "Line 346 is vulnerable:\n",
      "Line 347 is vulnerable:\n",
      "Line 348 is vulnerable:\n",
      "Line 349 is vulnerable:\n",
      "Line 350 is vulnerable:\n",
      "Line 351 is vulnerable:\n",
      "Line 352 is vulnerable:\n",
      "Line 353 is vulnerable:\n",
      "Line 354 is vulnerable:\n",
      "Line 355 is vulnerable:\n",
      "Line 356 is vulnerable:\n",
      "Line 357 is vulnerable:\n",
      "Line 358 is vulnerable:\n",
      "Line 359 is vulnerable:\n",
      "Line 360 is vulnerable:\n",
      "Line 361 is vulnerable:\n",
      "Line 362 is vulnerable:\n",
      "Line 363 is vulnerable:\n",
      "Line 364 is vulnerable:\n",
      "Line 365 is vulnerable:\n",
      "Line 366 is vulnerable:\n",
      "Line 367 is vulnerable:\n",
      "Line 368 is vulnerable:\n",
      "Line 369 is vulnerable:\n",
      "Line 370 is vulnerable:\n",
      "Line 371 is vulnerable:\n",
      "Line 372 is vulnerable:\n",
      "Line 373 is vulnerable:\n",
      "Line 374 is vulnerable:\n",
      "Line 375 is vulnerable:\n",
      "Line 376 is vulnerable:\n",
      "Line 377 is vulnerable:\n",
      "Line 378 is vulnerable:\n",
      "Line 379 is vulnerable:\n",
      "Line 380 is vulnerable:\n",
      "Line 381 is vulnerable:\n",
      "Line 382 is vulnerable:\n",
      "Line 383 is vulnerable:\n",
      "Line 384 is vulnerable:\n",
      "Line 385 is vulnerable:\n",
      "Line 386 is vulnerable:\n",
      "Line 387 is vulnerable:\n",
      "Line 388 is vulnerable:\n",
      "Line 389 is vulnerable:\n",
      "Line 390 is vulnerable:\n",
      "Line 391 is vulnerable:\n",
      "Line 392 is vulnerable:\n",
      "Line 393 is vulnerable:\n",
      "Line 394 is vulnerable:\n",
      "Line 395 is vulnerable:\n",
      "Line 396 is vulnerable:\n",
      "Line 397 is vulnerable:\n",
      "Line 398 is vulnerable:\n",
      "Line 399 is vulnerable:\n",
      "Line 400 is vulnerable:\n",
      "Line 401 is vulnerable:\n",
      "Line 402 is vulnerable:\n",
      "Line 403 is vulnerable:\n",
      "Line 404 is vulnerable:\n",
      "Line 405 is vulnerable:\n",
      "Line 406 is vulnerable:\n",
      "Line 407 is vulnerable:\n",
      "Line 408 is vulnerable:\n",
      "Line 409 is vulnerable:\n",
      "Line 410 is vulnerable:\n",
      "Line 411 is vulnerable:\n",
      "Line 412 is vulnerable:\n",
      "Line 413 is vulnerable:\n",
      "Line 414 is vulnerable:\n",
      "Line 415 is vulnerable:\n",
      "Line 416 is vulnerable:\n",
      "Line 417 is vulnerable:\n",
      "Line 418 is vulnerable:\n",
      "Line 419 is vulnerable:\n",
      "Line 420 is vulnerable:\n",
      "Line 421 is vulnerable:\n",
      "Line 422 is vulnerable:\n",
      "Line 423 is vulnerable:\n",
      "Line 424 is vulnerable:\n",
      "Line 425 is vulnerable:\n",
      "Line 426 is vulnerable:\n",
      "Line 427 is vulnerable:\n",
      "Line 428 is vulnerable:\n",
      "Line 429 is vulnerable:\n",
      "Line 430 is vulnerable:\n",
      "Line 431 is vulnerable:\n",
      "Line 432 is vulnerable:\n",
      "Line 433 is vulnerable:\n",
      "Line 434 is vulnerable:\n",
      "Line 435 is vulnerable:\n",
      "Line 436 is vulnerable:\n",
      "Line 437 is vulnerable:\n",
      "Line 438 is vulnerable:\n",
      "Line 439 is vulnerable:\n",
      "Line 440 is vulnerable:\n",
      "Line 441 is vulnerable:\n",
      "Line 442 is vulnerable:\n",
      "Line 443 is vulnerable:\n",
      "Line 444 is vulnerable:\n",
      "Line 445 is vulnerable:\n",
      "Line 446 is vulnerable:\n",
      "Line 447 is vulnerable:\n",
      "Line 448 is vulnerable:\n",
      "Line 449 is vulnerable:\n",
      "Line 450 is vulnerable:\n",
      "Line 451 is vulnerable:\n",
      "Line 452 is vulnerable:\n",
      "Line 453 is vulnerable:\n",
      "Line 454 is vulnerable:\n",
      "Line 455 is vulnerable:\n",
      "Line 456 is vulnerable:\n",
      "Line 457 is vulnerable:\n",
      "Line 458 is vulnerable:\n",
      "Line 459 is vulnerable:\n",
      "Line 460 is vulnerable:\n",
      "Line 461 is vulnerable:\n",
      "Line 462 is vulnerable:\n",
      "Line 463 is vulnerable:\n",
      "Line 464 is vulnerable:\n",
      "Line 465 is vulnerable:\n",
      "Line 466 is vulnerable:\n",
      "Line 467 is vulnerable:\n",
      "Line 468 is vulnerable:\n",
      "Line 469 is vulnerable:\n",
      "Line 470 is vulnerable:\n",
      "Line 471 is vulnerable:\n",
      "Line 472 is vulnerable:\n",
      "Line 473 is vulnerable:\n",
      "Line 474 is vulnerable:\n",
      "Line 475 is vulnerable:\n",
      "Line 476 is vulnerable:\n",
      "Line 477 is vulnerable:\n",
      "Line 478 is vulnerable:\n",
      "Line 479 is vulnerable:\n",
      "Line 480 is vulnerable:\n",
      "Line 481 is vulnerable:\n",
      "Line 482 is vulnerable:\n",
      "Line 483 is vulnerable:\n",
      "Line 484 is vulnerable:\n",
      "Line 485 is vulnerable:\n",
      "Line 486 is vulnerable:\n",
      "Line 487 is vulnerable:\n",
      "Line 488 is vulnerable:\n",
      "Line 489 is vulnerable:\n",
      "Line 490 is vulnerable:\n",
      "Line 491 is vulnerable:\n",
      "Line 492 is vulnerable:\n",
      "Line 493 is vulnerable:\n",
      "Line 494 is vulnerable:\n",
      "Line 495 is vulnerable:\n",
      "Line 496 is vulnerable:\n",
      "Line 497 is vulnerable:\n",
      "Line 498 is vulnerable:\n",
      "Line 499 is vulnerable:\n",
      "Line 500 is vulnerable:\n",
      "Line 501 is vulnerable:\n",
      "Line 502 is vulnerable:\n",
      "Line 503 is vulnerable:\n",
      "Line 504 is vulnerable:\n",
      "Line 505 is vulnerable:\n",
      "Line 506 is vulnerable:\n",
      "Line 507 is vulnerable:\n",
      "Line 508 is vulnerable:\n",
      "Line 509 is vulnerable:\n",
      "Line 510 is vulnerable:\n",
      "Line 511 is vulnerable:\n",
      "Line 512 is vulnerable:\n",
      "Line 513 is vulnerable:\n",
      "Line 514 is vulnerable:\n",
      "Line 515 is vulnerable:\n",
      "Line 516 is vulnerable:\n",
      "Line 517 is vulnerable:\n",
      "Line 518 is vulnerable:\n",
      "Line 519 is vulnerable:\n",
      "Line 520 is vulnerable:\n",
      "Line 521 is vulnerable:\n",
      "Line 522 is vulnerable:\n",
      "Line 523 is vulnerable:\n",
      "Line 524 is vulnerable:\n",
      "Line 525 is vulnerable:\n",
      "Line 526 is vulnerable:\n",
      "Line 527 is vulnerable:\n",
      "Line 528 is vulnerable:\n",
      "Line 529 is vulnerable:\n",
      "Line 530 is vulnerable:\n",
      "Line 531 is vulnerable:\n",
      "Line 532 is vulnerable:\n",
      "Line 533 is vulnerable:\n",
      "Line 534 is vulnerable:\n",
      "Line 535 is vulnerable:\n",
      "Line 536 is vulnerable:\n",
      "Line 537 is vulnerable:\n",
      "Line 538 is vulnerable:\n",
      "Line 539 is vulnerable:\n",
      "Line 540 is vulnerable:\n",
      "Line 541 is vulnerable:\n",
      "Line 542 is vulnerable:\n",
      "Line 543 is vulnerable:\n",
      "Line 544 is vulnerable:\n",
      "Line 545 is vulnerable:\n",
      "Line 546 is vulnerable:\n",
      "Line 547 is vulnerable:\n",
      "Line 548 is vulnerable:\n",
      "Line 549 is vulnerable:\n",
      "Line 550 is vulnerable:\n",
      "Line 551 is vulnerable:\n",
      "Line 552 is vulnerable:\n",
      "Line 553 is vulnerable:\n",
      "Line 554 is vulnerable:\n",
      "Line 555 is vulnerable:\n",
      "Line 556 is vulnerable:\n",
      "Line 557 is vulnerable:\n",
      "Line 558 is vulnerable:\n",
      "Line 559 is vulnerable:\n",
      "Line 560 is vulnerable:\n",
      "Line 561 is vulnerable:\n",
      "Line 562 is vulnerable:\n",
      "Line 563 is vulnerable:\n",
      "Line 564 is vulnerable:\n",
      "Line 565 is vulnerable:\n",
      "Line 566 is vulnerable:\n",
      "Line 567 is vulnerable:\n",
      "Line 568 is vulnerable:\n",
      "Line 569 is vulnerable:\n",
      "Line 570 is vulnerable:\n",
      "Line 571 is vulnerable:\n",
      "Line 572 is vulnerable:\n",
      "Line 573 is vulnerable:\n",
      "Line 574 is vulnerable:\n",
      "Line 575 is vulnerable:\n",
      "Line 576 is vulnerable:\n",
      "Line 577 is vulnerable:\n",
      "Line 578 is vulnerable:\n",
      "Line 579 is vulnerable:\n",
      "Line 580 is vulnerable:\n",
      "Line 581 is vulnerable:\n",
      "Line 582 is vulnerable:\n",
      "Line 583 is vulnerable:\n",
      "Line 584 is vulnerable:\n",
      "Line 585 is vulnerable:\n",
      "Line 586 is vulnerable:\n",
      "Line 587 is vulnerable:\n",
      "Line 588 is vulnerable:\n",
      "Line 589 is vulnerable:\n",
      "Line 590 is vulnerable:\n",
      "Line 591 is vulnerable:\n",
      "Line 592 is vulnerable:\n",
      "Line 593 is vulnerable:\n",
      "Line 594 is vulnerable:\n",
      "Line 595 is vulnerable:\n",
      "Line 596 is vulnerable:\n",
      "Line 597 is vulnerable:\n",
      "Line 598 is vulnerable:\n",
      "Line 599 is vulnerable:\n",
      "Line 600 is vulnerable:\n",
      "Line 601 is vulnerable:\n",
      "Line 602 is vulnerable:\n",
      "Line 603 is vulnerable:\n",
      "Line 604 is vulnerable:\n",
      "Line 605 is vulnerable:\n",
      "Line 606 is vulnerable:\n",
      "Line 607 is vulnerable:\n",
      "Line 608 is vulnerable:\n",
      "Line 609 is vulnerable:\n",
      "Line 610 is vulnerable:\n",
      "Line 611 is vulnerable:\n",
      "Line 612 is vulnerable:\n",
      "Line 613 is vulnerable:\n",
      "Line 614 is vulnerable:\n",
      "Line 615 is vulnerable:\n",
      "Line 616 is vulnerable:\n",
      "Line 617 is vulnerable:\n",
      "Line 618 is vulnerable:\n",
      "Line 619 is vulnerable:\n",
      "Line 620 is vulnerable:\n",
      "Line 621 is vulnerable:\n",
      "Line 622 is vulnerable:\n",
      "Line 623 is vulnerable:\n",
      "Line 624 is vulnerable:\n",
      "Line 625 is vulnerable:\n",
      "Line 626 is vulnerable:\n",
      "Line 627 is vulnerable:\n",
      "Line 628 is vulnerable:\n",
      "Line 629 is vulnerable:\n",
      "Line 630 is vulnerable:\n",
      "Line 631 is vulnerable:\n",
      "Line 632 is vulnerable:\n",
      "Line 633 is vulnerable:\n",
      "Line 634 is vulnerable:\n",
      "Line 635 is vulnerable:\n",
      "Line 636 is vulnerable:\n",
      "Line 637 is vulnerable:\n",
      "Line 638 is vulnerable:\n",
      "Line 639 is vulnerable:\n",
      "Line 640 is vulnerable:\n",
      "Line 641 is vulnerable:\n",
      "Line 642 is vulnerable:\n",
      "Line 643 is vulnerable:\n",
      "Line 644 is vulnerable:\n",
      "Line 645 is vulnerable:\n",
      "Line 646 is vulnerable:\n",
      "Line 647 is vulnerable:\n",
      "Line 648 is vulnerable:\n",
      "Line 649 is vulnerable:\n",
      "Line 650 is vulnerable:\n",
      "Line 651 is vulnerable:\n",
      "Line 652 is vulnerable:\n",
      "Line 653 is vulnerable:\n",
      "Line 654 is vulnerable:\n",
      "Line 655 is vulnerable:\n",
      "Line 656 is vulnerable:\n",
      "Line 657 is vulnerable:\n",
      "Line 658 is vulnerable:\n",
      "Line 659 is vulnerable:\n",
      "Line 660 is vulnerable:\n",
      "Line 661 is vulnerable:\n",
      "Line 662 is vulnerable:\n",
      "Line 663 is vulnerable:\n",
      "Line 664 is vulnerable:\n",
      "Line 665 is vulnerable:\n",
      "Line 666 is vulnerable:\n",
      "Line 667 is vulnerable:\n",
      "Line 668 is vulnerable:\n",
      "Line 669 is vulnerable:\n",
      "Line 670 is vulnerable:\n",
      "Line 671 is vulnerable:\n",
      "Line 672 is vulnerable:\n",
      "Line 673 is vulnerable:\n",
      "Line 674 is vulnerable:\n",
      "Line 675 is vulnerable:\n",
      "Line 676 is vulnerable:\n",
      "Line 677 is vulnerable:\n",
      "Line 678 is vulnerable:\n",
      "Line 679 is vulnerable:\n",
      "Line 680 is vulnerable:\n",
      "Line 681 is vulnerable:\n",
      "Line 682 is vulnerable:\n",
      "Line 683 is vulnerable:\n",
      "Line 684 is vulnerable:\n",
      "Line 685 is vulnerable:\n",
      "Line 686 is vulnerable:\n",
      "Line 687 is vulnerable:\n",
      "Line 688 is vulnerable:\n",
      "Line 689 is vulnerable:\n",
      "Line 690 is vulnerable:\n",
      "Line 691 is vulnerable:\n",
      "Line 692 is vulnerable:\n",
      "Line 693 is vulnerable:\n",
      "Line 694 is vulnerable:\n",
      "Line 695 is vulnerable:\n",
      "Line 696 is vulnerable:\n",
      "Line 697 is vulnerable:\n",
      "Line 698 is vulnerable:\n",
      "Line 699 is vulnerable:\n",
      "Line 700 is vulnerable:\n",
      "Line 701 is vulnerable:\n",
      "Line 702 is vulnerable:\n",
      "Line 703 is vulnerable:\n",
      "Line 704 is vulnerable:\n",
      "Line 705 is vulnerable:\n",
      "Line 706 is vulnerable:\n",
      "Line 707 is vulnerable:\n",
      "Line 708 is vulnerable:\n",
      "Line 709 is vulnerable:\n",
      "Line 710 is vulnerable:\n",
      "Line 711 is vulnerable:\n",
      "Line 712 is vulnerable:\n",
      "Line 713 is vulnerable:\n",
      "Line 714 is vulnerable:\n",
      "Line 715 is vulnerable:\n",
      "Line 716 is vulnerable:\n",
      "Line 717 is vulnerable:\n",
      "Line 718 is vulnerable:\n",
      "Line 719 is vulnerable:\n",
      "Line 720 is vulnerable:\n",
      "Line 721 is vulnerable:\n",
      "Line 722 is vulnerable:\n",
      "Line 723 is vulnerable:\n",
      "Line 724 is vulnerable:\n",
      "Line 725 is vulnerable:\n",
      "Line 726 is vulnerable:\n",
      "Line 727 is vulnerable:\n",
      "Line 728 is vulnerable:\n",
      "Line 729 is vulnerable:\n",
      "Line 730 is vulnerable:\n",
      "Line 731 is vulnerable:\n",
      "Line 732 is vulnerable:\n",
      "Line 733 is vulnerable:\n",
      "Line 734 is vulnerable:\n",
      "Line 735 is vulnerable:\n",
      "Line 736 is vulnerable:\n",
      "Line 737 is vulnerable:\n",
      "Line 738 is vulnerable:\n",
      "Line 739 is vulnerable:\n",
      "Line 740 is vulnerable:\n",
      "Line 741 is vulnerable:\n",
      "Line 742 is vulnerable:\n",
      "Line 743 is vulnerable:\n",
      "Line 744 is vulnerable:\n",
      "Line 745 is vulnerable:\n",
      "Line 746 is vulnerable:\n",
      "Line 747 is vulnerable:\n",
      "Line 748 is vulnerable:\n",
      "Line 749 is vulnerable:\n",
      "Line 750 is vulnerable:\n",
      "Line 751 is vulnerable:\n",
      "Line 752 is vulnerable:\n",
      "Line 753 is vulnerable:\n",
      "Line 754 is vulnerable:\n",
      "Line 755 is vulnerable:\n",
      "Line 756 is vulnerable:\n",
      "Line 757 is vulnerable:\n",
      "Line 758 is vulnerable:\n",
      "Line 759 is vulnerable:\n",
      "Line 760 is vulnerable:\n",
      "Line 761 is vulnerable:\n",
      "Line 762 is vulnerable:\n",
      "Line 763 is vulnerable:\n",
      "Line 764 is vulnerable:\n",
      "Line 765 is vulnerable:\n",
      "Line 766 is vulnerable:\n",
      "Line 767 is vulnerable:\n",
      "Line 768 is vulnerable:\n",
      "Line 769 is vulnerable:\n",
      "Line 770 is vulnerable:\n",
      "Line 771 is vulnerable:\n",
      "Line 772 is vulnerable:\n",
      "Line 773 is vulnerable:\n",
      "Line 774 is vulnerable:\n",
      "Line 775 is vulnerable:\n",
      "Line 776 is vulnerable:\n",
      "Line 777 is vulnerable:\n",
      "Line 778 is vulnerable:\n",
      "Line 779 is vulnerable:\n",
      "Line 780 is vulnerable:\n",
      "Line 781 is vulnerable:\n",
      "Line 782 is vulnerable:\n",
      "Line 783 is vulnerable:\n",
      "Line 784 is vulnerable:\n",
      "Line 785 is vulnerable:\n",
      "Line 786 is vulnerable:\n",
      "Line 787 is vulnerable:\n",
      "Line 788 is vulnerable:\n",
      "Line 789 is vulnerable:\n",
      "Line 790 is vulnerable:\n",
      "Line 791 is vulnerable:\n",
      "Line 792 is vulnerable:\n",
      "Line 793 is vulnerable:\n",
      "Line 794 is vulnerable:\n",
      "Line 795 is vulnerable:\n",
      "Line 796 is vulnerable:\n",
      "Line 797 is vulnerable:\n",
      "Line 798 is vulnerable:\n",
      "Line 799 is vulnerable:\n",
      "Line 800 is vulnerable:\n",
      "Line 801 is vulnerable:\n",
      "Line 802 is vulnerable:\n",
      "Line 803 is vulnerable:\n",
      "Line 804 is vulnerable:\n",
      "Line 805 is vulnerable:\n",
      "Line 806 is vulnerable:\n",
      "Line 807 is vulnerable:\n",
      "Line 808 is vulnerable:\n",
      "Line 809 is vulnerable:\n",
      "Line 810 is vulnerable:\n",
      "Line 811 is vulnerable:\n",
      "Line 812 is vulnerable:\n",
      "Line 813 is vulnerable:\n",
      "Line 814 is vulnerable:\n",
      "Line 815 is vulnerable:\n",
      "Line 816 is vulnerable:\n",
      "Line 817 is vulnerable:\n",
      "Line 818 is vulnerable:\n",
      "Line 819 is vulnerable:\n",
      "Line 820 is vulnerable:\n",
      "Line 821 is vulnerable:\n",
      "Line 822 is vulnerable:\n",
      "Line 823 is vulnerable:\n",
      "Line 824 is vulnerable:\n",
      "Line 825 is vulnerable:\n",
      "Line 826 is vulnerable:\n",
      "Line 827 is vulnerable:\n",
      "Line 828 is vulnerable:\n",
      "Line 829 is vulnerable:\n",
      "Line 830 is vulnerable:\n",
      "Line 831 is vulnerable:\n",
      "Line 832 is vulnerable:\n",
      "Line 833 is vulnerable:\n",
      "Line 834 is vulnerable:\n",
      "Line 835 is vulnerable:\n",
      "Line 836 is vulnerable:\n",
      "Line 837 is vulnerable:\n",
      "Line 838 is vulnerable:\n",
      "Line 839 is vulnerable:\n",
      "Line 840 is vulnerable:\n",
      "Line 841 is vulnerable:\n",
      "Line 842 is vulnerable:\n",
      "Line 843 is vulnerable:\n",
      "Line 844 is vulnerable:\n",
      "Line 845 is vulnerable:\n",
      "Line 846 is vulnerable:\n",
      "Line 847 is vulnerable:\n",
      "Line 848 is vulnerable:\n",
      "Line 849 is vulnerable:\n",
      "Line 850 is vulnerable:\n",
      "Line 851 is vulnerable:\n",
      "Line 852 is vulnerable:\n",
      "Line 853 is vulnerable:\n",
      "Line 854 is vulnerable:\n",
      "Line 855 is vulnerable:\n",
      "Line 856 is vulnerable:\n",
      "Line 857 is vulnerable:\n",
      "Line 858 is vulnerable:\n",
      "Line 859 is vulnerable:\n",
      "Line 860 is vulnerable:\n",
      "Line 861 is vulnerable:\n",
      "Line 862 is vulnerable:\n",
      "Line 863 is vulnerable:\n",
      "Line 864 is vulnerable:\n",
      "Line 865 is vulnerable:\n",
      "Line 866 is vulnerable:\n",
      "Line 867 is vulnerable:\n",
      "Line 868 is vulnerable:\n",
      "Line 869 is vulnerable:\n",
      "Line 870 is vulnerable:\n",
      "Line 871 is vulnerable:\n",
      "Line 872 is vulnerable:\n",
      "Line 873 is vulnerable:\n",
      "Line 874 is vulnerable:\n",
      "Line 875 is vulnerable:\n",
      "Line 876 is vulnerable:\n",
      "Line 877 is vulnerable:\n",
      "Line 878 is vulnerable:\n",
      "Line 879 is vulnerable:\n",
      "Line 880 is vulnerable:\n",
      "Line 881 is vulnerable:\n",
      "Line 882 is vulnerable:\n",
      "Line 883 is vulnerable:\n",
      "Line 884 is vulnerable:\n",
      "Line 885 is vulnerable:\n",
      "Line 886 is vulnerable:\n",
      "Line 887 is vulnerable:\n",
      "Line 888 is vulnerable:\n",
      "Line 889 is vulnerable:\n",
      "Line 890 is vulnerable:\n",
      "Line 891 is vulnerable:\n",
      "Line 892 is vulnerable:\n",
      "Line 893 is vulnerable:\n",
      "Line 894 is vulnerable:\n",
      "Line 895 is vulnerable:\n",
      "Line 896 is vulnerable:\n",
      "Line 897 is vulnerable:\n",
      "Line 898 is vulnerable:\n",
      "Line 899 is vulnerable:\n",
      "Line 900 is vulnerable:\n",
      "Line 901 is vulnerable:\n",
      "Line 902 is vulnerable:\n",
      "Line 903 is vulnerable:\n",
      "Line 904 is vulnerable:\n",
      "Line 905 is vulnerable:\n",
      "Line 906 is vulnerable:\n",
      "Line 907 is vulnerable:\n",
      "Line 908 is vulnerable:\n",
      "Line 909 is vulnerable:\n",
      "Line 910 is vulnerable:\n",
      "Line 911 is vulnerable:\n",
      "Line 912 is vulnerable:\n",
      "Line 913 is vulnerable:\n",
      "Line 914 is vulnerable:\n",
      "Line 915 is vulnerable:\n",
      "Line 916 is vulnerable:\n",
      "Line 917 is vulnerable:\n",
      "Line 918 is vulnerable:\n",
      "Line 919 is vulnerable:\n",
      "Line 920 is vulnerable:\n",
      "Line 921 is vulnerable:\n",
      "Line 922 is vulnerable:\n",
      "Line 923 is vulnerable:\n",
      "Line 924 is vulnerable:\n",
      "Line 925 is vulnerable:\n",
      "Line 926 is vulnerable:\n",
      "Line 927 is vulnerable:\n",
      "Line 928 is vulnerable:\n",
      "Line 929 is vulnerable:\n",
      "Line 930 is vulnerable:\n",
      "Line 931 is vulnerable:\n",
      "Line 932 is vulnerable:\n",
      "Line 933 is vulnerable:\n",
      "Line 934 is vulnerable:\n",
      "Line 935 is vulnerable:\n",
      "Line 936 is vulnerable:\n",
      "Line 937 is vulnerable:\n",
      "Line 938 is vulnerable:\n",
      "Line 939 is vulnerable:\n",
      "Line 940 is vulnerable:\n",
      "Line 941 is vulnerable:\n",
      "Line 942 is vulnerable:\n",
      "Line 943 is vulnerable:\n",
      "Line 944 is vulnerable:\n",
      "Line 945 is vulnerable:\n",
      "Line 946 is vulnerable:\n",
      "Line 947 is vulnerable:\n",
      "Line 948 is vulnerable:\n",
      "Line 949 is vulnerable:\n",
      "Line 950 is vulnerable:\n",
      "Line 951 is vulnerable:\n",
      "Line 952 is vulnerable:\n",
      "Line 953 is vulnerable:\n",
      "Line 954 is vulnerable:\n",
      "Line 955 is vulnerable:\n",
      "Line 956 is vulnerable:\n",
      "Line 957 is vulnerable:\n",
      "Line 958 is vulnerable:\n",
      "Line 959 is vulnerable:\n",
      "Line 960 is vulnerable:\n",
      "Line 961 is vulnerable:\n",
      "Line 962 is vulnerable:\n",
      "Line 963 is vulnerable:\n",
      "Line 964 is vulnerable:\n",
      "Line 965 is vulnerable:\n",
      "Line 966 is vulnerable:\n",
      "Line 967 is vulnerable:\n",
      "Line 968 is vulnerable:\n",
      "Line 969 is vulnerable:\n",
      "Line 970 is vulnerable:\n",
      "Line 971 is vulnerable:\n",
      "Line 972 is vulnerable:\n",
      "Line 973 is vulnerable:\n",
      "Line 974 is vulnerable:\n",
      "Line 975 is vulnerable:\n",
      "Line 976 is vulnerable:\n",
      "Line 977 is vulnerable:\n",
      "Line 978 is vulnerable:\n",
      "Line 979 is vulnerable:\n",
      "Line 980 is vulnerable:\n",
      "Line 981 is vulnerable:\n",
      "Line 982 is vulnerable:\n",
      "Line 983 is vulnerable:\n",
      "Line 984 is vulnerable:\n",
      "Line 985 is vulnerable:\n",
      "Line 986 is vulnerable:\n",
      "Line 987 is vulnerable:\n",
      "Line 988 is vulnerable:\n",
      "Line 989 is vulnerable:\n",
      "Line 990 is vulnerable:\n",
      "Line 991 is vulnerable:\n",
      "Line 992 is vulnerable:\n",
      "Line 993 is vulnerable:\n",
      "Line 994 is vulnerable:\n",
      "Line 995 is vulnerable:\n",
      "Line 996 is vulnerable:\n",
      "Line 997 is vulnerable:\n",
      "Line 998 is vulnerable:\n",
      "Line 999 is vulnerable:\n",
      "Line 1000 is vulnerable:\n",
      "Line 1001 is vulnerable:\n",
      "Line 1002 is vulnerable:\n",
      "Line 1003 is vulnerable:\n",
      "Line 1004 is vulnerable:\n",
      "Line 1005 is vulnerable:\n",
      "Line 1006 is vulnerable:\n",
      "Line 1007 is vulnerable:\n",
      "Line 1008 is vulnerable:\n",
      "Line 1009 is vulnerable:\n",
      "Line 1010 is vulnerable:\n",
      "Line 1011 is vulnerable:\n",
      "Line 1012 is vulnerable:\n",
      "Line 1013 is vulnerable:\n",
      "Line 1014 is vulnerable:\n",
      "Line 1015 is vulnerable:\n",
      "Line 1016 is vulnerable:\n",
      "Line 1017 is vulnerable:\n",
      "Line 1018 is vulnerable:\n",
      "Line 1019 is vulnerable:\n",
      "Line 1020 is vulnerable:\n",
      "Line 1021 is vulnerable:\n",
      "Line 1022 is vulnerable:\n",
      "Line 1023 is vulnerable:\n",
      "✅ Test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Enable debug mode\n",
    "model._debug_mode = False\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        ast_input_ids=ast_input_ids,\n",
    "        ast_attention_mask=ast_attention_mask,\n",
    "        target_ids=input_ids,  # Use input_ids as target for inference\n",
    "        token_to_line=token_to_line\n",
    "    )\n",
    "\n",
    "contract_vuln_logits = outputs.get('contract_vulnerability_logits')\n",
    "line_vuln_logits = outputs.get('line_vulnerability_logits')\n",
    "\n",
    "line_vuln_probs = torch.sigmoid(line_vuln_logits)  # Shape: [1, num_lines, 8]\n",
    "\n",
    "for line_idx in range(line_vuln_probs.shape[1]):\n",
    "    line_probs = line_vuln_probs[0, line_idx, :]  # Shape: [8]\n",
    "    # Check if any vulnerability type has high probability\n",
    "    is_vulnerable = (line_probs > 0.1).any()\n",
    "    if is_vulnerable:\n",
    "        print(f\"Line {line_idx} is vulnerable:\")\n",
    "        for i, vuln_type in enumerate(VULNERABILITY_TYPES):\n",
    "            if line_probs[i] > 0.1 and line_probs[i] < 0.5000:\n",
    "                print(f\"  {vuln_type}: {line_probs[i]:.4f}\")\n",
    "\n",
    "print(\"✅ Test completed successfully!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7692294-f9bb-436e-a1d3-ff0adacdc963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50121]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_tokens = tokenizer.encode(lines[5], add_special_tokens=False)\n",
    "line_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08450e1d-9fee-4d05-b322-51c226804e93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df8c42-24fe-42f7-ace7-221ba210ecea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac78d09f-d9f7-4015-8922-f64b5a308ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66800902-be90-4fee-aa7e-2de6a2534216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce80b00-e169-40ac-9e6b-fb8b774c36a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb18ce4e-91e2-4b3b-8c55-923911c11b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_p310",
   "language": "python",
   "name": "pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
