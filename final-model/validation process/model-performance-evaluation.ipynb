{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f55485-2c52-452f-88eb-da6bebedc5ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/m20180848/.local/lib/python3.12/site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /home/m20180848/.local/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/anaconda/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/anaconda/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/anaconda/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc70e70-3388-48a1-9891-528c5230273f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m20180848/.conda/envs/pytorch_p310/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from inference import *\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Model imports\n",
    "from model import SmartContractTransformer\n",
    "\n",
    "# Optional but useful imports\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # for progress bars\n",
    "import logging\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import re\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, accuracy_score"
   ]
  },
  {
   "cell_type": "raw",
   "id": "24542b59-93eb-4d44-bd09-a4a7d44faf7d",
   "metadata": {},
   "source": [
    "import importlib\n",
    "from inference import SmartContractAnalyzer\n",
    "\n",
    "importlib.reload(SmartContractAnalyzer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33baac5-1132-4019-9a19-9de07ce9f3fe",
   "metadata": {},
   "source": [
    "# 1. Load Validation Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abf829a4-aab2-4666-9d54-1f5ed0de035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def parse_solidity_to_ast(code: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parse Solidity code into a simplified AST structure\n",
    "    \"\"\"\n",
    "    def extract_contract_info(code: str) -> Dict[str, Any]:\n",
    "        # Extract contract name\n",
    "        contract_match = re.search(r'contract\\s+(\\w+)', code)\n",
    "        contract_name = contract_match.group(1) if contract_match else \"Unknown\"\n",
    "        \n",
    "        # Extract functions\n",
    "        functions = []\n",
    "        function_pattern = r'function\\s+(\\w+)\\s*\\(([^)]*)\\)\\s*(?:public|private|internal|external)?\\s*(?:view|pure|payable)?\\s*(?:returns\\s*\\(([^)]*)\\))?\\s*{'\n",
    "        for match in re.finditer(function_pattern, code):\n",
    "            func_name = match.group(1)\n",
    "            params = match.group(2).split(',') if match.group(2) else []\n",
    "            returns = match.group(3).split(',') if match.group(3) else []\n",
    "            \n",
    "            functions.append({\n",
    "                'name': func_name,\n",
    "                'parameters': [p.strip() for p in params],\n",
    "                'returns': [r.strip() for r in returns]\n",
    "            })\n",
    "        \n",
    "        # Extract state variables\n",
    "        variables = []\n",
    "        var_pattern = r'(?:uint|address|string|bool|mapping)\\s+(?:\\w+)\\s+(\\w+)'\n",
    "        for match in re.finditer(var_pattern, code):\n",
    "            variables.append(match.group(1))\n",
    "        \n",
    "        return {\n",
    "            'type': 'Contract',\n",
    "            'name': contract_name,\n",
    "            'functions': functions,\n",
    "            'variables': variables\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        # Clean the code\n",
    "        code = re.sub(r'//.*?\\n|/\\*.*?\\*/', '', code)  # Remove comments\n",
    "        code = re.sub(r'\\s+', ' ', code)  # Normalize whitespace\n",
    "        \n",
    "        # Parse the code\n",
    "        ast = extract_contract_info(code)\n",
    "        return ast\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing code: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def prepare_code2vec_input(ast: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Convert AST to codeBert input format\n",
    "    \"\"\"\n",
    "    paths = []\n",
    "    \n",
    "    def extract_paths(node: Dict[str, Any], current_path: List[str] = None):\n",
    "        if current_path is None:\n",
    "            current_path = []\n",
    "            \n",
    "        # Add current node to path\n",
    "        if 'name' in node:\n",
    "            current_path.append(node['name'])\n",
    "            \n",
    "        # Process functions\n",
    "        if 'functions' in node:\n",
    "            for func in node['functions']:\n",
    "                func_path = current_path + [func['name']]\n",
    "                paths.append(' '.join(func_path))\n",
    "                \n",
    "                # Add parameter paths\n",
    "                for param in func['parameters']:\n",
    "                    param_path = func_path + [param]\n",
    "                    paths.append(' '.join(param_path))\n",
    "                \n",
    "                # Add return paths\n",
    "                for ret in func['returns']:\n",
    "                    ret_path = func_path + [ret]\n",
    "                    paths.append(' '.join(ret_path))\n",
    "        \n",
    "        # Process variables\n",
    "        if 'variables' in node:\n",
    "            for var in node['variables']:\n",
    "                var_path = current_path + [var]\n",
    "                paths.append(' '.join(var_path))\n",
    "    \n",
    "    extract_paths(ast)\n",
    "    return paths\n",
    "\n",
    "class SmartContractVulnerabilityDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        max_length: int = 1024,\n",
    "        split: str = \"train\",\n",
    "        vulnerability_types: List[str] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_path: Path to the CSV file containing the dataset\n",
    "            tokenizer: Tokenizer for encoding the source code\n",
    "            max_length: Maximum sequence length\n",
    "            split: \"train\" or \"val\" to specify which split to load\n",
    "            vulnerability_types: List of vulnerability types to consider\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.split = split\n",
    "        self.vulnerability_types = vulnerability_types or [\n",
    "            'ARTHM', 'DOS', 'LE', 'RENT', 'TimeM', 'TimeO', 'Tx-Origin', 'UE'\n",
    "        ]\n",
    "        \n",
    "        # Load the dataset\n",
    "        self.data = self._load_dataset(data_path)\n",
    "        \n",
    "    def _load_dataset(self, data_path: str) -> List[Dict]:\n",
    "        \"\"\"Load and preprocess the dataset from CSV\"\"\"\n",
    "        dataset = []\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(data_path)\n",
    "        \n",
    "        # Split into train/val if needed\n",
    "        if self.split == \"train\":\n",
    "            df = df.sample(frac=0.8, random_state=42)\n",
    "        else:\n",
    "            df = df.sample(frac=0.2, random_state=42)\n",
    "        \n",
    "        # Process each contract\n",
    "        for _, row in df.iterrows():\n",
    "            try:\n",
    "                source_code = row['source_code']\n",
    "                contract_name = row['contract_name']\n",
    "                \n",
    "                # Parse AST and get paths\n",
    "                ast = parse_solidity_to_ast(source_code)\n",
    "                ast_paths = prepare_code2vec_input(ast) if ast else []\n",
    "                ast_path_text = ' '.join(ast_paths)\n",
    "                \n",
    "                # Split source code into lines\n",
    "                lines = source_code.split('\\n')\n",
    "                \n",
    "                # Create token-to-line mapping\n",
    "                token_to_line = []\n",
    "                current_line = 0\n",
    "                \n",
    "                # Tokenize each line separately to maintain mapping\n",
    "                for line in lines:\n",
    "                    line_tokens = self.tokenizer.encode(line, add_special_tokens=False)\n",
    "                    token_to_line.extend([current_line] * len(line_tokens))\n",
    "                    current_line += 1\n",
    "                \n",
    "                # Add special tokens\n",
    "                token_to_line = [0] + token_to_line + [0]  # [CLS] and [SEP] tokens\n",
    "                \n",
    "                # Truncate if too long\n",
    "                if len(token_to_line) > self.max_length:\n",
    "                    token_to_line = token_to_line[:self.max_length]\n",
    "                \n",
    "                # Pad if too short\n",
    "                if len(token_to_line) < self.max_length:\n",
    "                    token_to_line.extend([0] * (self.max_length - len(token_to_line)))\n",
    "                \n",
    "                # Create multi-label line labels for each vulnerability type\n",
    "                line_labels = self._create_multi_label_line_labels(source_code, row)\n",
    "                \n",
    "                # Create contract-level vulnerability labels\n",
    "                contract_labels = self._create_contract_vulnerability_labels(row)\n",
    "                \n",
    "                # Tokenize the source code\n",
    "                encoding = self.tokenizer(\n",
    "                    source_code,\n",
    "                    max_length=self.max_length,\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                # Tokenize AST paths\n",
    "                ast_encoding = self.tokenizer(\n",
    "                    ast_path_text,\n",
    "                    max_length=self.max_length,\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                # Convert line labels to tensor and ensure consistent shape\n",
    "                vuln_tensor = torch.zeros((len(self.vulnerability_types), self.max_length), dtype=torch.long)\n",
    "                for i, labels in enumerate(line_labels):\n",
    "                    if len(labels) > self.max_length:\n",
    "                        labels = labels[:self.max_length]\n",
    "                    vuln_tensor[i, :len(labels)] = torch.tensor(labels, dtype=torch.long)\n",
    "                \n",
    "                # Convert contract labels to tensor\n",
    "                contract_vuln_tensor = torch.tensor(contract_labels, dtype=torch.long)\n",
    "                \n",
    "                # Convert token_to_line to tensor\n",
    "                token_to_line_tensor = torch.tensor(token_to_line, dtype=torch.long)\n",
    "                \n",
    "                # Ensure attention masks are boolean\n",
    "                attention_mask = encoding['attention_mask'].squeeze(0).bool()\n",
    "                ast_attention_mask = ast_encoding['attention_mask'].squeeze(0).bool()\n",
    "                \n",
    "                # Ensure input_ids are the right length\n",
    "                input_ids = encoding['input_ids'].squeeze(0)\n",
    "                ast_input_ids = ast_encoding['input_ids'].squeeze(0)\n",
    "                \n",
    "                if len(input_ids) > self.max_length:\n",
    "                    input_ids = input_ids[:self.max_length]\n",
    "                if len(ast_input_ids) > self.max_length:\n",
    "                    ast_input_ids = ast_input_ids[:self.max_length]\n",
    "                \n",
    "                # Pad if necessary\n",
    "                if len(input_ids) < self.max_length:\n",
    "                    input_ids = torch.nn.functional.pad(input_ids, (0, self.max_length - len(input_ids)))\n",
    "                if len(ast_input_ids) < self.max_length:\n",
    "                    ast_input_ids = torch.nn.functional.pad(ast_input_ids, (0, self.max_length - len(ast_input_ids)))\n",
    "                \n",
    "                dataset.append({\n",
    "                    'input_ids': input_ids,\n",
    "                    'attention_mask': attention_mask,\n",
    "                    'ast_input_ids': ast_input_ids,\n",
    "                    'ast_attention_mask': ast_attention_mask,\n",
    "                    'vulnerable_lines': vuln_tensor,\n",
    "                    'contract_vulnerabilities': contract_vuln_tensor,\n",
    "                    'token_to_line': token_to_line_tensor,\n",
    "                    'source_code': source_code,\n",
    "                    'contract_name': contract_name\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing contract {contract_name}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    def _create_contract_vulnerability_labels(self, row: pd.Series) -> List[int]:\n",
    "        \"\"\"Create contract-level vulnerability labels\"\"\"\n",
    "        contract_labels = []\n",
    "        for vuln_type in self.vulnerability_types:\n",
    "            # Check if contract has this vulnerability type\n",
    "            vuln_lines = row[f'{vuln_type}_lines']\n",
    "            if isinstance(vuln_lines, str):\n",
    "                try:\n",
    "                    vuln_lines = eval(vuln_lines)\n",
    "                except:\n",
    "                    vuln_lines = [vuln_lines]\n",
    "            \n",
    "            # Contract is vulnerable if it has any vulnerable lines\n",
    "            has_vulnerability = len(vuln_lines) > 0\n",
    "            contract_labels.append(1 if has_vulnerability else 0)\n",
    "        \n",
    "        return contract_labels\n",
    "    \n",
    "    def _create_multi_label_line_labels(self, source_code: str, row: pd.Series) -> List[List[int]]:\n",
    "        \"\"\"Create multi-label line labels for each vulnerability type\"\"\"\n",
    "        total_lines = len(source_code.split('\\n'))\n",
    "        line_labels = {vuln_type: [0] * total_lines for vuln_type in self.vulnerability_types}\n",
    "        \n",
    "        # Process each vulnerability type\n",
    "        for vuln_type in self.vulnerability_types:\n",
    "            vuln_lines = row[f'{vuln_type}_lines']\n",
    "            if isinstance(vuln_lines, str):\n",
    "                try:\n",
    "                    vuln_lines = eval(vuln_lines)\n",
    "                except:\n",
    "                    vuln_lines = [vuln_lines]\n",
    "            \n",
    "            # Process each vulnerable line/snippet\n",
    "            for line_or_snippet in vuln_lines:\n",
    "                if isinstance(line_or_snippet, int):\n",
    "                    # If it's a line number, mark that line\n",
    "                    if 0 <= line_or_snippet < total_lines:\n",
    "                        line_labels[vuln_type][line_or_snippet] = 1\n",
    "                else:\n",
    "                    # If it's a code snippet, find matching lines\n",
    "                    source_lines = source_code.split('\\n')\n",
    "                    for i, line in enumerate(source_lines):\n",
    "                        # Clean both the line and snippet for comparison\n",
    "                        clean_line = re.sub(r'\\s+', ' ', line.strip())\n",
    "                        clean_snippet = re.sub(r'\\s+', ' ', str(line_or_snippet).strip())\n",
    "                        if clean_snippet in clean_line:\n",
    "                            line_labels[vuln_type][i] = 1\n",
    "        \n",
    "        # Convert to list format\n",
    "        return [line_labels[vuln_type] for vuln_type in self.vulnerability_types]\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict:\n",
    "        return self.data[idx]\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle variable length inputs\n",
    "    \"\"\"\n",
    "    # Get the maximum length in this batch for each type of tensor\n",
    "    max_input_len = max(item['input_ids'].size(0) for item in batch)\n",
    "    \n",
    "    # Pad all tensors to their respective maximum lengths\n",
    "    padded_batch = {\n",
    "        'input_ids': torch.stack([\n",
    "            torch.nn.functional.pad(item['input_ids'], (0, max_input_len - item['input_ids'].size(0)))\n",
    "            for item in batch\n",
    "        ]),\n",
    "        'attention_mask': torch.stack([\n",
    "            torch.nn.functional.pad(item['attention_mask'], (0, max_input_len - item['attention_mask'].size(0)))\n",
    "            for item in batch\n",
    "        ]),\n",
    "        'ast_input_ids': torch.stack([item['ast_input_ids'] for item in batch]),\n",
    "        'ast_attention_mask': torch.stack([item['ast_attention_mask'] for item in batch]),\n",
    "        'vulnerable_lines': torch.stack([item['vulnerable_lines'] for item in batch]),\n",
    "        'contract_vulnerabilities': torch.stack([item['contract_vulnerabilities'] for item in batch]),\n",
    "        'token_to_line': torch.stack([item['token_to_line'] for item in batch]),\n",
    "        'source_code': [item['source_code'] for item in batch],\n",
    "        'contract_name': [item['contract_name'] for item in batch]\n",
    "    }\n",
    "    \n",
    "    return padded_batch\n",
    "\n",
    "def create_dataloaders(\n",
    "    data_path: str,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    batch_size: int = 8,\n",
    "    max_length: int = 1024,\n",
    "    num_workers: int = 4,\n",
    "    vulnerability_types: List[str] = None\n",
    ") -> Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
    "    \"\"\"\n",
    "    Create train and validation dataloaders\n",
    "    \n",
    "    Args:\n",
    "        data_path: Path to the CSV file containing the dataset\n",
    "        tokenizer: Tokenizer for encoding the source code\n",
    "        batch_size: Batch size for training\n",
    "        max_length: Maximum sequence length\n",
    "        num_workers: Number of workers for data loading\n",
    "        vulnerability_types: List of vulnerability types to consider\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train_dataloader, val_dataloader)\n",
    "    \"\"\"\n",
    "    # Create datasets\n",
    "    train_dataset = SmartContractVulnerabilityDataset(\n",
    "        data_path=data_path,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=max_length,\n",
    "        split=\"train\",\n",
    "        vulnerability_types=vulnerability_types\n",
    "    )\n",
    "    \n",
    "    val_dataset = SmartContractVulnerabilityDataset(\n",
    "        data_path=data_path,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=max_length,\n",
    "        split=\"val\",\n",
    "        vulnerability_types=vulnerability_types\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders with custom collate function\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "    \n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "    \n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bea9d5c-1371-4d31-9b39-d84ae55e03f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m20180848/.conda/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader, val_dataloader = create_dataloaders(\n",
    "    data_path=\"contract_sources_with_vulnerabilities_2048_token_size.csv\",\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=8,\n",
    "    max_length=1024,\n",
    "    vulnerability_types=['ARTHM', 'DOS', 'LE', 'RENT', 'TimeM', 'TimeO', 'Tx-Origin', 'UE']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b43db63-0e15-4e48-b9ec-399aa5c68e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataloader.dataset.data[0]['vulnerable_lines'][7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea56f5f-154f-4ffe-9360-3a227bada3e1",
   "metadata": {},
   "source": [
    "# 2. Load Model and SmartContractAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c1ac1b8-f16f-46da-a408-9b08360d6b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision(true_labels: np.ndarray, pred_labels: np.ndarray) -> float:\n",
    "    \"\"\"Calculate precision for vulnerability detection.\"\"\"\n",
    "    if np.sum(pred_labels) == 0:\n",
    "        return 0.0\n",
    "    return np.sum((true_labels == 1) & (pred_labels == 1)) / np.sum(pred_labels)\n",
    "\n",
    "def calculate_recall(true_labels: np.ndarray, pred_labels: np.ndarray) -> float:\n",
    "    \"\"\"Calculate recall for vulnerability detection.\"\"\"\n",
    "    if np.sum(true_labels) == 0:\n",
    "        return 0.0\n",
    "    return np.sum((true_labels == 1) & (pred_labels == 1)) / np.sum(true_labels)\n",
    "\n",
    "def calculate_f1_score(precision: float, recall: float) -> float:\n",
    "    \"\"\"Calculate F1 score.\"\"\"\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def calculate_line_accuracy(true_line_vulns: np.ndarray, pred_line_vulns: Dict) -> float:\n",
    "    \"\"\"Calculate line-level accuracy (simplified).\"\"\"\n",
    "    try:\n",
    "        # Convert predicted line vulnerabilities to array format\n",
    "        pred_array = np.zeros_like(true_line_vulns)\n",
    "        for line_num, line_vulns in pred_line_vulns.items():\n",
    "            if line_num < pred_array.shape[0]:\n",
    "                for vuln_idx, is_vuln in enumerate(line_vulns.values()):\n",
    "                    if vuln_idx < pred_array.shape[1]:\n",
    "                        pred_array[line_num, vuln_idx] = 1 if is_vuln else 0\n",
    "        \n",
    "        return np.mean(pred_array == true_line_vulns)\n",
    "    except:\n",
    "        return 0.\n",
    "\n",
    "def get_vulnerability_details(analyzer, true_vulns: np.ndarray, pred_vulns: np.ndarray, \n",
    "                            probabilities: List[float]) -> Dict[str, Any]:\n",
    "    \"\"\"Get detailed vulnerability analysis.\"\"\"\n",
    "    details = {}\n",
    "    for i, vuln_type in enumerate(analyzer.vulnerability_types):\n",
    "        details[vuln_type] = {\n",
    "            'true_positive': bool(true_vulns[i] == 1 and pred_vulns[i] == 1),\n",
    "            'false_positive': bool(true_vulns[i] == 0 and pred_vulns[i] == 1),\n",
    "            'false_negative': bool(true_vulns[i] == 1 and pred_vulns[i] == 0),\n",
    "            'true_negative': bool(true_vulns[i] == 0 and pred_vulns[i] == 0),\n",
    "            'probability': probabilities[i],\n",
    "            'true_label': int(true_vulns[i]),\n",
    "            'predicted_label': int(pred_vulns[i])\n",
    "        }\n",
    "    return details\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba95f732-ea3d-4d6d-8766-d418ff4e9337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3ae2c20-b725-451c-91bb-f6a4d9772231",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"contract_sources_with_vulnerabilities_2048_token_size.csv\"\n",
    "MODEL_PATH = \"checkpoints_v5_2048_output/best_model_augmented_gan_epoch_106.pt\"\n",
    "TOKENIZER_NAME = \"microsoft/codebert-base\"\n",
    "VULNERABILITY_TYPES = ['ARTHM', 'DOS', 'LE', 'RENT', 'TimeM', 'TimeO', 'Tx-Origin', 'UE']\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "MODEL_LINE_CODE_VULNERABILITY_THRESHOLD = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4f98a35-c0ea-45ce-ab66-adaeda9507d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m20180848/.conda/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/m20180848/.conda/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Initialized line feature extractor layer 1 with small random weights\n",
      "DEBUG: Initialized line feature extractor layer 3 with small random weights\n",
      "DEBUG: Initialized custom line feature extractor with small weights\n",
      "Model loaded from checkpoints_v5_2048_output/best_model_augmented_gan_epoch_106.pt\n",
      "Training epoch: 106\n",
      "Best validation loss: 0.773994717746973\n",
      "Training config: GAN=True\n"
     ]
    }
   ],
   "source": [
    "analyzer = SmartContractAnalyzer(\n",
    "    model_path=MODEL_PATH,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    use_gan=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e6fca82-26f0-428f-b6ca-6cbd76cc4089",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/**\n",
      " * Source Code first verified at https://etherscan.io on Tuesday, December 18, 2018\n",
      " (UTC) */\n",
      "\n",
      "pragma solidity ^0.4.23;\n",
      "\n",
      "library SafeMath {\n",
      "\n",
      "  /**\n",
      "  * @dev Multiplies two numbers, throws on overflow.\n",
      "  */\n",
      "  function mul(uint256 a, uint256 b) internal pure returns (uint256 c) {\n",
      "\n",
      "    if (a == 0) {\n",
      "      return 0;\n",
      "    }\n",
      "\n",
      "    c = a * b;\n",
      "    assert(c / a == b);\n",
      "    return c;\n",
      "  }\n",
      "\n",
      "  /**\n",
      "  * @dev Integer division of two numbers, truncating the quotient.\n",
      "  */\n",
      "  function div(uint256 a, uint256 b) internal pure returns (uint256) {\n",
      "\n",
      "    return a / b;\n",
      "  }\n",
      "\n",
      "  /**\n",
      "  * @dev Subtracts two numbers, throws on overflow (i.e. if subtrahend is greater than minuend).\n",
      "  */\n",
      "  function sub(uint256 a, uint256 b) internal pure returns (uint256) {\n",
      "    assert(b <= a);\n",
      "    return a - b;\n",
      "  }\n",
      "\n",
      "  /**\n",
      "  * @dev Adds two numbers, throws on overflow.\n",
      "  */\n",
      "  function add(uint256 a, uint256 b) internal pure returns (uint256 c) {\n",
      "    c = a + b;\n",
      "    assert(c >= a);\n",
      "    return c;\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "contract ERC20Basic {\n",
      "    \n",
      "  function totalSupply() public view returns (uint256);\n",
      "  function balanceOf(address who) public view returns (uint256);\n",
      "  function transfer(address to, uint256 value) public returns (bool);\n",
      "  event Transfer(address indexed from, address indexed to, uint256 value);\n",
      "  \n",
      "}\n",
      "\n",
      "contract ERC20 is ERC20Basic {\n",
      "    \n",
      "  function allowance(address owner, address spender)\n",
      "    public view returns (uint256);\n",
      "\n",
      "  function transferFrom(address from, address to, uint256 value)\n",
      "    public returns (bool);\n",
      "\n",
      "  function approve(address spender, uint256 value) public returns (bool);\n",
      "  event Approval(\n",
      "    address indexed owner,\n",
      "    address indexed spender,\n",
      "    uint256 value\n",
      "  );\n",
      "}\n",
      "\n",
      "contract DetailedERC20 is ERC20 {\n",
      "  string public name;\n",
      "  string public symbol;\n",
      "  uint8 public decimals;\n",
      "\n",
      "  constructor(string _name, string _symbol, uint8 _decimals) public {\n",
      "    name = _name;\n",
      "    symbol = _symbol;\n",
      "    decimals = _decimals;\n",
      "  }\n",
      "}\n",
      "\n",
      "/**\n",
      " * @title 实现ERC20基本合约的接口 \n",
      " * @dev 基本的StandardToken，不包含allowances.\n",
      " */\n",
      "contract BasicToken is ERC20Basic {\n",
      "  using SafeMath for uint256;\n",
      "\n",
      "  mapping(address => uint256) balances;\n",
      "\n",
      "  uint256 totalSupply_;\n",
      "  \n",
      "  function totalSupply() public view returns (uint256) {\n",
      "    return totalSupply_;\n",
      "  }\n",
      "\n",
      "  function transfer(address _to, uint256 _value) public returns (bool) {\n",
      "    require(_to != address(0));\n",
      "    require(_value <= balances[msg.sender]);\n",
      "    balances[msg.sender] = balances[msg.sender].sub(_value);\n",
      "    balances[_to] = balances[_to].add(_value);\n",
      "    emit Transfer(msg.sender, _to, _value);\n",
      "    return true;\n",
      "  }\n",
      "\n",
      "  function balanceOf(address _owner) public view returns (uint256) {\n",
      "    return balances[_owner];\n",
      "  }\n",
      "\n",
      "}\n",
      "\n",
      "contract StandardToken is ERC20, BasicToken {\n",
      "  mapping (address => mapping (address => uint256)) internal allowed;\n",
      "\n",
      "  /**\n",
      "   * @dev 从一个地址向另外一个地址转token\n",
      "   * @param _from 转账的from地址\n",
      "   * @param _to address 转账的to地址\n",
      "   * @param _value uint256 转账token数量\n",
      "   */\n",
      "  function transferFrom(\n",
      "    address _from,\n",
      "    address _to,\n",
      "    uint256 _value\n",
      "  )\n",
      "    public\n",
      "    returns (bool)\n",
      "  {\n",
      "    // 做合法性检查\n",
      "    require(_to != address(0));\n",
      "    require(_value <= balances[_from]);\n",
      "    require(_value <= allowed[_from][msg.sender]);\n",
      "    balances[_from] = balances[_from].sub(_value);\n",
      "    balances[_to] = balances[_to].add(_value);\n",
      "    allowed[_from][msg.sender] = allowed[_from][msg.sender].sub(_value);\n",
      "    emit Transfer(_from, _to, _value);\n",
      "    return true;\n",
      "  }\n",
      "\n",
      "  function approve(address _spender, uint256 _value) public returns (bool) {\n",
      "    allowed[msg.sender][_spender] = _value;\n",
      "    emit Approval(msg.sender, _spender, _value);\n",
      "    return true;\n",
      "  }\n",
      "\n",
      "  function allowance(\n",
      "    address _owner,\n",
      "    address _spender\n",
      "   )\n",
      "    public\n",
      "    view\n",
      "    returns (uint256)\n",
      "  {\n",
      "    return allowed[_owner][_spender];\n",
      "  }\n",
      "\n",
      "}\n",
      "\n",
      "contract BurnableToken is BasicToken {\n",
      "\n",
      "  event Burn(address indexed burner, uint256 value);\n",
      "\n",
      "}\n",
      "\n",
      "contract MintableToken is StandardToken {\n",
      "  event Mint(address indexed to, uint256 amount);\n",
      "  event MintFinished();\n",
      "\n",
      "  bool public mintingFinished = false;\n",
      "\n",
      "\n",
      "  modifier canMint() {\n",
      "    require(!mintingFinished);\n",
      "    _;\n",
      "  }\n",
      "\n",
      "\n",
      "  /**\n",
      "   * @dev Function to stop minting new tokens.\n",
      "   * @return True if the operation was successful.\n",
      "   */\n",
      "  function finishMinting() public  canMint returns (bool) {\n",
      "    mintingFinished = true;\n",
      "    emit MintFinished();\n",
      "    return true;\n",
      "  }\n",
      "}\n",
      "\n",
      "contract StandardBurnableToken is BurnableToken, StandardToken,MintableToken {\n",
      "\n",
      "\n",
      "  \n",
      "}\n",
      "\n",
      "contract valuehometoken is StandardBurnableToken {\n",
      "    string public name = 'value home token';\n",
      "    string public symbol = 'VHT';\n",
      "    uint8 public decimals = 8;\n",
      "    uint256 public INITIAL_SUPPLY = 50000000000000000; \n",
      "    \n",
      "  constructor() public {\n",
      "    totalSupply_ = INITIAL_SUPPLY;\n",
      "    balances[msg.sender] = INITIAL_SUPPLY;\n",
      "  }\n",
      "\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(val_dataloader.dataset.data[5]['source_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a197bbb-f478-4e8f-bcc3-566df1c8bdc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m20180848/.conda/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/m20180848/.conda/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Initialized line feature extractor layer 1 with small random weights\n",
      "DEBUG: Initialized line feature extractor layer 3 with small random weights\n",
      "DEBUG: Initialized custom line feature extractor with small weights\n",
      "Model loaded from checkpoints_v5_2048_output/best_model_augmented_gan_epoch_106.pt\n",
      "Training epoch: 106\n",
      "Best validation loss: 0.773994717746973\n",
      "Training config: GAN=True\n",
      "🚀 Using threshold: 0.1\n",
      "🚀 Starting comprehensive validation analysis...\n",
      "📊 Processing 10 contracts...\n",
      "    Contract 0: actual_lines=90\n",
      "    Contract 0: pred_line_probs_array shape: (8, 1024)\n",
      "    Contract 0: pred_line_labels_array shape: (8, 1024)\n",
      "    Contract 0: found 4 vulnerable lines\n",
      "    Contract 1: actual_lines=101\n",
      "    Contract 1: pred_line_probs_array shape: (8, 1024)\n",
      "    Contract 1: pred_line_labels_array shape: (8, 1024)\n",
      "    Contract 1: found 7 vulnerable lines\n",
      "    Contract 2: actual_lines=88\n",
      "    Contract 2: pred_line_probs_array shape: (8, 1024)\n",
      "    Contract 2: pred_line_labels_array shape: (8, 1024)\n",
      "    Contract 2: found 5 vulnerable lines\n",
      "    Contract 3: actual_lines=153\n",
      "    Contract 3: pred_line_probs_array shape: (8, 1024)\n",
      "    Contract 3: pred_line_labels_array shape: (8, 1024)\n",
      "    Contract 3: found 4 vulnerable lines\n",
      "    Contract 4: actual_lines=85\n",
      "    Contract 4: pred_line_probs_array shape: (8, 1024)\n",
      "    Contract 4: pred_line_labels_array shape: (8, 1024)\n",
      "    Contract 4: found 2 vulnerable lines\n",
      "    Contract 5: actual_lines=211\n",
      "    Contract 5: pred_line_probs_array shape: (8, 1024)\n",
      "    Contract 5: pred_line_labels_array shape: (8, 1024)\n",
      "    Contract 5: found 5 vulnerable lines\n",
      "    Contract 6: actual_lines=79\n",
      "    Contract 6: pred_line_probs_array shape: (8, 1024)\n",
      "    Contract 6: pred_line_labels_array shape: (8, 1024)\n",
      "    Contract 6: found 1 vulnerable lines\n",
      "    Contract 7: actual_lines=81\n",
      "    Contract 7: pred_line_probs_array shape: (8, 1024)\n",
      "    Contract 7: pred_line_labels_array shape: (8, 1024)\n",
      "    Contract 7: found 5 vulnerable lines\n",
      "    Contract 8: actual_lines=157\n",
      "    Contract 8: pred_line_probs_array shape: (8, 1024)\n",
      "    Contract 8: pred_line_labels_array shape: (8, 1024)\n",
      "    Contract 8: found 5 vulnerable lines\n",
      "  ✅ Processed 10/10 contracts\n",
      "    Contract 9: actual_lines=55\n",
      "    Contract 9: pred_line_probs_array shape: (8, 1024)\n",
      "    Contract 9: pred_line_labels_array shape: (8, 1024)\n",
      "    Contract 9: found 4 vulnerable lines\n",
      "✅ Validation analysis completed!\n",
      "📊 Processed 10 contracts\n",
      "⏱️  Processing time: 0.84 seconds\n",
      "🎯 Generation success rate: 0.00%\n",
      "🔍 Analyzing line positions with threshold 0.1...\n",
      "\n",
      "================================================================================\n",
      "📊 LINE POSITION ANALYSIS (THRESHOLD 0.1)\n",
      "================================================================================\n",
      "\n",
      "📈 Overall Statistics:\n",
      "  Total Contracts: 10\n",
      "  Total True Vulnerable Lines: 42\n",
      "  Total Detected Vulnerable Lines: 2132\n",
      "  Total Correctly Detected Lines: 42\n",
      "  Overall Recall: 100.00%\n",
      "  Overall Precision: 1.97%\n",
      "\n",
      "🔍 LINE POSITIONS BY CONTRACT:\n",
      "================================================================================\n",
      "\n",
      "📋 Contract: Contract_0\n",
      "  Overall: TRUE=4, PREDICTED=78, CORRECT=4\n",
      "  ARTHM:\n",
      "    TRUE: [4, 5, 19]\n",
      "    PREDICTED: [4, 5, 19, 52, 81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
      "    CORRECT: [19, 4, 5]\n",
      "    Counts: TRUE=3, PREDICTED=13, CORRECT=3\n",
      "  DOS:\n",
      "    TRUE: []\n",
      "    PREDICTED: [81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=9, CORRECT=0\n",
      "  LE:\n",
      "    TRUE: []\n",
      "    PREDICTED: [81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=9, CORRECT=0\n",
      "  RENT:\n",
      "    TRUE: []\n",
      "    PREDICTED: [81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=9, CORRECT=0\n",
      "  TimeM:\n",
      "    TRUE: [58]\n",
      "    PREDICTED: [57, 58, 81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
      "    CORRECT: [58]\n",
      "    Counts: TRUE=1, PREDICTED=11, CORRECT=1\n",
      "  TimeO:\n",
      "    TRUE: []\n",
      "    PREDICTED: [81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=9, CORRECT=0\n",
      "  Tx-Origin:\n",
      "    TRUE: []\n",
      "    PREDICTED: [81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=9, CORRECT=0\n",
      "  UE:\n",
      "    TRUE: []\n",
      "    PREDICTED: [81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=9, CORRECT=0\n",
      "\n",
      "📋 Contract: Contract_1\n",
      "  Overall: TRUE=7, PREDICTED=241, CORRECT=7\n",
      "  ARTHM:\n",
      "    TRUE: [29, 30, 41, 55, 76, 87, 97]\n",
      "    PREDICTED: [28, 29, 30, 31, 41, 42, 50, 53, 54, 55, 56, 57, 58, 62, 64, 69, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
      "    CORRECT: [97, 41, 76, 87, 55, 29, 30]\n",
      "    Counts: TRUE=7, PREDICTED=44, CORRECT=7\n",
      "  DOS:\n",
      "    TRUE: []\n",
      "    PREDICTED: [73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=28, CORRECT=0\n",
      "  LE:\n",
      "    TRUE: []\n",
      "    PREDICTED: [73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=28, CORRECT=0\n",
      "  RENT:\n",
      "    TRUE: []\n",
      "    PREDICTED: [73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=28, CORRECT=0\n",
      "  TimeM:\n",
      "    TRUE: []\n",
      "    PREDICTED: [57, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=29, CORRECT=0\n",
      "  TimeO:\n",
      "    TRUE: []\n",
      "    PREDICTED: [73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=28, CORRECT=0\n",
      "  Tx-Origin:\n",
      "    TRUE: []\n",
      "    PREDICTED: [73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=28, CORRECT=0\n",
      "  UE:\n",
      "    TRUE: []\n",
      "    PREDICTED: [73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=28, CORRECT=0\n",
      "\n",
      "📋 Contract: Contract_2\n",
      "  Overall: TRUE=5, PREDICTED=51, CORRECT=5\n",
      "  ARTHM:\n",
      "    TRUE: [5, 6, 75, 79, 82]\n",
      "    PREDICTED: [5, 6, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87]\n",
      "    CORRECT: [5, 6, 75, 79, 82]\n",
      "    Counts: TRUE=5, PREDICTED=16, CORRECT=5\n",
      "  DOS:\n",
      "    TRUE: []\n",
      "    PREDICTED: [83, 84, 85, 86, 87]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=5, CORRECT=0\n",
      "  LE:\n",
      "    TRUE: []\n",
      "    PREDICTED: [83, 84, 85, 86, 87]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=5, CORRECT=0\n",
      "  RENT:\n",
      "    TRUE: []\n",
      "    PREDICTED: [83, 84, 85, 86, 87]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=5, CORRECT=0\n",
      "  TimeM:\n",
      "    TRUE: []\n",
      "    PREDICTED: [83, 84, 85, 86, 87]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=5, CORRECT=0\n",
      "  TimeO:\n",
      "    TRUE: []\n",
      "    PREDICTED: [83, 84, 85, 86, 87]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=5, CORRECT=0\n",
      "  Tx-Origin:\n",
      "    TRUE: []\n",
      "    PREDICTED: [83, 84, 85, 86, 87]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=5, CORRECT=0\n",
      "  UE:\n",
      "    TRUE: []\n",
      "    PREDICTED: [83, 84, 85, 86, 87]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=5, CORRECT=0\n",
      "\n",
      "📋 Contract: Contract_3\n",
      "  Overall: TRUE=4, PREDICTED=440, CORRECT=4\n",
      "  ARTHM:\n",
      "    TRUE: [74, 79, 80, 99]\n",
      "    PREDICTED: [30, 60, 74, 75, 76, 79, 80, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152]\n",
      "    CORRECT: [80, 74, 99, 79]\n",
      "    Counts: TRUE=4, PREDICTED=62, CORRECT=4\n",
      "  DOS:\n",
      "    TRUE: []\n",
      "    PREDICTED: [99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=54, CORRECT=0\n",
      "  LE:\n",
      "    TRUE: []\n",
      "    PREDICTED: [99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=54, CORRECT=0\n",
      "  RENT:\n",
      "    TRUE: []\n",
      "    PREDICTED: [99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=54, CORRECT=0\n",
      "  TimeM:\n",
      "    TRUE: []\n",
      "    PREDICTED: [99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=54, CORRECT=0\n",
      "  TimeO:\n",
      "    TRUE: []\n",
      "    PREDICTED: [99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=54, CORRECT=0\n",
      "  Tx-Origin:\n",
      "    TRUE: []\n",
      "    PREDICTED: [99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=54, CORRECT=0\n",
      "  UE:\n",
      "    TRUE: []\n",
      "    PREDICTED: [99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=54, CORRECT=0\n",
      "\n",
      "📋 Contract: Contract_4\n",
      "  Overall: TRUE=2, PREDICTED=107, CORRECT=2\n",
      "  ARTHM:\n",
      "    TRUE: [36, 37]\n",
      "    PREDICTED: [36, 37, 38, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84]\n",
      "    CORRECT: [36, 37]\n",
      "    Counts: TRUE=2, PREDICTED=16, CORRECT=2\n",
      "  DOS:\n",
      "    TRUE: []\n",
      "    PREDICTED: [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=13, CORRECT=0\n",
      "  LE:\n",
      "    TRUE: []\n",
      "    PREDICTED: [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=13, CORRECT=0\n",
      "  RENT:\n",
      "    TRUE: []\n",
      "    PREDICTED: [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=13, CORRECT=0\n",
      "  TimeM:\n",
      "    TRUE: []\n",
      "    PREDICTED: [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=13, CORRECT=0\n",
      "  TimeO:\n",
      "    TRUE: []\n",
      "    PREDICTED: [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=13, CORRECT=0\n",
      "  Tx-Origin:\n",
      "    TRUE: []\n",
      "    PREDICTED: [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=13, CORRECT=0\n",
      "  UE:\n",
      "    TRUE: []\n",
      "    PREDICTED: [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=13, CORRECT=0\n",
      "\n",
      "📋 Contract: Contract_5\n",
      "  Overall: TRUE=5, PREDICTED=715, CORRECT=5\n",
      "  ARTHM:\n",
      "    TRUE: [43, 201, 202, 207, 208]\n",
      "    PREDICTED: [18, 43, 44, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210]\n",
      "    CORRECT: [201, 202, 43, 207, 208]\n",
      "    Counts: TRUE=5, PREDICTED=92, CORRECT=5\n",
      "  DOS:\n",
      "    TRUE: []\n",
      "    PREDICTED: [122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=89, CORRECT=0\n",
      "  LE:\n",
      "    TRUE: []\n",
      "    PREDICTED: [122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=89, CORRECT=0\n",
      "  RENT:\n",
      "    TRUE: []\n",
      "    PREDICTED: [122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=89, CORRECT=0\n",
      "  TimeM:\n",
      "    TRUE: []\n",
      "    PREDICTED: [122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=89, CORRECT=0\n",
      "  TimeO:\n",
      "    TRUE: []\n",
      "    PREDICTED: [122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=89, CORRECT=0\n",
      "  Tx-Origin:\n",
      "    TRUE: []\n",
      "    PREDICTED: [122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=89, CORRECT=0\n",
      "  UE:\n",
      "    TRUE: []\n",
      "    PREDICTED: [122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=89, CORRECT=0\n",
      "\n",
      "📋 Contract: Contract_6\n",
      "  Overall: TRUE=1, PREDICTED=1, CORRECT=1\n",
      "  ARTHM:\n",
      "    TRUE: [20]\n",
      "    PREDICTED: [20]\n",
      "    CORRECT: [20]\n",
      "    Counts: TRUE=1, PREDICTED=1, CORRECT=1\n",
      "\n",
      "📋 Contract: Contract_7\n",
      "  Overall: TRUE=5, PREDICTED=13, CORRECT=5\n",
      "  ARTHM:\n",
      "    TRUE: [21, 22, 23, 49, 63]\n",
      "    PREDICTED: [21, 22, 23, 33, 37, 48, 49, 56, 57, 61, 63, 64]\n",
      "    CORRECT: [49, 21, 22, 23, 63]\n",
      "    Counts: TRUE=5, PREDICTED=12, CORRECT=5\n",
      "  DOS:\n",
      "    TRUE: []\n",
      "    PREDICTED: [74]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=1, CORRECT=0\n",
      "\n",
      "📋 Contract: Contract_8\n",
      "  Overall: TRUE=5, PREDICTED=482, CORRECT=5\n",
      "  ARTHM:\n",
      "    TRUE: [83, 84, 103, 141, 142]\n",
      "    PREDICTED: [83, 84, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156]\n",
      "    CORRECT: [103, 141, 142, 83, 84]\n",
      "    Counts: TRUE=5, PREDICTED=62, CORRECT=5\n",
      "  DOS:\n",
      "    TRUE: []\n",
      "    PREDICTED: [97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=60, CORRECT=0\n",
      "  LE:\n",
      "    TRUE: []\n",
      "    PREDICTED: [97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=60, CORRECT=0\n",
      "  RENT:\n",
      "    TRUE: []\n",
      "    PREDICTED: [97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=60, CORRECT=0\n",
      "  TimeM:\n",
      "    TRUE: []\n",
      "    PREDICTED: [97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=60, CORRECT=0\n",
      "  TimeO:\n",
      "    TRUE: []\n",
      "    PREDICTED: [97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=60, CORRECT=0\n",
      "  Tx-Origin:\n",
      "    TRUE: []\n",
      "    PREDICTED: [97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=60, CORRECT=0\n",
      "  UE:\n",
      "    TRUE: []\n",
      "    PREDICTED: [97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156]\n",
      "    CORRECT: []\n",
      "    Counts: TRUE=0, PREDICTED=60, CORRECT=0\n",
      "\n",
      "📋 Contract: Contract_9\n",
      "  Overall: TRUE=4, PREDICTED=4, CORRECT=4\n",
      "  ARTHM:\n",
      "    TRUE: [7, 8, 24, 50]\n",
      "    PREDICTED: [7, 8, 24, 50]\n",
      "    CORRECT: [8, 24, 50, 7]\n",
      "    Counts: TRUE=4, PREDICTED=4, CORRECT=4\n",
      "\n",
      "✅ Results saved to: line_positions_threshold_0.1.json\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from notebook_utils import (\n",
    "    collect_validation_results,\n",
    "    compute_contract_level_metrics,\n",
    "    compute_line_level_metrics\n",
    ")\n",
    "from inference import SmartContractAnalyzer\n",
    "\n",
    "def get_line_positions(validation_results, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Get line positions of vulnerable lines in array format.\n",
    "    \"\"\"\n",
    "    print(f\"🔍 Analyzing line positions with threshold {threshold}...\")\n",
    "    \n",
    "    line_positions = {\n",
    "        'contracts': [],\n",
    "        'summary': {\n",
    "            'total_contracts': len(validation_results['line_level']['true_labels']),\n",
    "            'total_true_vulnerable_lines': 0,\n",
    "            'total_detected_vulnerable_lines': 0,\n",
    "            'total_correct_detections': 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    vuln_types = validation_results['metadata']['vulnerability_types']\n",
    "    \n",
    "    for contract_idx in range(len(validation_results['line_level']['true_labels'])):\n",
    "        try:\n",
    "            # Get data for this contract\n",
    "            true_labels = validation_results['line_level']['true_labels'][contract_idx]  # Shape: (8, 1024)\n",
    "            pred_labels = validation_results['line_level']['predicted_labels'][contract_idx]  # Shape: (8, 1024)\n",
    "            \n",
    "            # Get source code lines\n",
    "            if contract_idx < len(validation_results['line_level']['line_mappings']):\n",
    "                source_lines = validation_results['line_level']['line_mappings'][contract_idx]\n",
    "            else:\n",
    "                source_lines = [f\"Line {i}\" for i in range(1024)]\n",
    "            \n",
    "            contract_name = validation_results['contract_level']['contract_names'][contract_idx]\n",
    "            \n",
    "            # Analyze each vulnerability type\n",
    "            vuln_positions = {}\n",
    "            \n",
    "            for vuln_idx, vuln_type in enumerate(vuln_types):\n",
    "                if vuln_idx < true_labels.shape[0]:\n",
    "                    # Get true and predicted vulnerabilities for this type\n",
    "                    true_vulns = true_labels[vuln_idx, :]  # Shape: (1024,)\n",
    "                    pred_vulns = pred_labels[vuln_idx, :]  # Shape: (1024,)\n",
    "                    \n",
    "                    # Find true vulnerable line positions\n",
    "                    true_positions = []\n",
    "                    for line_idx in range(min(len(source_lines), 1024)):\n",
    "                        if true_vulns[line_idx] == 1:\n",
    "                            true_positions.append(line_idx)\n",
    "                    \n",
    "                    # Find detected vulnerable line positions\n",
    "                    detected_positions = []\n",
    "                    for line_idx in range(min(len(source_lines), 1024)):\n",
    "                        if pred_vulns[line_idx] == 1:\n",
    "                            detected_positions.append(line_idx)\n",
    "                    \n",
    "                    # Find correctly detected positions (intersection)\n",
    "                    correct_positions = list(set(true_positions) & set(detected_positions))\n",
    "                    \n",
    "                    vuln_positions[vuln_type] = {\n",
    "                        'TRUE': true_positions,\n",
    "                        'PREDICTED': detected_positions,\n",
    "                        'CORRECT': correct_positions,\n",
    "                        'counts': {\n",
    "                            'true_count': len(true_positions),\n",
    "                            'predicted_count': len(detected_positions),\n",
    "                            'correct_count': len(correct_positions)\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    # Update summary\n",
    "                    line_positions['summary']['total_true_vulnerable_lines'] += len(true_positions)\n",
    "                    line_positions['summary']['total_detected_vulnerable_lines'] += len(detected_positions)\n",
    "                    line_positions['summary']['total_correct_detections'] += len(correct_positions)\n",
    "            \n",
    "            # Store contract analysis\n",
    "            contract_analysis = {\n",
    "                'contract_name': contract_name,\n",
    "                'contract_idx': contract_idx,\n",
    "                'vulnerability_positions': vuln_positions,\n",
    "                'overall_summary': {\n",
    "                    'total_true_lines': sum(vuln_positions[vuln]['counts']['true_count'] for vuln in vuln_positions),\n",
    "                    'total_predicted_lines': sum(vuln_positions[vuln]['counts']['predicted_count'] for vuln in vuln_positions),\n",
    "                    'total_correct_lines': sum(vuln_positions[vuln]['counts']['correct_count'] for vuln in vuln_positions)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            line_positions['contracts'].append(contract_analysis)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠️  Error analyzing contract {contract_idx}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return line_positions\n",
    "\n",
    "# Initialize analyzer with latest checkpoint\n",
    "analyzer = SmartContractAnalyzer(\n",
    "    model_path=MODEL_PATH,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    use_gan=True\n",
    ")\n",
    "\n",
    "# Step 1: Collect validation results with specific threshold\n",
    "threshold = 0.1  # You can change this to any threshold you want\n",
    "print(f\"🚀 Using threshold: {threshold}\")\n",
    "\n",
    "validation_results = collect_validation_results(\n",
    "    analyzer=analyzer,\n",
    "    val_dataloader=val_dataloader,\n",
    "    threshold=threshold,\n",
    "    max_contracts=10,\n",
    "    generate_contracts=False  # Skip generation for speed\n",
    ")\n",
    "\n",
    "# Step 2: Get line positions\n",
    "line_positions = get_line_positions(validation_results, threshold=threshold)\n",
    "\n",
    "# Step 3: Print results in clean array format\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"📊 LINE POSITION ANALYSIS (THRESHOLD {threshold})\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary = line_positions['summary']\n",
    "print(f\"\\n📈 Overall Statistics:\")\n",
    "print(f\"  Total Contracts: {summary['total_contracts']}\")\n",
    "print(f\"  Total True Vulnerable Lines: {summary['total_true_vulnerable_lines']}\")\n",
    "print(f\"  Total Detected Vulnerable Lines: {summary['total_detected_vulnerable_lines']}\")\n",
    "print(f\"  Total Correctly Detected Lines: {summary['total_correct_detections']}\")\n",
    "\n",
    "if summary['total_true_vulnerable_lines'] > 0:\n",
    "    recall = summary['total_correct_detections'] / summary['total_true_vulnerable_lines']\n",
    "    print(f\"  Overall Recall: {recall:.2%}\")\n",
    "\n",
    "if summary['total_detected_vulnerable_lines'] > 0:\n",
    "    precision = summary['total_correct_detections'] / summary['total_detected_vulnerable_lines']\n",
    "    print(f\"  Overall Precision: {precision:.2%}\")\n",
    "\n",
    "print(f\"\\n🔍 LINE POSITIONS BY CONTRACT:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for contract in line_positions['contracts']:\n",
    "    print(f\"\\n📋 Contract: {contract['contract_name']}\")\n",
    "    print(f\"  Overall: TRUE={contract['overall_summary']['total_true_lines']}, \"\n",
    "          f\"PREDICTED={contract['overall_summary']['total_predicted_lines']}, \"\n",
    "          f\"CORRECT={contract['overall_summary']['total_correct_lines']}\")\n",
    "    \n",
    "    for vuln_type, positions in contract['vulnerability_positions'].items():\n",
    "        true_count = positions['counts']['true_count']\n",
    "        predicted_count = positions['counts']['predicted_count']\n",
    "        correct_count = positions['counts']['correct_count']\n",
    "        \n",
    "        if true_count > 0 or predicted_count > 0:\n",
    "            print(f\"  {vuln_type}:\")\n",
    "            print(f\"    TRUE: {positions['TRUE']}\")\n",
    "            print(f\"    PREDICTED: {positions['PREDICTED']}\")\n",
    "            print(f\"    CORRECT: {positions['CORRECT']}\")\n",
    "            print(f\"    Counts: TRUE={true_count}, PREDICTED={predicted_count}, CORRECT={correct_count}\")\n",
    "\n",
    "# Step 4: Save results\n",
    "import json\n",
    "\n",
    "json_results = {\n",
    "    'threshold': threshold,\n",
    "    'summary': line_positions['summary'],\n",
    "    'contracts': [\n",
    "        {\n",
    "            'contract_name': contract['contract_name'],\n",
    "            'contract_idx': contract['contract_idx'],\n",
    "            'overall_summary': contract['overall_summary'],\n",
    "            'vulnerability_positions': contract['vulnerability_positions']\n",
    "        }\n",
    "        for contract in line_positions['contracts']\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(f'line_positions_threshold_{threshold}.json', 'w') as f:\n",
    "    json.dump(json_results, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Results saved to: line_positions_threshold_{threshold}.json\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34be462a-9a44-45b9-adcb-e159d460a9e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Debugging line predictions for contract 0...\n",
      "📊 Contract 0 shapes:\n",
      "  True labels: (8, 1024)\n",
      "  Pred labels: (8, 1024)\n",
      "  Pred probs: (8, 1024)\n",
      "📏 Actual lines in contract: 90\n",
      "\n",
      "🔍 Vulnerability Analysis:\n",
      "  ARTHM:\n",
      "    True vulnerable lines: 3\n",
      "    Predicted vulnerable lines: 0.0\n",
      "    Max probability: 0.0000\n",
      "    Min probability: 0.0000\n",
      "    Mean probability: 0.0000\n",
      "    Vulnerable line indices: [ 4  5 19]\n",
      "      Line 4: prob=0.0000, pred=0.0\n",
      "      Line 5: prob=0.0000, pred=0.0\n",
      "      Line 19: prob=0.0000, pred=0.0\n",
      "  DOS:\n",
      "    True vulnerable lines: 0\n",
      "    Predicted vulnerable lines: 0.0\n",
      "    Max probability: 0.0000\n",
      "    Min probability: 0.0000\n",
      "    Mean probability: 0.0000\n",
      "  LE:\n",
      "    True vulnerable lines: 0\n",
      "    Predicted vulnerable lines: 0.0\n",
      "    Max probability: 0.0000\n",
      "    Min probability: 0.0000\n",
      "    Mean probability: 0.0000\n",
      "  RENT:\n",
      "    True vulnerable lines: 0\n",
      "    Predicted vulnerable lines: 0.0\n",
      "    Max probability: 0.0000\n",
      "    Min probability: 0.0000\n",
      "    Mean probability: 0.0000\n",
      "  TimeM:\n",
      "    True vulnerable lines: 1\n",
      "    Predicted vulnerable lines: 0.0\n",
      "    Max probability: 0.0000\n",
      "    Min probability: 0.0000\n",
      "    Mean probability: 0.0000\n",
      "    Vulnerable line indices: [58]\n",
      "      Line 58: prob=0.0000, pred=0.0\n",
      "  TimeO:\n",
      "    True vulnerable lines: 0\n",
      "    Predicted vulnerable lines: 0.0\n",
      "    Max probability: 0.0000\n",
      "    Min probability: 0.0000\n",
      "    Mean probability: 0.0000\n",
      "  Tx-Origin:\n",
      "    True vulnerable lines: 0\n",
      "    Predicted vulnerable lines: 0.0\n",
      "    Max probability: 0.0000\n",
      "    Min probability: 0.0000\n",
      "    Mean probability: 0.0000\n",
      "  UE:\n",
      "    True vulnerable lines: 0\n",
      "    Predicted vulnerable lines: 0.0\n",
      "    Max probability: 0.0000\n",
      "    Min probability: 0.0000\n",
      "    Mean probability: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from notebook_utils import (\n",
    "    debug_line_predictions,\n",
    "    analyze_vulnerable_line_probabilities,\n",
    "    check_model_line_predictions,\n",
    "    print_probability_analysis\n",
    ")\n",
    "\n",
    "debug_line_predictions(validation_results, contract_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6a1773f-cb86-4e1a-937d-7c730b7fdd6b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Analyzing probability scores for vulnerable lines...\n",
      "✅ Probability analysis completed!\n",
      "================================================================================\n",
      "📊 VULNERABLE LINE PROBABILITY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "📈 Overall Statistics:\n",
      "  Total Vulnerable Lines: 42\n",
      "  Mean Probability (Vulnerable Lines): 0.0000\n",
      "  Mean Probability (All Lines): 0.0000\n",
      "\n",
      "🎯 Probability Distribution (Vulnerable Lines):\n",
      "  High Confidence (>0.8): 0 (0.0%)\n",
      "  Medium Confidence (0.5-0.8): 0 (0.0%)\n",
      "  Low Confidence (<0.5): 42 (100.0%)\n",
      "\n",
      "🔍 Per-Vulnerability Type Analysis:\n",
      "  ARTHM:\n",
      "    Vulnerable Lines: 41\n",
      "    Mean Probability (Vulnerable): 0.0000\n",
      "    Max Probability (Vulnerable): 0.0000\n",
      "    Min Probability (Vulnerable): 0.0000\n",
      "    Mean Probability (All Lines): 0.0000\n",
      "\n",
      "  DOS:\n",
      "    Vulnerable Lines: 0\n",
      "    Mean Probability (All Lines): 0.0000\n",
      "\n",
      "  LE:\n",
      "    Vulnerable Lines: 0\n",
      "    Mean Probability (All Lines): 0.0000\n",
      "\n",
      "  RENT:\n",
      "    Vulnerable Lines: 0\n",
      "    Mean Probability (All Lines): 0.0000\n",
      "\n",
      "  TimeM:\n",
      "    Vulnerable Lines: 1\n",
      "    Mean Probability (Vulnerable): 0.0000\n",
      "    Max Probability (Vulnerable): 0.0000\n",
      "    Min Probability (Vulnerable): 0.0000\n",
      "    Mean Probability (All Lines): 0.0000\n",
      "\n",
      "  TimeO:\n",
      "    Vulnerable Lines: 0\n",
      "    Mean Probability (All Lines): 0.0000\n",
      "\n",
      "  Tx-Origin:\n",
      "    Vulnerable Lines: 0\n",
      "    Mean Probability (All Lines): 0.0000\n",
      "\n",
      "  UE:\n",
      "    Vulnerable Lines: 0\n",
      "    Mean Probability (All Lines): 0.0000\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "prob_analysis = analyze_vulnerable_line_probabilities(validation_results)\n",
    "print_probability_analysis(prob_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7345e002-9b12-4341-8d7d-76224ff13713",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Testing model line-level predictions on sample contract...\n",
      "Contract vuln logits shape: torch.Size([1, 8])\n",
      "Line vuln logits shape: torch.Size([1, 1024, 8])\n",
      "Number of lines in contract: 90\n",
      "Contract predictions shape: (1, 8)\n",
      "Line predictions shape: (1, 1024, 8)\n",
      "📊 Model output keys: ['contract_vulnerabilities', 'line_vulnerabilities', 'contract_probabilities', 'line_probabilities']\n",
      "📋 Line vulnerabilities type: <class 'dict'>\n",
      "📋 Number of lines with predictions: 90\n",
      "  Line 0: {'ARTHM': False, 'DOS': False, 'LE': False, 'RENT': False, 'TimeM': False, 'TimeO': False, 'Tx-Origin': False, 'UE': False}\n",
      "  Line 1: {'ARTHM': False, 'DOS': False, 'LE': False, 'RENT': False, 'TimeM': False, 'TimeO': False, 'Tx-Origin': False, 'UE': False}\n",
      "  Line 2: {'ARTHM': False, 'DOS': False, 'LE': False, 'RENT': False, 'TimeM': False, 'TimeO': False, 'Tx-Origin': False, 'UE': False}\n",
      "  Line 3: {'ARTHM': False, 'DOS': False, 'LE': False, 'RENT': False, 'TimeM': False, 'TimeO': False, 'Tx-Origin': False, 'UE': False}\n",
      "  Line 4: {'ARTHM': False, 'DOS': False, 'LE': False, 'RENT': False, 'TimeM': False, 'TimeO': False, 'Tx-Origin': False, 'UE': False}\n",
      "📊 Line probabilities type: <class 'list'>\n",
      "📊 Number of line probability arrays: 1\n",
      "📊 First line probabilities shape: 1024\n",
      "📊 Sample probabilities: [[0.07996711879968643, 0.005272488109767437, 1.4614659704648147e-08, 2.886715492422809e-06, 0.012826386839151382, 0.00838454719632864, 1.4542585802246322e-08, 0.005261730402708054], [0.07996711879968643, 0.005272488109767437, 1.4614659704648147e-08, 2.886715492422809e-06, 0.012826386839151382, 0.00838454719632864, 1.4542585802246322e-08, 0.005261730402708054], [0.07996711879968643, 0.005272488109767437, 1.4614659704648147e-08, 2.886715492422809e-06, 0.012826386839151382, 0.00838454719632864, 1.4542585802246322e-08, 0.005261730402708054], [0.07996711879968643, 0.005272488109767437, 1.4614659704648147e-08, 2.886715492422809e-06, 0.012826386839151382, 0.00838454719632864, 1.4542585802246322e-08, 0.005261730402708054], [0.07996711879968643, 0.005272488109767437, 1.4614659704648147e-08, 2.886715492422809e-06, 0.012826386839151382, 0.00838454719632864, 1.4542585802246322e-08, 0.005261730402708054]]\n",
      "📋 Contract vulnerabilities: {'ARTHM': True, 'DOS': False, 'LE': False, 'RENT': False, 'TimeM': False, 'TimeO': False, 'Tx-Origin': False, 'UE': False}\n",
      "📊 Contract probabilities: [[0.6173984408378601, 0.43492990732192993, 0.44014403223991394, 0.49842485785484314, 0.4296608865261078, 0.4274321496486664, 0.021944785490632057, 0.4097830355167389]]\n"
     ]
    }
   ],
   "source": [
    "sample_contract = val_dataloader.dataset.data[0]['source_code']\n",
    "check_model_line_predictions(analyzer, sample_contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08450e1d-9fee-4d05-b322-51c226804e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataloader.dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92df8c42-24fe-42f7-ace7-221ba210ecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import Dict, List, Any, Tuple\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve, \n",
    "    roc_curve, \n",
    "    auc, \n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac78d09f-d9f7-4015-8922-f64b5a308ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_for_threshold(y_true: np.ndarray, y_pred: np.ndarray, y_probs: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute comprehensive metrics for a given threshold.\n",
    "    \n",
    "    Args:\n",
    "        y_true: True labels\n",
    "        y_pred: Predicted labels (binary)\n",
    "        y_probs: Predicted probabilities\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with computed metrics\n",
    "    \"\"\"\n",
    "    if len(y_true) == 0 or np.sum(y_true) == 0:\n",
    "        return {\n",
    "            'accuracy': 0.0,\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1_score': 0.0,\n",
    "            'pr_auc': 0.0,\n",
    "            'roc_auc': 0.0\n",
    "        }\n",
    "    \n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    # AUC metrics\n",
    "    try:\n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_probs)\n",
    "        pr_auc = auc(recall_curve, precision_curve)\n",
    "    except:\n",
    "        pr_auc = 0.0\n",
    "    \n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "    except:\n",
    "        roc_auc = 0.0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': float(accuracy),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'f1_score': float(f1),\n",
    "        'pr_auc': float(pr_auc),\n",
    "        'roc_auc': float(roc_auc)\n",
    "    }\n",
    "\n",
    "def evaluate_model_performance(\n",
    "    model_path: str,\n",
    "    val_dataloader: DataLoader,\n",
    "    contract_thresholds: Dict[str, float] = None,\n",
    "    line_thresholds: Dict[str, float] = None,\n",
    "    max_contracts: int = None,\n",
    "    output_file: str = \"comprehensive_evaluation_results.json\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation function that computes detailed performance metrics.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the trained model\n",
    "        val_dataloader: Validation dataloader\n",
    "        contract_thresholds: Dictionary of thresholds for each vulnerability type at contract level\n",
    "                           e.g., {'ARTHM': 0.2, 'DOS': 0.3, 'LE': 0.1, ...}\n",
    "        line_thresholds: Dictionary of thresholds for each vulnerability type at line level\n",
    "                        e.g., {'ARTHM': 0.2, 'DOS': 0.3, 'LE': 0.1, ...}\n",
    "        max_contracts: Maximum number of contracts to evaluate (None for all)\n",
    "        output_file: Output JSON file path\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with comprehensive evaluation results\n",
    "    \"\"\"\n",
    "    print(\"🚀 Starting comprehensive model evaluation...\")\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    print(\"🔧 Setting up analyzer...\")\n",
    "    analyzer = SmartContractAnalyzer(\n",
    "        model_path=model_path,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        use_gan=True\n",
    "    )\n",
    "    \n",
    "    # Set default thresholds if not provided\n",
    "    if contract_thresholds is None:\n",
    "        contract_thresholds = {vuln_type: 0.2 for vuln_type in analyzer.vulnerability_types}\n",
    "    if line_thresholds is None:\n",
    "        line_thresholds = {vuln_type: 0.2 for vuln_type in analyzer.vulnerability_types}\n",
    "    \n",
    "    print(f\"✅ Components initialized. Evaluating on {len(val_dataloader.dataset)} contracts\")\n",
    "    print(f\"📋 Contract thresholds: {contract_thresholds}\")\n",
    "    print(f\"📍 Line thresholds: {line_thresholds}\")\n",
    "    \n",
    "    # Results storage\n",
    "    results = {\n",
    "        'model_info': {\n",
    "            'model_path': model_path,\n",
    "            'contract_thresholds': contract_thresholds,\n",
    "            'line_thresholds': line_thresholds,\n",
    "            'total_contracts': len(val_dataloader.dataset),\n",
    "            'vulnerability_types': analyzer.vulnerability_types\n",
    "        },\n",
    "        'contract_level': {\n",
    "            'overall': {},\n",
    "            'per_vulnerability': {}\n",
    "        },\n",
    "        'line_level': {\n",
    "            'overall': {},\n",
    "            'per_vulnerability': {},\n",
    "            'statistics': {\n",
    "                'total_lines_processed': 0,\n",
    "                'total_lines_with_vulnerabilities': 0,\n",
    "                'total_lines_predicted_vulnerable': 0,\n",
    "                'per_vulnerability': {}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Collect validation results with the specified thresholds\n",
    "    print(f\"\\n📊 Collecting validation results...\")\n",
    "    \n",
    "    # We need to collect results for each vulnerability type with its specific threshold\n",
    "    # This requires multiple passes through the data\n",
    "    contract_true_all = []\n",
    "    contract_pred_all = []\n",
    "    contract_probs_all = []\n",
    "    \n",
    "    line_true_all = []\n",
    "    line_pred_all = []\n",
    "    line_probs_all = []\n",
    "    \n",
    "    # Process each contract\n",
    "    total_contracts = len(val_dataloader.dataset) if max_contracts is None else min(max_contracts, len(val_dataloader.dataset))\n",
    "    \n",
    "    for contract_idx in range(total_contracts):\n",
    "        try:\n",
    "            # Get contract data\n",
    "            contract_data = val_dataloader.dataset.data[contract_idx]\n",
    "            source_code = contract_data['source_code']\n",
    "            true_contract_vulns = contract_data['contract_vulnerabilities'].cpu().numpy()\n",
    "            true_line_vulns = contract_data['vulnerable_lines'].cpu().numpy()  # Shape: (8, 1024)\n",
    "            \n",
    "            # Get vulnerability predictions using the regular method\n",
    "            try:\n",
    "                analyzer_results = analyzer.detect_vulnerabilities(\n",
    "                    source_code, \n",
    "                    threshold=0.0  # Use 0.0 to get all probabilities, then apply thresholds later\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"    Error in detect_vulnerabilities for contract {contract_idx}: {str(e)}\")\n",
    "                continue\n",
    "            \n",
    "            # Extract predictions\n",
    "            pred_contract_vulns = analyzer_results['contract_vulnerabilities']\n",
    "            pred_line_vulns = analyzer_results['line_vulnerabilities']\n",
    "            pred_contract_probs = analyzer_results['contract_probabilities']\n",
    "            pred_line_probs = analyzer_results['line_probabilities']\n",
    "            \n",
    "            # Debug: Print structure of pred_line_probs\n",
    "            if contract_idx == 0:  # Only for first contract to avoid spam\n",
    "                print(f\"🔍 DEBUG: pred_line_probs structure:\")\n",
    "                print(f\"  Type: {type(pred_line_probs)}\")\n",
    "                print(f\"  Length: {len(pred_line_probs)}\")\n",
    "                if len(pred_line_probs) > 0:\n",
    "                    print(f\"  pred_line_probs[0] type: {type(pred_line_probs[0])}\")\n",
    "                    print(f\"  pred_line_probs[0] length: {len(pred_line_probs[0])}\")\n",
    "                    if len(pred_line_probs[0]) > 0:\n",
    "                        print(f\"  pred_line_probs[0][0] type: {type(pred_line_probs[0][0])}\")\n",
    "                        print(f\"  pred_line_probs[0][0] length: {len(pred_line_probs[0][0])}\")\n",
    "                        print(f\"  Sample values: {pred_line_probs[0][0][:5]}\")\n",
    "            \n",
    "            # Process contract-level predictions with specific thresholds\n",
    "            contract_pred = np.zeros(len(analyzer.vulnerability_types))\n",
    "            contract_probs = np.zeros(len(analyzer.vulnerability_types))\n",
    "            \n",
    "            for vuln_idx, vuln_type in enumerate(analyzer.vulnerability_types):\n",
    "                if vuln_idx < len(pred_contract_probs[0]):\n",
    "                    prob = pred_contract_probs[0][vuln_idx]\n",
    "                    contract_probs[vuln_idx] = prob\n",
    "                    # Apply specific threshold for this vulnerability type\n",
    "                    contract_pred[vuln_idx] = 1 if prob > contract_thresholds[vuln_type] else 0\n",
    "            \n",
    "            contract_true_all.append(true_contract_vulns)\n",
    "            contract_pred_all.append(contract_pred)\n",
    "            contract_probs_all.append(contract_probs)\n",
    "            \n",
    "            # Process line-level predictions with specific thresholds\n",
    "            lines = source_code.split('\\n')\n",
    "            actual_lines = len(lines)\n",
    "            \n",
    "            # Only process actual lines in the contract, not the full 1024\n",
    "            line_pred = np.zeros((len(analyzer.vulnerability_types), actual_lines))\n",
    "            line_probs = np.zeros((len(analyzer.vulnerability_types), actual_lines))\n",
    "            \n",
    "            # Handle the 3D structure of pred_line_probs: [batch][lines][vulnerabilities]\n",
    "            # pred_line_probs is a list of shape [1][num_lines][num_vulnerabilities]\n",
    "            if len(pred_line_probs) > 0 and len(pred_line_probs[0]) > 0:\n",
    "                # pred_line_probs[0] has shape [num_lines][num_vulnerabilities]\n",
    "                for line_idx in range(min(actual_lines, len(pred_line_probs[0]))):\n",
    "                    for vuln_idx, vuln_type in enumerate(analyzer.vulnerability_types):\n",
    "                        if vuln_idx < len(pred_line_probs[0][line_idx]):\n",
    "                            prob = pred_line_probs[0][line_idx][vuln_idx]\n",
    "                            line_probs[vuln_idx, line_idx] = prob\n",
    "                            \n",
    "                            # Filter out empty lines (probability 0.5000) and apply specific threshold\n",
    "                            if prob != 0.5000:  # Not an empty line\n",
    "                                line_pred[vuln_idx, line_idx] = 1 if prob > line_thresholds[vuln_type] else 0\n",
    "                            else:\n",
    "                                # Empty line - set prediction to 0 regardless of threshold\n",
    "                                line_pred[vuln_idx, line_idx] = 0\n",
    "            \n",
    "            # Truncate true line vulnerabilities to match actual lines\n",
    "            true_line_vulns_actual = true_line_vulns[:, :actual_lines] if true_line_vulns.shape[1] > actual_lines else true_line_vulns\n",
    "            line_true_all.append(true_line_vulns_actual)\n",
    "            line_pred_all.append(line_pred)\n",
    "            line_probs_all.append(line_probs)\n",
    "            \n",
    "            if (contract_idx + 1) % 10 == 0:\n",
    "                print(f\"  ✅ Processed {contract_idx + 1}/{total_contracts} contracts\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠️  Error processing contract {contract_idx}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    contract_true_all = np.array(contract_true_all)\n",
    "    contract_pred_all = np.array(contract_pred_all)\n",
    "    contract_probs_all = np.array(contract_probs_all)\n",
    "    \n",
    "    # Handle variable-length line arrays by flattening them\n",
    "    # Since each contract has different number of lines, we need to flatten the results\n",
    "    line_true_flat = []\n",
    "    line_pred_flat = []\n",
    "    line_probs_flat = []\n",
    "    \n",
    "    for i in range(len(line_true_all)):\n",
    "        # Flatten each contract's line data\n",
    "        for vuln_idx in range(line_true_all[i].shape[0]):\n",
    "            for line_idx in range(line_true_all[i].shape[1]):\n",
    "                line_true_flat.append(line_true_all[i][vuln_idx, line_idx])\n",
    "                line_pred_flat.append(line_pred_all[i][vuln_idx, line_idx])\n",
    "                line_probs_flat.append(line_probs_all[i][vuln_idx, line_idx])\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    line_true_flat = np.array(line_true_flat)\n",
    "    line_pred_flat = np.array(line_pred_flat)\n",
    "    line_probs_flat = np.array(line_probs_flat)\n",
    "    \n",
    "    print(f\"✅ Collected data for {len(contract_true_all)} contracts\")\n",
    "    \n",
    "    # Calculate line-level statistics using flattened arrays\n",
    "    total_lines_processed = len(line_true_flat)  # Total number of line-vulnerability combinations\n",
    "    total_lines_with_vulnerabilities = np.sum(line_true_flat > 0)  # Lines that actually have vulnerabilities\n",
    "    total_lines_predicted_vulnerable = np.sum(line_pred_flat > 0)  # Lines predicted as vulnerable\n",
    "    \n",
    "    # Store statistics\n",
    "    results['line_level']['statistics']['total_lines_processed'] = int(total_lines_processed)\n",
    "    results['line_level']['statistics']['total_lines_with_vulnerabilities'] = int(total_lines_with_vulnerabilities)\n",
    "    results['line_level']['statistics']['total_lines_predicted_vulnerable'] = int(total_lines_predicted_vulnerable)\n",
    "    \n",
    "    # Per-vulnerability statistics - need to reconstruct from flattened data\n",
    "    # We need to track which vulnerability type each flattened element belongs to\n",
    "    vuln_type_counts = {}\n",
    "    vuln_type_vulnerable_counts = {}\n",
    "    vuln_type_predicted_counts = {}\n",
    "    \n",
    "    # Initialize counters\n",
    "    for vuln_type in analyzer.vulnerability_types:\n",
    "        vuln_type_counts[vuln_type] = 0\n",
    "        vuln_type_vulnerable_counts[vuln_type] = 0\n",
    "        vuln_type_predicted_counts[vuln_type] = 0\n",
    "    \n",
    "    # Count per vulnerability type from the flattened data\n",
    "    # Since we flattened by contract -> vulnerability -> line, we need to reconstruct\n",
    "    current_idx = 0\n",
    "    for contract_idx in range(len(line_true_all)):\n",
    "        for vuln_idx in range(line_true_all[contract_idx].shape[0]):\n",
    "            vuln_type = analyzer.vulnerability_types[vuln_idx]\n",
    "            num_lines = line_true_all[contract_idx].shape[1]\n",
    "            \n",
    "            # Count this vulnerability type's lines\n",
    "            vuln_type_counts[vuln_type] += num_lines\n",
    "            \n",
    "            # Count vulnerable and predicted lines for this contract and vulnerability type\n",
    "            contract_vuln_true = line_true_all[contract_idx][vuln_idx, :]\n",
    "            contract_vuln_pred = line_pred_all[contract_idx][vuln_idx, :]\n",
    "            \n",
    "            vuln_type_vulnerable_counts[vuln_type] += np.sum(contract_vuln_true > 0)\n",
    "            vuln_type_predicted_counts[vuln_type] += np.sum(contract_vuln_pred > 0)\n",
    "    \n",
    "    # Store per-vulnerability statistics\n",
    "    for vuln_type in analyzer.vulnerability_types:\n",
    "        results['line_level']['statistics']['per_vulnerability'][vuln_type] = {\n",
    "            'total_lines_processed': int(vuln_type_counts[vuln_type]),\n",
    "            'total_lines_with_vulnerabilities': int(vuln_type_vulnerable_counts[vuln_type]),\n",
    "            'total_lines_predicted_vulnerable': int(vuln_type_predicted_counts[vuln_type])\n",
    "        }\n",
    "    \n",
    "    print(f\"📊 Line-level statistics:\")\n",
    "    print(f\"  Total lines processed: {total_lines_processed:,}\")\n",
    "    print(f\"  Total lines with vulnerabilities: {total_lines_with_vulnerabilities:,}\")\n",
    "    print(f\"  Total lines predicted as vulnerable: {total_lines_predicted_vulnerable:,}\")\n",
    "    \n",
    "    # Compute contract-level metrics\n",
    "    print(f\"\\n📋 Computing contract-level metrics...\")\n",
    "    \n",
    "    # Overall contract-level metrics (aggregated across all vulnerability types)\n",
    "    contract_true_flat = contract_true_all.flatten()\n",
    "    contract_pred_flat = contract_pred_all.flatten()\n",
    "    contract_probs_flat = contract_probs_all.flatten()\n",
    "    \n",
    "    results['contract_level']['overall'] = compute_metrics_for_threshold(\n",
    "        contract_true_flat, contract_pred_flat, contract_probs_flat\n",
    "    )\n",
    "    \n",
    "    # Per-vulnerability contract-level metrics\n",
    "    for vuln_idx, vuln_type in enumerate(analyzer.vulnerability_types):\n",
    "        if vuln_idx < contract_true_all.shape[1]:\n",
    "            vuln_true = contract_true_all[:, vuln_idx]\n",
    "            vuln_pred = contract_pred_all[:, vuln_idx]\n",
    "            vuln_probs = contract_probs_all[:, vuln_idx]\n",
    "            \n",
    "            results['contract_level']['per_vulnerability'][vuln_type] = compute_metrics_for_threshold(\n",
    "                vuln_true, vuln_pred, vuln_probs\n",
    "            )\n",
    "    \n",
    "    # Compute line-level metrics\n",
    "    print(f\"\\n📍 Computing line-level metrics...\")\n",
    "    \n",
    "    # Overall line-level metrics (aggregated across all vulnerability types and lines)\n",
    "    # Use the already flattened arrays\n",
    "    # Calculate overall probability statistics\n",
    "    true_positive_mask = (line_true_flat == 1) & (line_pred_flat == 1)\n",
    "    should_be_vulnerable_mask = (line_true_flat == 1)\n",
    "    \n",
    "    # Debug information\n",
    "    print(f\"🔍 DEBUG: Line-level analysis:\")\n",
    "    print(f\"  Total flattened elements: {len(line_true_flat)}\")\n",
    "    print(f\"  Elements that should be vulnerable: {np.sum(should_be_vulnerable_mask)}\")\n",
    "    print(f\"  True positives: {np.sum(true_positive_mask)}\")\n",
    "    print(f\"  Sample of line_probs_flat: {line_probs_flat[:10]}\")\n",
    "    print(f\"  Sample of should_be_vulnerable_mask: {should_be_vulnerable_mask[:10]}\")\n",
    "    if np.any(should_be_vulnerable_mask):\n",
    "        print(f\"  Probabilities for should_be_vulnerable lines: {line_probs_flat[should_be_vulnerable_mask][:10]}\")\n",
    "    \n",
    "    mean_true_positive_prob = float(np.mean(line_probs_flat[true_positive_mask])) if np.any(true_positive_mask) else 0.0\n",
    "    mean_should_be_vulnerable_prob = float(np.mean(line_probs_flat[should_be_vulnerable_mask])) if np.any(should_be_vulnerable_mask) else 0.0\n",
    "    \n",
    "    print(f\"  Mean probability for should_be_vulnerable: {mean_should_be_vulnerable_prob:.6f}\")\n",
    "    print(f\"  Mean probability for true_positives: {mean_true_positive_prob:.6f}\")\n",
    "    \n",
    "    # Get basic metrics\n",
    "    basic_metrics = compute_metrics_for_threshold(line_true_flat, line_pred_flat, line_probs_flat)\n",
    "    \n",
    "    # Add probability statistics\n",
    "    results['line_level']['overall'] = {\n",
    "        **basic_metrics,\n",
    "        'mean_true_positive_probability': mean_true_positive_prob,\n",
    "        'mean_should_be_vulnerable_probability': mean_should_be_vulnerable_prob,\n",
    "        'num_true_positives': int(np.sum(true_positive_mask)),\n",
    "        'num_should_be_vulnerable': int(np.sum(should_be_vulnerable_mask))\n",
    "    }\n",
    "    \n",
    "    # Per-vulnerability line-level metrics - need to reconstruct from flattened data\n",
    "    for vuln_idx, vuln_type in enumerate(analyzer.vulnerability_types):\n",
    "        # Collect data for this vulnerability type from all contracts\n",
    "        vuln_true = []\n",
    "        vuln_pred = []\n",
    "        vuln_probs = []\n",
    "        \n",
    "        for contract_idx in range(len(line_true_all)):\n",
    "            if vuln_idx < line_true_all[contract_idx].shape[0]:\n",
    "                vuln_true.extend(line_true_all[contract_idx][vuln_idx, :])\n",
    "                vuln_pred.extend(line_pred_all[contract_idx][vuln_idx, :])\n",
    "                vuln_probs.extend(line_probs_all[contract_idx][vuln_idx, :])\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        vuln_true = np.array(vuln_true)\n",
    "        vuln_pred = np.array(vuln_pred)\n",
    "        vuln_probs = np.array(vuln_probs)\n",
    "        \n",
    "        # Calculate mean prediction probability for true positive lines\n",
    "        true_positive_mask = (vuln_true == 1) & (vuln_pred == 1)\n",
    "        mean_true_positive_prob = float(np.mean(vuln_probs[true_positive_mask])) if np.any(true_positive_mask) else 0.0\n",
    "        \n",
    "        # Calculate mean prediction probability for all lines that should be predicted as vulnerable (true positive + false negative)\n",
    "        should_be_vulnerable_mask = (vuln_true == 1)\n",
    "        mean_should_be_vulnerable_prob = float(np.mean(vuln_probs[should_be_vulnerable_mask])) if np.any(should_be_vulnerable_mask) else 0.0\n",
    "        \n",
    "        # Debug for this vulnerability type\n",
    "        if np.sum(should_be_vulnerable_mask) > 0:\n",
    "            print(f\"  🔍 {vuln_type}: {np.sum(should_be_vulnerable_mask)} should be vulnerable, mean prob: {mean_should_be_vulnerable_prob:.6f}\")\n",
    "            print(f\"     Sample probs: {vuln_probs[should_be_vulnerable_mask][:5]}\")\n",
    "        \n",
    "        # Get basic metrics\n",
    "        basic_metrics = compute_metrics_for_threshold(vuln_true, vuln_pred, vuln_probs)\n",
    "        \n",
    "        # Add probability statistics\n",
    "        results['line_level']['per_vulnerability'][vuln_type] = {\n",
    "            **basic_metrics,\n",
    "            'mean_true_positive_probability': mean_true_positive_prob,\n",
    "            'mean_should_be_vulnerable_probability': mean_should_be_vulnerable_prob,\n",
    "            'num_true_positives': int(np.sum(true_positive_mask)),\n",
    "            'num_should_be_vulnerable': int(np.sum(should_be_vulnerable_mask))\n",
    "        }\n",
    "    \n",
    "    # Save results\n",
    "    print(f\"\\n💾 Saving results to {output_file}...\")\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ Comprehensive evaluation completed! Results saved to {output_file}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_evaluation_summary(results: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Print a summary of the evaluation results.\n",
    "    \n",
    "    Args:\n",
    "        results: Evaluation results from evaluate_model_performance\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"📊 COMPREHENSIVE EVALUATION SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Model info\n",
    "    model_info = results['model_info']\n",
    "    print(f\"\\n🔧 Model Information:\")\n",
    "    print(f\"  Model Path: {model_info['model_path']}\")\n",
    "    print(f\"  Contract Thresholds: {model_info['contract_thresholds']}\")\n",
    "    print(f\"  Line Thresholds: {model_info['line_thresholds']}\")\n",
    "    print(f\"  Total Contracts: {model_info['total_contracts']}\")\n",
    "    print(f\"  Vulnerability Types: {model_info['vulnerability_types']}\")\n",
    "    \n",
    "    # Contract-level results\n",
    "    print(f\"\\n📋 CONTRACT-LEVEL RESULTS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    print(f\"  Overall Performance:\")\n",
    "    for metric, value in results['contract_level']['overall'].items():\n",
    "        print(f\"    {metric.upper()}: {value:.4f}\")\n",
    "    \n",
    "    print(f\"\\n  Per-Vulnerability Performance:\")\n",
    "    for vuln_type, metrics in results['contract_level']['per_vulnerability'].items():\n",
    "        print(f\"    {vuln_type}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"      {metric.upper()}: {value:.4f}\")\n",
    "    \n",
    "    # Line-level results\n",
    "    print(f\"\\n📍 LINE-LEVEL RESULTS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    print(f\"  Overall Performance:\")\n",
    "    for metric, value in results['line_level']['overall'].items():\n",
    "        if metric in ['mean_true_positive_probability', 'mean_should_be_vulnerable_probability']:\n",
    "            print(f\"    {metric}: {value:.4f}\")\n",
    "        elif metric in ['num_true_positives', 'num_should_be_vulnerable']:\n",
    "            print(f\"    {metric}: {value}\")\n",
    "        else:\n",
    "            print(f\"    {metric.upper()}: {value:.4f}\")\n",
    "    \n",
    "    # Display line-level statistics\n",
    "    stats = results['line_level']['statistics']\n",
    "    print(f\"\\n  📊 LINE-LEVEL STATISTICS:\")\n",
    "    print(f\"    Total lines processed: {stats['total_lines_processed']:,}\")\n",
    "    print(f\"    Total lines with vulnerabilities: {stats['total_lines_with_vulnerabilities']:,}\")\n",
    "    print(f\"    Total lines predicted as vulnerable: {stats['total_lines_predicted_vulnerable']:,}\")\n",
    "    \n",
    "    print(f\"\\n  Per-Vulnerability Statistics:\")\n",
    "    for vuln_type, vuln_stats in stats['per_vulnerability'].items():\n",
    "        print(f\"    {vuln_type}:\")\n",
    "        print(f\"      Lines processed: {vuln_stats['total_lines_processed']:,}\")\n",
    "        print(f\"      Lines with vulnerabilities: {vuln_stats['total_lines_with_vulnerabilities']:,}\")\n",
    "        print(f\"      Lines predicted as vulnerable: {vuln_stats['total_lines_predicted_vulnerable']:,}\")\n",
    "    \n",
    "    print(f\"\\n  Per-Vulnerability Performance:\")\n",
    "    for vuln_type, metrics in results['line_level']['per_vulnerability'].items():\n",
    "        print(f\"    {vuln_type}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            if metric in ['mean_true_positive_probability', 'mean_should_be_vulnerable_probability']:\n",
    "                print(f\"      {metric}: {value:.4f}\")\n",
    "            elif metric in ['num_true_positives', 'num_should_be_vulnerable']:\n",
    "                print(f\"      {metric}: {value}\")\n",
    "            else:\n",
    "                print(f\"      {metric.upper()}: {value:.4f}\")\n",
    "    \n",
    "    # Add a note about the statistics\n",
    "    print(f\"\\n💡 NOTE: To get exact counts of processed lines, vulnerable lines, and predicted vulnerable lines,\")\n",
    "    print(f\"   the evaluation function would need to be modified to track these statistics during processing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66800902-be90-4fee-aa7e-2de6a2534216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting comprehensive model evaluation...\n",
      "🔧 Setting up analyzer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m20180848/.conda/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/m20180848/.conda/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Initialized line feature extractor layer 1 with small random weights\n",
      "DEBUG: Initialized line feature extractor layer 3 with small random weights\n",
      "DEBUG: Initialized custom line feature extractor with small weights\n",
      "Model loaded from checkpoints_v5_2048_output/best_model_augmented_gan_epoch_106.pt\n",
      "Training epoch: 106\n",
      "Best validation loss: 0.773994717746973\n",
      "Training config: GAN=True\n",
      "✅ Components initialized. Evaluating on 506 contracts\n",
      "📋 Contract thresholds: {'ARTHM': 0.5, 'DOS': 0.4, 'LE': 0.4, 'RENT': 0.4, 'TimeM': 0.4, 'TimeO': 0.4, 'Tx-Origin': 0.4, 'UE': 0.4}\n",
      "📍 Line thresholds: {'ARTHM': 0.2, 'DOS': 0.2, 'LE': 0.2, 'RENT': 0.2, 'TimeM': 0.2, 'TimeO': 0.2, 'Tx-Origin': 0.2, 'UE': 0.2}\n",
      "\n",
      "📊 Collecting validation results...\n",
      "🔍 DEBUG: pred_line_probs structure:\n",
      "  Type: <class 'list'>\n",
      "  Length: 1\n",
      "  pred_line_probs[0] type: <class 'list'>\n",
      "  pred_line_probs[0] length: 1024\n",
      "  pred_line_probs[0][0] type: <class 'list'>\n",
      "  pred_line_probs[0][0] length: 8\n",
      "  Sample values: [1.1084030120400712e-05, 1.5819520842144295e-16, 1.335360667717395e-27, 4.802037918732523e-26, 8.862677780689155e-18]\n",
      "  ✅ Processed 10/500 contracts\n",
      "  ✅ Processed 20/500 contracts\n",
      "  ✅ Processed 30/500 contracts\n",
      "  ✅ Processed 40/500 contracts\n",
      "  ✅ Processed 50/500 contracts\n",
      "  ✅ Processed 60/500 contracts\n",
      "  ✅ Processed 70/500 contracts\n",
      "  ✅ Processed 80/500 contracts\n",
      "  ✅ Processed 90/500 contracts\n",
      "  ✅ Processed 100/500 contracts\n",
      "  ✅ Processed 110/500 contracts\n",
      "  ✅ Processed 120/500 contracts\n",
      "  ✅ Processed 130/500 contracts\n",
      "  ✅ Processed 140/500 contracts\n",
      "  ✅ Processed 150/500 contracts\n",
      "  ✅ Processed 160/500 contracts\n",
      "  ✅ Processed 170/500 contracts\n",
      "  ✅ Processed 180/500 contracts\n",
      "  ✅ Processed 190/500 contracts\n",
      "  ✅ Processed 200/500 contracts\n",
      "  ✅ Processed 210/500 contracts\n",
      "  ✅ Processed 220/500 contracts\n",
      "  ✅ Processed 230/500 contracts\n",
      "  ✅ Processed 240/500 contracts\n",
      "  ✅ Processed 250/500 contracts\n",
      "  ✅ Processed 260/500 contracts\n",
      "  ✅ Processed 270/500 contracts\n",
      "  ✅ Processed 280/500 contracts\n",
      "  ✅ Processed 290/500 contracts\n",
      "  ✅ Processed 300/500 contracts\n",
      "  ✅ Processed 310/500 contracts\n",
      "  ✅ Processed 320/500 contracts\n",
      "  ✅ Processed 330/500 contracts\n",
      "  ✅ Processed 340/500 contracts\n",
      "  ✅ Processed 350/500 contracts\n",
      "  ✅ Processed 360/500 contracts\n",
      "  ✅ Processed 370/500 contracts\n",
      "  ✅ Processed 380/500 contracts\n",
      "  ✅ Processed 390/500 contracts\n",
      "  ✅ Processed 400/500 contracts\n",
      "  ✅ Processed 410/500 contracts\n",
      "  ✅ Processed 420/500 contracts\n",
      "  ✅ Processed 430/500 contracts\n",
      "  ✅ Processed 440/500 contracts\n",
      "  ✅ Processed 450/500 contracts\n",
      "  ✅ Processed 460/500 contracts\n",
      "  ✅ Processed 470/500 contracts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ Processed 480/500 contracts\n",
      "  ✅ Processed 490/500 contracts\n",
      "  ✅ Processed 500/500 contracts\n",
      "✅ Collected data for 500 contracts\n",
      "📊 Line-level statistics:\n",
      "  Total lines processed: 401,016\n",
      "  Total lines with vulnerabilities: 2,174\n",
      "  Total lines predicted as vulnerable: 2,566\n",
      "\n",
      "📋 Computing contract-level metrics...\n",
      "\n",
      "📍 Computing line-level metrics...\n",
      "🔍 DEBUG: Line-level analysis:\n",
      "  Total flattened elements: 401016\n",
      "  Elements that should be vulnerable: 2174\n",
      "  True positives: 1403\n",
      "  Sample of line_probs_flat: [1.10840301e-05 1.83676381e-08 3.51013398e-07 6.64268737e-04\n",
      " 9.83592749e-01 9.87356424e-01 1.45548191e-02 5.05667813e-05\n",
      " 1.87427617e-07 1.06397044e-06]\n",
      "  Sample of should_be_vulnerable_mask: [False False False False  True  True False False False False]\n",
      "  Probabilities for should_be_vulnerable lines: [0.98359275 0.98735642 0.97724676 0.9405756  0.40342605 0.44837305\n",
      " 0.22966476 0.49984008 0.5        0.5       ]\n",
      "  Mean probability for should_be_vulnerable: 0.562761\n",
      "  Mean probability for true_positives: 0.671087\n",
      "  🔍 ARTHM: 1785 should be vulnerable, mean prob: 0.577102\n",
      "     Sample probs: [0.98359275 0.98735642 0.97724676 0.40342605 0.44837305]\n",
      "  🔍 DOS: 68 should be vulnerable, mean prob: 0.555698\n",
      "     Sample probs: [0.80715096 0.8711338  0.5        0.53453678 0.97810352]\n",
      "  🔍 TimeM: 136 should be vulnerable, mean prob: 0.578757\n",
      "     Sample probs: [0.9405756  0.5        0.5        0.5        0.81314808]\n",
      "  🔍 TimeO: 102 should be vulnerable, mean prob: 0.351827\n",
      "     Sample probs: [1.24996095e-05 1.16316856e-04 5.00000000e-01 5.00000000e-01\n",
      " 4.79199328e-02]\n",
      "  🔍 UE: 83 should be vulnerable, mean prob: 0.493138\n",
      "     Sample probs: [5.00000000e-01 3.06112895e-04 6.55133486e-01 9.57206011e-01\n",
      " 3.16745818e-01]\n",
      "\n",
      "💾 Saving results to comprehensive_evaluation_results.json...\n",
      "✅ Comprehensive evaluation completed! Results saved to comprehensive_evaluation_results.json\n",
      "\n",
      "================================================================================\n",
      "📊 COMPREHENSIVE EVALUATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "🔧 Model Information:\n",
      "  Model Path: checkpoints_v5_2048_output/best_model_augmented_gan_epoch_106.pt\n",
      "  Contract Thresholds: {'ARTHM': 0.5, 'DOS': 0.4, 'LE': 0.4, 'RENT': 0.4, 'TimeM': 0.4, 'TimeO': 0.4, 'Tx-Origin': 0.4, 'UE': 0.4}\n",
      "  Line Thresholds: {'ARTHM': 0.2, 'DOS': 0.2, 'LE': 0.2, 'RENT': 0.2, 'TimeM': 0.2, 'TimeO': 0.2, 'Tx-Origin': 0.2, 'UE': 0.2}\n",
      "  Total Contracts: 506\n",
      "  Vulnerability Types: ['ARTHM', 'DOS', 'LE', 'RENT', 'TimeM', 'TimeO', 'Tx-Origin', 'UE']\n",
      "\n",
      "📋 CONTRACT-LEVEL RESULTS:\n",
      "----------------------------------------\n",
      "  Overall Performance:\n",
      "    ACCURACY: 0.3518\n",
      "    PRECISION: 0.2591\n",
      "    RECALL: 1.0000\n",
      "    F1_SCORE: 0.4116\n",
      "    PR_AUC: 0.7468\n",
      "    ROC_AUC: 0.8489\n",
      "\n",
      "  Per-Vulnerability Performance:\n",
      "    ARTHM:\n",
      "      ACCURACY: 0.9040\n",
      "      PRECISION: 0.9040\n",
      "      RECALL: 1.0000\n",
      "      F1_SCORE: 0.9496\n",
      "      PR_AUC: 0.9520\n",
      "      ROC_AUC: 0.5000\n",
      "    DOS:\n",
      "      ACCURACY: 0.1140\n",
      "      PRECISION: 0.1140\n",
      "      RECALL: 1.0000\n",
      "      F1_SCORE: 0.2047\n",
      "      PR_AUC: 0.5570\n",
      "      ROC_AUC: 0.5000\n",
      "    LE:\n",
      "      ACCURACY: 0.1520\n",
      "      PRECISION: 0.1520\n",
      "      RECALL: 1.0000\n",
      "      F1_SCORE: 0.2639\n",
      "      PR_AUC: 0.5760\n",
      "      ROC_AUC: 0.5000\n",
      "    RENT:\n",
      "      ACCURACY: 0.3540\n",
      "      PRECISION: 0.3540\n",
      "      RECALL: 1.0000\n",
      "      F1_SCORE: 0.5229\n",
      "      PR_AUC: 0.6770\n",
      "      ROC_AUC: 0.5000\n",
      "    TimeM:\n",
      "      ACCURACY: 0.1000\n",
      "      PRECISION: 0.1000\n",
      "      RECALL: 1.0000\n",
      "      F1_SCORE: 0.1818\n",
      "      PR_AUC: 0.5500\n",
      "      ROC_AUC: 0.5000\n",
      "    TimeO:\n",
      "      ACCURACY: 0.1060\n",
      "      PRECISION: 0.1060\n",
      "      RECALL: 1.0000\n",
      "      F1_SCORE: 0.1917\n",
      "      PR_AUC: 0.5530\n",
      "      ROC_AUC: 0.5000\n",
      "    Tx-Origin:\n",
      "      ACCURACY: 0.0000\n",
      "      PRECISION: 0.0000\n",
      "      RECALL: 0.0000\n",
      "      F1_SCORE: 0.0000\n",
      "      PR_AUC: 0.0000\n",
      "      ROC_AUC: 0.0000\n",
      "    UE:\n",
      "      ACCURACY: 0.0840\n",
      "      PRECISION: 0.0840\n",
      "      RECALL: 1.0000\n",
      "      F1_SCORE: 0.1550\n",
      "      PR_AUC: 0.5420\n",
      "      ROC_AUC: 0.5000\n",
      "\n",
      "📍 LINE-LEVEL RESULTS:\n",
      "----------------------------------------\n",
      "  Overall Performance:\n",
      "    ACCURACY: 0.9952\n",
      "    PRECISION: 0.5468\n",
      "    RECALL: 0.6454\n",
      "    F1_SCORE: 0.5920\n",
      "    PR_AUC: 0.6193\n",
      "    ROC_AUC: 0.9042\n",
      "    mean_true_positive_probability: 0.6711\n",
      "    mean_should_be_vulnerable_probability: 0.5628\n",
      "    num_true_positives: 1403\n",
      "    num_should_be_vulnerable: 2174\n",
      "\n",
      "  📊 LINE-LEVEL STATISTICS:\n",
      "    Total lines processed: 401,016\n",
      "    Total lines with vulnerabilities: 2,174\n",
      "    Total lines predicted as vulnerable: 2,566\n",
      "\n",
      "  Per-Vulnerability Statistics:\n",
      "    ARTHM:\n",
      "      Lines processed: 50,127\n",
      "      Lines with vulnerabilities: 1,785\n",
      "      Lines predicted as vulnerable: 2,313\n",
      "    DOS:\n",
      "      Lines processed: 50,127\n",
      "      Lines with vulnerabilities: 68\n",
      "      Lines predicted as vulnerable: 44\n",
      "    LE:\n",
      "      Lines processed: 50,127\n",
      "      Lines with vulnerabilities: 0\n",
      "      Lines predicted as vulnerable: 0\n",
      "    RENT:\n",
      "      Lines processed: 50,127\n",
      "      Lines with vulnerabilities: 0\n",
      "      Lines predicted as vulnerable: 0\n",
      "    TimeM:\n",
      "      Lines processed: 50,127\n",
      "      Lines with vulnerabilities: 136\n",
      "      Lines predicted as vulnerable: 119\n",
      "    TimeO:\n",
      "      Lines processed: 50,127\n",
      "      Lines with vulnerabilities: 102\n",
      "      Lines predicted as vulnerable: 35\n",
      "    Tx-Origin:\n",
      "      Lines processed: 50,127\n",
      "      Lines with vulnerabilities: 0\n",
      "      Lines predicted as vulnerable: 0\n",
      "    UE:\n",
      "      Lines processed: 50,127\n",
      "      Lines with vulnerabilities: 83\n",
      "      Lines predicted as vulnerable: 55\n",
      "\n",
      "  Per-Vulnerability Performance:\n",
      "    ARTHM:\n",
      "      ACCURACY: 0.9663\n",
      "      PRECISION: 0.5210\n",
      "      RECALL: 0.6751\n",
      "      F1_SCORE: 0.5881\n",
      "      PR_AUC: 0.6617\n",
      "      ROC_AUC: 0.8976\n",
      "      mean_true_positive_probability: 0.6622\n",
      "      mean_should_be_vulnerable_probability: 0.5771\n",
      "      num_true_positives: 1205\n",
      "      num_should_be_vulnerable: 1785\n",
      "    DOS:\n",
      "      ACCURACY: 0.9992\n",
      "      PRECISION: 0.8182\n",
      "      RECALL: 0.5294\n",
      "      F1_SCORE: 0.6429\n",
      "      PR_AUC: 0.6117\n",
      "      ROC_AUC: 0.8373\n",
      "      mean_true_positive_probability: 0.7746\n",
      "      mean_should_be_vulnerable_probability: 0.5557\n",
      "      num_true_positives: 36\n",
      "      num_should_be_vulnerable: 68\n",
      "    LE:\n",
      "      ACCURACY: 0.0000\n",
      "      PRECISION: 0.0000\n",
      "      RECALL: 0.0000\n",
      "      F1_SCORE: 0.0000\n",
      "      PR_AUC: 0.0000\n",
      "      ROC_AUC: 0.0000\n",
      "      mean_true_positive_probability: 0.0000\n",
      "      mean_should_be_vulnerable_probability: 0.0000\n",
      "      num_true_positives: 0\n",
      "      num_should_be_vulnerable: 0\n",
      "    RENT:\n",
      "      ACCURACY: 0.0000\n",
      "      PRECISION: 0.0000\n",
      "      RECALL: 0.0000\n",
      "      F1_SCORE: 0.0000\n",
      "      PR_AUC: 0.0000\n",
      "      ROC_AUC: 0.0000\n",
      "      mean_true_positive_probability: 0.0000\n",
      "      mean_should_be_vulnerable_probability: 0.0000\n",
      "      num_true_positives: 0\n",
      "      num_should_be_vulnerable: 0\n",
      "    TimeM:\n",
      "      ACCURACY: 0.9983\n",
      "      PRECISION: 0.7059\n",
      "      RECALL: 0.6176\n",
      "      F1_SCORE: 0.6588\n",
      "      PR_AUC: 0.6802\n",
      "      ROC_AUC: 0.9001\n",
      "      mean_true_positive_probability: 0.7335\n",
      "      mean_should_be_vulnerable_probability: 0.5788\n",
      "      num_true_positives: 84\n",
      "      num_should_be_vulnerable: 136\n",
      "    TimeO:\n",
      "      ACCURACY: 0.9986\n",
      "      PRECISION: 0.9714\n",
      "      RECALL: 0.3333\n",
      "      F1_SCORE: 0.4964\n",
      "      PR_AUC: 0.3858\n",
      "      ROC_AUC: 0.8351\n",
      "      mean_true_positive_probability: 0.6688\n",
      "      mean_should_be_vulnerable_probability: 0.3518\n",
      "      num_true_positives: 34\n",
      "      num_should_be_vulnerable: 102\n",
      "    Tx-Origin:\n",
      "      ACCURACY: 0.0000\n",
      "      PRECISION: 0.0000\n",
      "      RECALL: 0.0000\n",
      "      F1_SCORE: 0.0000\n",
      "      PR_AUC: 0.0000\n",
      "      ROC_AUC: 0.0000\n",
      "      mean_true_positive_probability: 0.0000\n",
      "      mean_should_be_vulnerable_probability: 0.0000\n",
      "      num_true_positives: 0\n",
      "      num_should_be_vulnerable: 0\n",
      "    UE:\n",
      "      ACCURACY: 0.9990\n",
      "      PRECISION: 0.8000\n",
      "      RECALL: 0.5301\n",
      "      F1_SCORE: 0.6377\n",
      "      PR_AUC: 0.5684\n",
      "      ROC_AUC: 0.8604\n",
      "      mean_true_positive_probability: 0.7130\n",
      "      mean_should_be_vulnerable_probability: 0.4931\n",
      "      num_true_positives: 44\n",
      "      num_should_be_vulnerable: 83\n",
      "\n",
      "💡 NOTE: To get exact counts of processed lines, vulnerable lines, and predicted vulnerable lines,\n",
      "   the evaluation function would need to be modified to track these statistics during processing.\n"
     ]
    }
   ],
   "source": [
    "contract_thresholds = {\n",
    "    'ARTHM': 0.5,\n",
    "    'DOS': 0.4,\n",
    "    'LE': 0.4,\n",
    "    'RENT': 0.4,\n",
    "    'TimeM': 0.4,\n",
    "    'TimeO': 0.4,\n",
    "    'Tx-Origin': 0.4,\n",
    "    'UE': 0.4\n",
    "}\n",
    "\n",
    "line_thresholds = {\n",
    "    'ARTHM': 0.2,\n",
    "    'DOS': 0.2,\n",
    "    'LE': 0.2,\n",
    "    'RENT': 0.2,\n",
    "    'TimeM': 0.2,\n",
    "    'TimeO': 0.2,\n",
    "    'Tx-Origin': 0.2,\n",
    "    'UE': 0.2\n",
    "}\n",
    "\n",
    "results = evaluate_model_performance(\n",
    "    model_path=MODEL_PATH,\n",
    "    val_dataloader=val_dataloader,\n",
    "    contract_thresholds=contract_thresholds,\n",
    "    line_thresholds=line_thresholds,\n",
    "    max_contracts=500,  # Evaluate first 50 contracts\n",
    "    output_file=\"comprehensive_evaluation_results.json\"\n",
    ")\n",
    "\n",
    "print_evaluation_summary(results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce80b00-e169-40ac-9e6b-fb8b774c36a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb18ce4e-91e2-4b3b-8c55-923911c11b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_p310",
   "language": "python",
   "name": "pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
