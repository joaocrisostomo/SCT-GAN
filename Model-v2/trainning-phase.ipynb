{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c3acb4f-edae-4342-9a26-7f8bf3a57e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uv pip install torch transformers numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1898cf2f-ccf6-4cc8-8aec-c2ce42f7b561",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.11/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3365, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3610, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3670, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_2088207/944889248.py\", line 2, in <module>\n",
      "    import torch\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/torch/__init__.py\", line 1471, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/m20180848/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/m20180848/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Model imports\n",
    "from model import SmartContractTransformer\n",
    "\n",
    "# Training imports\n",
    "from train import SmartContractTrainer\n",
    "\n",
    "# Optional but useful imports\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # for progress bars\n",
    "import logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7854810c-ced1-4bcf-b1ef-2fd5323dfa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0379b7b-bd04-495b-8521-9cb9be0fbaa2",
   "metadata": {},
   "source": [
    "- Dataset.py script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7d5051a-5c5f-46fc-b3d6-25b687eb0689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n",
      "Number of GPUs: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8342c217-fa0e-486d-9ace-e2ab37ef266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def parse_solidity_to_ast(code: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parse Solidity code into a simplified AST structure\n",
    "    \"\"\"\n",
    "    def extract_contract_info(code: str) -> Dict[str, Any]:\n",
    "        # Extract contract name\n",
    "        contract_match = re.search(r'contract\\s+(\\w+)', code)\n",
    "        contract_name = contract_match.group(1) if contract_match else \"Unknown\"\n",
    "        \n",
    "        # Extract functions\n",
    "        functions = []\n",
    "        function_pattern = r'function\\s+(\\w+)\\s*\\(([^)]*)\\)\\s*(?:public|private|internal|external)?\\s*(?:view|pure|payable)?\\s*(?:returns\\s*\\(([^)]*)\\))?\\s*{'\n",
    "        for match in re.finditer(function_pattern, code):\n",
    "            func_name = match.group(1)\n",
    "            params = match.group(2).split(',') if match.group(2) else []\n",
    "            returns = match.group(3).split(',') if match.group(3) else []\n",
    "            \n",
    "            functions.append({\n",
    "                'name': func_name,\n",
    "                'parameters': [p.strip() for p in params],\n",
    "                'returns': [r.strip() for r in returns]\n",
    "            })\n",
    "        \n",
    "        # Extract state variables\n",
    "        variables = []\n",
    "        var_pattern = r'(?:uint|address|string|bool|mapping)\\s+(?:\\w+)\\s+(\\w+)'\n",
    "        for match in re.finditer(var_pattern, code):\n",
    "            variables.append(match.group(1))\n",
    "        \n",
    "        return {\n",
    "            'type': 'Contract',\n",
    "            'name': contract_name,\n",
    "            'functions': functions,\n",
    "            'variables': variables\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        # Clean the code\n",
    "        code = re.sub(r'//.*?\\n|/\\*.*?\\*/', '', code)  # Remove comments\n",
    "        code = re.sub(r'\\s+', ' ', code)  # Normalize whitespace\n",
    "        \n",
    "        # Parse the code\n",
    "        ast = extract_contract_info(code)\n",
    "        return ast\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing code: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def prepare_code2vec_input(ast: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Convert AST to codeBert input format\n",
    "    \"\"\"\n",
    "    paths = []\n",
    "    \n",
    "    def extract_paths(node: Dict[str, Any], current_path: List[str] = None):\n",
    "        if current_path is None:\n",
    "            current_path = []\n",
    "            \n",
    "        # Add current node to path\n",
    "        if 'name' in node:\n",
    "            current_path.append(node['name'])\n",
    "            \n",
    "        # Process functions\n",
    "        if 'functions' in node:\n",
    "            for func in node['functions']:\n",
    "                func_path = current_path + [func['name']]\n",
    "                paths.append(' '.join(func_path))\n",
    "                \n",
    "                # Add parameter paths\n",
    "                for param in func['parameters']:\n",
    "                    param_path = func_path + [param]\n",
    "                    paths.append(' '.join(param_path))\n",
    "                \n",
    "                # Add return paths\n",
    "                for ret in func['returns']:\n",
    "                    ret_path = func_path + [ret]\n",
    "                    paths.append(' '.join(ret_path))\n",
    "        \n",
    "        # Process variables\n",
    "        if 'variables' in node:\n",
    "            for var in node['variables']:\n",
    "                var_path = current_path + [var]\n",
    "                paths.append(' '.join(var_path))\n",
    "    \n",
    "    extract_paths(ast)\n",
    "    return paths\n",
    "\n",
    "class SmartContractVulnerabilityDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        max_length: int = 1024,\n",
    "        split: str = \"train\",\n",
    "        vulnerability_types: List[str] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_path: Path to the CSV file containing the dataset\n",
    "            tokenizer: Tokenizer for encoding the source code\n",
    "            max_length: Maximum sequence length\n",
    "            split: \"train\" or \"val\" to specify which split to load\n",
    "            vulnerability_types: List of vulnerability types to consider\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.split = split\n",
    "        self.vulnerability_types = vulnerability_types or [\n",
    "            'ARTHM', 'DOS', 'LE', 'RENT', 'TimeM', 'TimeO', 'Tx-Origin', 'UE'\n",
    "        ]\n",
    "        \n",
    "        # Load the dataset\n",
    "        self.data = self._load_dataset(data_path)\n",
    "        \n",
    "    def _load_dataset(self, data_path: str) -> List[Dict]:\n",
    "        \"\"\"Load and preprocess the dataset from CSV\"\"\"\n",
    "        dataset = []\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(data_path)\n",
    "        \n",
    "        # Split into train/val if needed\n",
    "        if self.split == \"train\":\n",
    "            df = df.sample(frac=0.8, random_state=42)\n",
    "        else:\n",
    "            df = df.sample(frac=0.2, random_state=42)\n",
    "        \n",
    "        # Process each contract\n",
    "        for _, row in df.iterrows():\n",
    "            try:\n",
    "                source_code = row['source_code']\n",
    "                contract_name = row['contract_name']\n",
    "                \n",
    "                # Parse AST and get paths\n",
    "                ast = parse_solidity_to_ast(source_code)\n",
    "                ast_paths = prepare_code2vec_input(ast) if ast else []\n",
    "                ast_path_text = ' '.join(ast_paths)\n",
    "                \n",
    "                # Split source code into lines\n",
    "                lines = source_code.split('\\n')\n",
    "                \n",
    "                # Create token-to-line mapping\n",
    "                token_to_line = []\n",
    "                current_line = 0\n",
    "                \n",
    "                # Tokenize each line separately to maintain mapping\n",
    "                for line in lines:\n",
    "                    line_tokens = self.tokenizer.encode(line, add_special_tokens=False)\n",
    "                    token_to_line.extend([current_line] * len(line_tokens))\n",
    "                    current_line += 1\n",
    "                \n",
    "                # Add special tokens\n",
    "                token_to_line = [0] + token_to_line + [0]  # [CLS] and [SEP] tokens\n",
    "                \n",
    "                # Truncate if too long\n",
    "                if len(token_to_line) > self.max_length:\n",
    "                    token_to_line = token_to_line[:self.max_length]\n",
    "                \n",
    "                # Pad if too short\n",
    "                if len(token_to_line) < self.max_length:\n",
    "                    token_to_line.extend([0] * (self.max_length - len(token_to_line)))\n",
    "                \n",
    "                # Create multi-label line labels for each vulnerability type\n",
    "                line_labels = self._create_multi_label_line_labels(source_code, row)\n",
    "                \n",
    "                # Create contract-level vulnerability labels\n",
    "                contract_labels = self._create_contract_vulnerability_labels(row)\n",
    "                \n",
    "                # Tokenize the source code\n",
    "                encoding = self.tokenizer(\n",
    "                    source_code,\n",
    "                    max_length=self.max_length,\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                # Tokenize AST paths\n",
    "                ast_encoding = self.tokenizer(\n",
    "                    ast_path_text,\n",
    "                    max_length=self.max_length,\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                # Convert line labels to tensor and ensure consistent shape\n",
    "                vuln_tensor = torch.zeros((len(self.vulnerability_types), self.max_length), dtype=torch.long)\n",
    "                for i, labels in enumerate(line_labels):\n",
    "                    if len(labels) > self.max_length:\n",
    "                        labels = labels[:self.max_length]\n",
    "                    vuln_tensor[i, :len(labels)] = torch.tensor(labels, dtype=torch.long)\n",
    "                \n",
    "                # Convert contract labels to tensor\n",
    "                contract_vuln_tensor = torch.tensor(contract_labels, dtype=torch.long)\n",
    "                \n",
    "                # Convert token_to_line to tensor\n",
    "                token_to_line_tensor = torch.tensor(token_to_line, dtype=torch.long)\n",
    "                \n",
    "                # Ensure attention masks are boolean\n",
    "                attention_mask = encoding['attention_mask'].squeeze(0).bool()\n",
    "                ast_attention_mask = ast_encoding['attention_mask'].squeeze(0).bool()\n",
    "                \n",
    "                # Ensure input_ids are the right length\n",
    "                input_ids = encoding['input_ids'].squeeze(0)\n",
    "                ast_input_ids = ast_encoding['input_ids'].squeeze(0)\n",
    "                \n",
    "                if len(input_ids) > self.max_length:\n",
    "                    input_ids = input_ids[:self.max_length]\n",
    "                if len(ast_input_ids) > self.max_length:\n",
    "                    ast_input_ids = ast_input_ids[:self.max_length]\n",
    "                \n",
    "                # Pad if necessary\n",
    "                if len(input_ids) < self.max_length:\n",
    "                    input_ids = torch.nn.functional.pad(input_ids, (0, self.max_length - len(input_ids)))\n",
    "                if len(ast_input_ids) < self.max_length:\n",
    "                    ast_input_ids = torch.nn.functional.pad(ast_input_ids, (0, self.max_length - len(ast_input_ids)))\n",
    "                \n",
    "                dataset.append({\n",
    "                    'input_ids': input_ids,\n",
    "                    'attention_mask': attention_mask,\n",
    "                    'ast_input_ids': ast_input_ids,\n",
    "                    'ast_attention_mask': ast_attention_mask,\n",
    "                    'vulnerable_lines': vuln_tensor,\n",
    "                    'contract_vulnerabilities': contract_vuln_tensor,\n",
    "                    'token_to_line': token_to_line_tensor,\n",
    "                    'source_code': source_code,\n",
    "                    'contract_name': contract_name\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing contract {contract_name}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    def _create_contract_vulnerability_labels(self, row: pd.Series) -> List[int]:\n",
    "        \"\"\"Create contract-level vulnerability labels\"\"\"\n",
    "        contract_labels = []\n",
    "        for vuln_type in self.vulnerability_types:\n",
    "            # Check if contract has this vulnerability type\n",
    "            vuln_lines = row[f'{vuln_type}_lines']\n",
    "            if isinstance(vuln_lines, str):\n",
    "                try:\n",
    "                    vuln_lines = eval(vuln_lines)\n",
    "                except:\n",
    "                    vuln_lines = [vuln_lines]\n",
    "            \n",
    "            # Contract is vulnerable if it has any vulnerable lines\n",
    "            has_vulnerability = len(vuln_lines) > 0\n",
    "            contract_labels.append(1 if has_vulnerability else 0)\n",
    "        \n",
    "        return contract_labels\n",
    "    \n",
    "    def _create_multi_label_line_labels(self, source_code: str, row: pd.Series) -> List[List[int]]:\n",
    "        \"\"\"Create multi-label line labels for each vulnerability type\"\"\"\n",
    "        total_lines = len(source_code.split('\\n'))\n",
    "        line_labels = {vuln_type: [0] * total_lines for vuln_type in self.vulnerability_types}\n",
    "        \n",
    "        # Process each vulnerability type\n",
    "        for vuln_type in self.vulnerability_types:\n",
    "            vuln_lines = row[f'{vuln_type}_lines']\n",
    "            if isinstance(vuln_lines, str):\n",
    "                try:\n",
    "                    vuln_lines = eval(vuln_lines)\n",
    "                except:\n",
    "                    vuln_lines = [vuln_lines]\n",
    "            \n",
    "            # Process each vulnerable line/snippet\n",
    "            for line_or_snippet in vuln_lines:\n",
    "                if isinstance(line_or_snippet, int):\n",
    "                    # If it's a line number, mark that line\n",
    "                    if 0 <= line_or_snippet < total_lines:\n",
    "                        line_labels[vuln_type][line_or_snippet] = 1\n",
    "                else:\n",
    "                    # If it's a code snippet, find matching lines\n",
    "                    source_lines = source_code.split('\\n')\n",
    "                    for i, line in enumerate(source_lines):\n",
    "                        # Clean both the line and snippet for comparison\n",
    "                        clean_line = re.sub(r'\\s+', ' ', line.strip())\n",
    "                        clean_snippet = re.sub(r'\\s+', ' ', str(line_or_snippet).strip())\n",
    "                        if clean_snippet in clean_line:\n",
    "                            line_labels[vuln_type][i] = 1\n",
    "        \n",
    "        # Convert to list format\n",
    "        return [line_labels[vuln_type] for vuln_type in self.vulnerability_types]\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict:\n",
    "        return self.data[idx]\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle variable length inputs\n",
    "    \"\"\"\n",
    "    # Get the maximum length in this batch for each type of tensor\n",
    "    max_input_len = max(item['input_ids'].size(0) for item in batch)\n",
    "    \n",
    "    # Pad all tensors to their respective maximum lengths\n",
    "    padded_batch = {\n",
    "        'input_ids': torch.stack([\n",
    "            torch.nn.functional.pad(item['input_ids'], (0, max_input_len - item['input_ids'].size(0)))\n",
    "            for item in batch\n",
    "        ]),\n",
    "        'attention_mask': torch.stack([\n",
    "            torch.nn.functional.pad(item['attention_mask'], (0, max_input_len - item['attention_mask'].size(0)))\n",
    "            for item in batch\n",
    "        ]),\n",
    "        'ast_input_ids': torch.stack([item['ast_input_ids'] for item in batch]),\n",
    "        'ast_attention_mask': torch.stack([item['ast_attention_mask'] for item in batch]),\n",
    "        'vulnerable_lines': torch.stack([item['vulnerable_lines'] for item in batch]),\n",
    "        'contract_vulnerabilities': torch.stack([item['contract_vulnerabilities'] for item in batch]),\n",
    "        'token_to_line': torch.stack([item['token_to_line'] for item in batch]),\n",
    "        'source_code': [item['source_code'] for item in batch],\n",
    "        'contract_name': [item['contract_name'] for item in batch]\n",
    "    }\n",
    "    \n",
    "    return padded_batch\n",
    "\n",
    "def create_dataloaders(\n",
    "    data_path: str,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    batch_size: int = 8,\n",
    "    max_length: int = 1024,\n",
    "    num_workers: int = 4,\n",
    "    vulnerability_types: List[str] = None\n",
    ") -> Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
    "    \"\"\"\n",
    "    Create train and validation dataloaders\n",
    "    \n",
    "    Args:\n",
    "        data_path: Path to the CSV file containing the dataset\n",
    "        tokenizer: Tokenizer for encoding the source code\n",
    "        batch_size: Batch size for training\n",
    "        max_length: Maximum sequence length\n",
    "        num_workers: Number of workers for data loading\n",
    "        vulnerability_types: List of vulnerability types to consider\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (train_dataloader, val_dataloader)\n",
    "    \"\"\"\n",
    "    # Create datasets\n",
    "    train_dataset = SmartContractVulnerabilityDataset(\n",
    "        data_path=data_path,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=max_length,\n",
    "        split=\"train\",\n",
    "        vulnerability_types=vulnerability_types\n",
    "    )\n",
    "    \n",
    "    val_dataset = SmartContractVulnerabilityDataset(\n",
    "        data_path=data_path,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=max_length,\n",
    "        split=\"val\",\n",
    "        vulnerability_types=vulnerability_types\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders with custom collate function\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "    \n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        collate_fn=custom_collate_fn\n",
    "    )\n",
    "    \n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f35cba34-ea45-434f-ad6d-9b4449db435a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader, val_dataloader = create_dataloaders(\n",
    "    data_path=\"contract_sources_with_vulnerabilities_2048_token_size.csv\",\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=8,\n",
    "    max_length=1024,\n",
    "    vulnerability_types=['ARTHM', 'DOS', 'LE', 'RENT', 'TimeM', 'TimeO', 'Tx-Origin', 'UE']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd90546-c363-4914-89bf-cc2ed0c53bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   2%|▏         | 5/253 [00:04<03:15,  1.27it/s, gen_loss=10.8250, contract_vuln_loss=0.1225, line_vuln_loss=0.1225, lr=0.000020]"
     ]
    }
   ],
   "source": [
    "model = SmartContractTransformer()\n",
    "\n",
    "trainer = SmartContractTrainer(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    tokenizer=tokenizer,\n",
    "    learning_rate=0.08,\n",
    "    weight_decay=0.001,\n",
    "    max_grad_norm= 1.0\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train(num_epochs=400, checkpoint_dir='checkpoints_v2_2048_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cbc0e8-e189-41a4-95f5-4d65a9c2e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeac150-5016-4f26-ac9c-e8345e61a804",
   "metadata": {},
   "source": [
    "## Re-trainning phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b8776-c9b0-4d6c-91e2-495414474d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ed63565-adb9-4465-9bfe-7b9f1939ad16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from epoch 40\n",
      "Validation loss: 4.5804\n",
      "Reset learning rate to 0.002\n"
     ]
    }
   ],
   "source": [
    "def load_trained_model(checkpoint_path):\n",
    "    \"\"\"\n",
    "    Load a trained model and discriminator from checkpoint\n",
    "    \"\"\"\n",
    "\n",
    "    device = torch.device('cuda:1')\n",
    "    \n",
    "    # Initialize model and discriminator\n",
    "    model = SmartContractTransformer()\n",
    "    discriminator = Discriminator()\n",
    "    \n",
    "    model = model.to(device)\n",
    "    discriminator = discriminator.to(device)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    # Load model and discriminator states\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
    "\n",
    "    if 'optimizer_state_dict' in checkpoint:\n",
    "        for param_group in checkpoint['optimizer_state_dict']['param_groups']:\n",
    "            param_group['lr'] = 0.02\n",
    "    if 'discriminator_optimizer_state_dict' in checkpoint:\n",
    "        for param_group in checkpoint['discriminator_optimizer_state_dict']['param_groups']:\n",
    "            param_group['lr'] = 0.02\n",
    "    \n",
    "    print(f\"Loaded model from epoch {checkpoint['epoch']}\")\n",
    "    print(f\"Validation loss: {checkpoint['val_loss']:.4f}\")\n",
    "    print(f\"Reset learning rate to 0.02\")\n",
    "    \n",
    "    return model, discriminator, checkpoint\n",
    "\n",
    "# Load pre-trained model\n",
    "checkpoint_path = 'checkpoints_v1_512_output/best_model_epoch_40.pt'  \n",
    "model, discriminator, checkpoint = load_trained_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9013060-daab-41aa-b7c1-67f564808280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m20180848/pytorch_env/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 88/88 [05:39<00:00,  3.85s/it, gen_loss=3.78, vuln_loss=0.377, synth_loss=0.766, diversity_loss=-0, d_penalty=0, g_penalty=0, is_synthetic=0]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0873\n",
      "Val Loss: 4.6308\n",
      "Vulnerability Loss: 9.4490\n",
      "Synthetic Loss: 23.9306\n",
      "Learning Rate: 0.020000\n",
      "Saved checkpoint to checkpoints_v1_512_retrain/best_model_epoch_1.pt\n",
      "\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 88/88 [05:47<00:00,  3.95s/it, gen_loss=4.87, vuln_loss=0.378, synth_loss=0.317, diversity_loss=-0, d_penalty=0, g_penalty=0, is_synthetic=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1122\n",
      "Val Loss: 4.6044\n",
      "Vulnerability Loss: 0.3398\n",
      "Synthetic Loss: 0.5832\n",
      "Learning Rate: 0.020000\n",
      "Saved checkpoint to checkpoints_v1_512_retrain/best_model_epoch_2.pt\n",
      "\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 88/88 [05:29<00:00,  3.74s/it, gen_loss=4.2, vuln_loss=0.246, synth_loss=0.84, diversity_loss=-0, d_penalty=0, g_penalty=0, is_synthetic=0]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0973\n",
      "Val Loss: 4.6069\n",
      "Vulnerability Loss: 0.3393\n",
      "Synthetic Loss: 0.5637\n",
      "Learning Rate: 0.020000\n",
      "\n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 88/88 [05:19<00:00,  3.64s/it, gen_loss=3.8, vuln_loss=0.247, synth_loss=0.258, diversity_loss=-0, d_penalty=0, g_penalty=0, is_synthetic=1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0883\n",
      "Val Loss: 4.6367\n",
      "Vulnerability Loss: 0.3413\n",
      "Synthetic Loss: 0.5390\n",
      "Learning Rate: 0.020000\n",
      "\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 5/88 [00:22<06:18,  4.57s/it, gen_loss=4.96, vuln_loss=0.444, synth_loss=0.864, diversity_loss=-0, d_penalty=0, g_penalty=0, is_synthetic=0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m     trainer.discriminator_optimizer.load_state_dict(checkpoint[\u001b[33m'\u001b[39m\u001b[33mdiscriminator_optimizer_state_dict\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcheckpoints_v1_512_retrain/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smrt-transformer/02. Research-model/train.py:370\u001b[39m, in \u001b[36mSmartContractTrainer.train\u001b[39m\u001b[34m(self, num_epochs, checkpoint_dir)\u001b[39m\n\u001b[32m    367\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    369\u001b[39m \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m train_metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;66;03m# Validation phase\u001b[39;00m\n\u001b[32m    373\u001b[39m val_metrics = \u001b[38;5;28mself\u001b[39m.validate()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smrt-transformer/02. Research-model/train.py:174\u001b[39m, in \u001b[36mSmartContractTrainer.train_epoch\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;66;03m# Generate synthetic data\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     synthetic_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_input_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     synthetic_encoder_output = synthetic_outputs[\u001b[33m'\u001b[39m\u001b[33mencoder_output\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    183\u001b[39m \u001b[38;5;66;03m# Train discriminator on synthetic data\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smrt-transformer/02. Research-model/model.py:138\u001b[39m, in \u001b[36mSmartContractTransformer.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, path_input_ids, path_attention_mask, target_ids)\u001b[39m\n\u001b[32m    135\u001b[39m max_len = \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m.max_length, \u001b[32m50\u001b[39m)  \u001b[38;5;66;03m# Limit generation length to prevent infinite loops\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_len - \u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     tgt_mask = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_square_subsequent_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m    139\u001b[39m     tgt_pos = torch.arange(\u001b[32m0\u001b[39m, tgt.size(\u001b[32m1\u001b[39m), device=device).unsqueeze(\u001b[32m0\u001b[39m).expand(batch_size, -\u001b[32m1\u001b[39m)\n\u001b[32m    141\u001b[39m     tgt_emb = \u001b[38;5;28mself\u001b[39m.embedding(tgt) * (\u001b[38;5;28mself\u001b[39m.d_model ** \u001b[32m0.5\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/smrt-transformer/02. Research-model/model.py:72\u001b[39m, in \u001b[36mSmartContractTransformer.generate_square_subsequent_mask\u001b[39m\u001b[34m(self, sz)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_square_subsequent_mask\u001b[39m(\u001b[38;5;28mself\u001b[39m, sz):\n\u001b[32m     71\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Generate a square mask for the sequence\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     mask = (\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtriu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43msz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m == \u001b[32m1\u001b[39m).transpose(\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m     73\u001b[39m     mask = mask.float().masked_fill(mask == \u001b[32m0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m-inf\u001b[39m\u001b[33m'\u001b[39m)).masked_fill(mask == \u001b[32m1\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[32m0.0\u001b[39m))\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mask\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer = SmartContractTrainer(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    learning_rate=0.02,\n",
    "    weight_decay=0.002,\n",
    "    max_grad_norm=1.0,\n",
    "    gpu_id=1\n",
    ")\n",
    "\n",
    "# Load optimizer states if available\n",
    "if 'optimizer_state_dict' in checkpoint:\n",
    "    trainer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "if 'discriminator_optimizer_state_dict' in checkpoint:\n",
    "    trainer.discriminator_optimizer.load_state_dict(checkpoint['discriminator_optimizer_state_dict'])\n",
    "\n",
    "# Start training\n",
    "trainer.train(num_epochs=200, checkpoint_dir='checkpoints_v1_512_retrain/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915c3b0-0b6d-46bc-99af-bf58c4d2f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22e7129b-5411-4831-82fa-337a880d3d99",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot generator loss\n",
    "plt.subplot(2, 2, 1)\n",
    "#plt.plot(trainer.training_history['train_loss'], label='Train')\n",
    "plt.plot(trainer.training_history['val_loss'], label='Validation')\n",
    "plt.title('Generator Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot vulnerability loss\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(trainer.training_history['vulnerability_loss'])\n",
    "plt.title('Vulnerability Detection Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Plot synthetic loss\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(trainer.training_history['synthetic_loss'])\n",
    "plt.title('Synthetic Detection Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Plot learning rate\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(trainer.training_history['learning_rate'])\n",
    "plt.title('Learning Rate')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd835ecb-c7c1-4b26-96bc-0e4904f46bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from epoch 20\n",
      "Previous validation loss: 0.0070\n"
     ]
    }
   ],
   "source": [
    "# Load checkpoint\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint_epoch_20_model_v3.pt')  # Change this to your checkpoint file\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# Load model states\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "model.discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
    "model.decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "\n",
    "# Load optimizer states\n",
    "trainer.optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])\n",
    "trainer.optimizer_D.load_state_dict(checkpoint['optimizer_D_state_dict'])\n",
    "trainer.optimizer_decoder.load_state_dict(checkpoint['optimizer_decoder_state_dict'])\n",
    "\n",
    "# Get the epoch to start from and best validation loss\n",
    "start_epoch = checkpoint['epoch']\n",
    "best_val_loss = checkpoint['val_loss']\n",
    "\n",
    "print(f\"Loaded checkpoint from epoch {start_epoch + 1}\")\n",
    "print(f\"Previous validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26779f5-56bc-4d32-9c6a-81ce63c676c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training epoch...\n"
     ]
    }
   ],
   "source": [
    "# Training loop - start from the next epoch\n",
    "num_epochs = 120\n",
    "\n",
    "for epoch in range(start_epoch + 1, num_epochs):  # Start from the next epoch\n",
    "    # Start timer for this epoch\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    # Training\n",
    "    g_loss, d_loss, decoder_loss = trainer.train_epoch()\n",
    "    val_loss = trainer.validate()\n",
    "    \n",
    "    # Calculate epoch time\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    \n",
    "    # Print training progress\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Generator Loss: {g_loss:.4f}\")\n",
    "    print(f\"Discriminator Loss: {d_loss:.4f}\")\n",
    "    print(f\"Decoder Loss: {decoder_loss:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    print(f\"Epoch Time: {epoch_time:.2f}s\")\n",
    "    \n",
    "    # Save model checkpoint\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        checkpoint = {\n",
    "            # Model states\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'generator_state_dict': model.generator.state_dict(),\n",
    "            'discriminator_state_dict': model.discriminator.state_dict(),\n",
    "            'decoder_state_dict': model.decoder.state_dict(),\n",
    "            \n",
    "            # Optimizer states\n",
    "            'optimizer_G_state_dict': trainer.optimizer_G.state_dict(),\n",
    "            'optimizer_D_state_dict': trainer.optimizer_D.state_dict(),\n",
    "            'optimizer_decoder_state_dict': trainer.optimizer_decoder.state_dict(),\n",
    "            \n",
    "            # Loss values\n",
    "            'g_loss': g_loss,\n",
    "            'd_loss': d_loss,\n",
    "            'decoder_loss': decoder_loss,\n",
    "            'val_loss': val_loss,\n",
    "            \n",
    "            # Model configuration\n",
    "            'model_config': {\n",
    "                'vocab_size': model.decoder.vocab_size,\n",
    "                'max_length': model.decoder.max_length\n",
    "            },\n",
    "            \n",
    "            # Training metadata\n",
    "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            'epoch_time': epoch_time\n",
    "        }\n",
    "        \n",
    "        # Save regular checkpoint\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}_model_v3.pt')\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"Saved checkpoint for epoch {epoch+1}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_path = os.path.join(checkpoint_dir, 'best_model_v3.pt')\n",
    "            torch.save(checkpoint, best_model_path)\n",
    "            print(f\"New best model saved with validation loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a9277d-d896-44c6-af23-db7512b8f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1088dc1-ee3e-457b-980f-cbfa67896dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6116b2b-55dc-4842-8794-88283e9e2acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64ca8665-9d47-4383-8fbf-ec85abb2ba8d",
   "metadata": {},
   "source": [
    "NOTES:\n",
    "\n",
    "1. Input Processing:\n",
    "Initial input: [32, 512] (batch_size=32, sequence_length=512)\n",
    "After embedding: [32, 512, 512] (batch_size=32, sequence_length=512, embedding_dim=512)\n",
    "This is correct because the embedding layer converts each token to a 512-dimensional vector\n",
    "\n",
    "2. Path Embeddings Processing:\n",
    "Initial path embeddings: [32, 768] (batch_size=32, code2vec_dim=768)\n",
    "After path embedding layer: [32, 512] (batch_size=32, transformer_dim=512)\n",
    "The linear layer converts from code2vec's 768 dimensions to transformer's 512 dimensions\n",
    "After expansion: [32, 512, 512] (batch_size=32, sequence_length=512, transformer_dim=512)\n",
    "The path embeddings are expanded to match the sequence length\n",
    "\n",
    "3. Final Shape:\n",
    "[32, 512, 512] (batch_size=32, sequence_length=512, transformer_dim=512)\n",
    "This is the correct shape for the transformer layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc9d4bfa-25f5-4b56-b679-44fc3102049e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint for epoch 10\n"
     ]
    }
   ],
   "source": [
    "checkpoint = {\n",
    "    # Model states\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'generator_state_dict': model.generator.state_dict(),\n",
    "    'discriminator_state_dict': model.discriminator.state_dict(),\n",
    "    'decoder_state_dict': model.decoder.state_dict(),\n",
    "    \n",
    "    # Optimizer states\n",
    "    'optimizer_G_state_dict': trainer.optimizer_G.state_dict(),\n",
    "    'optimizer_D_state_dict': trainer.optimizer_D.state_dict(),\n",
    "    'optimizer_decoder_state_dict': trainer.optimizer_decoder.state_dict(),\n",
    "    \n",
    "    # Loss values\n",
    "    'g_loss': g_loss,\n",
    "    'd_loss': d_loss,\n",
    "    'decoder_loss': decoder_loss,\n",
    "    'val_loss': val_loss,\n",
    "    \n",
    "    # Model configuration\n",
    "    'model_config': {\n",
    "        #'d_model': model.d_model,\n",
    "        'vocab_size': model.decoder.vocab_size,\n",
    "        'max_length': model.decoder.max_length\n",
    "    },\n",
    "    \n",
    "    # Training metadata\n",
    "    'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    'epoch_time': epoch_time\n",
    "}\n",
    "\n",
    "# Save regular checkpoint\n",
    "checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}_model_v3.pt')\n",
    "torch.save(checkpoint, checkpoint_path)\n",
    "print(f\"Saved checkpoint for epoch {epoch+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "812eafcf-c1de-4283-905d-9943fcacffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [119/120]\n",
      "Generator Loss: 10.5703\n",
      "Discriminator Loss: 0.0062\n",
      "Validation Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "print(f\"Epoch [{epoch}/{num_epochs}]\")\n",
    "print(f\"Generator Loss: {g_loss:.4f}\")\n",
    "print(f\"Discriminator Loss: {d_loss:.4f}\")\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144f2e17-41c2-4553-a974-d92ec9add514",
   "metadata": {},
   "source": [
    "## Save model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c34b13-9ee1-466b-a751-f7d898d7bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch': 100,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    #'optimizer_G_state_dict': trainer.optimizer_G.state_dict(),\n",
    "    #'optimizer_D_state_dict': trainer.optimizer_D.state_dict(),\n",
    "    'gen_loss': model.gen_loss,\n",
    "    'synth_loss': model.synth_loss,\n",
    "    'vul_loss': model.vul_loss,\n",
    "    'val_loss': model.val_loss,\n",
    "    'model_config': {\n",
    "        'd_model': 768,\n",
    "    }\n",
    "}, 'final_model_v1_512.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a542cf7e-3f9a-405f-b855-74f4ed22cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training loop\n",
    "# Save the final model and training state\n",
    "\n",
    "\n",
    "# If you want to save just the model for inference\n",
    "torch.save(model.state_dict(), 'model_weights_v1_512.pt')\n",
    "\n",
    "# If you want to save the entire model\n",
    "torch.save(model, 'full_model_v1_512.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4518ba2-796c-4576-b707-dce9b7b50f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model with additional information\n",
    "torch.save({\n",
    "    'epoch': num_epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_G_state_dict': trainer.optimizer_G.state_dict(),\n",
    "    'optimizer_D_state_dict': trainer.optimizer_D.state_dict(),\n",
    "    'g_loss': g_loss,\n",
    "    'd_loss': d_loss,\n",
    "    'val_loss': val_loss,\n",
    "    'model_config': {\n",
    "        'd_model': 768\n",
    "    },\n",
    "    'training_config': {\n",
    "        'learning_rate': 0.0002,\n",
    "        'beta1': 0.5,\n",
    "        'batch_size': 32\n",
    "    },\n",
    "    'training_history': {\n",
    "        'g_losses': g_loss,  # List of generator losses\n",
    "        'd_losses': d_loss,  # List of discriminator losses\n",
    "        'val_losses': val_loss  # List of validation losses\n",
    "    }\n",
    "}, 'final_model_v4_with_history.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bdb45a-1d83-4f1c-ba3d-537122d6d20d",
   "metadata": {},
   "source": [
    "# Load Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9c635a8-7b46-4a65-8310-6752630ea0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full training state\n",
    "checkpoint = torch.load('final_model_v4.pt')\n",
    "model = SmartContractVulnerabilityGAN(**checkpoint['model_config'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.cuda() \n",
    "\n",
    "# Initialize trainer with loaded model\n",
    "trainer = VulnerabilityDetectionTrainer(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    val_dataloader\n",
    ")\n",
    "\n",
    "# Load optimizer states if needed\n",
    "trainer.optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])\n",
    "trainer.optimizer_D.load_state_dict(checkpoint['optimizer_D_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73a2faac-91c0-42d9-8166-27b46ca15918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or if you just want to load the model weights\n",
    "model = SmartContractVulnerabilityGAN(d_model=768)\n",
    "model.load_state_dict(torch.load('model_weights.pt'))\n",
    "model = model.cuda()  # Move to GPU if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f084e260-1dab-4400-8cd1-23de24a06f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or if you saved the entire model\n",
    "model = torch.load('full_model.pt')\n",
    "model = model.cuda()  # Move to GPU if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882d56c1-6276-4a53-a46f-eef634bdbcb5",
   "metadata": {},
   "source": [
    "## Model Exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53f7a67e-c86b-4b37-83cd-ac2bd8f74be7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of model: <class 'model.SmartContractVulnerabilityGAN'>\n",
      "\n",
      "Model Components:\n",
      "--------------------------------------------------\n",
      "\n",
      "Model Attributes:\n",
      "- T_destination\n",
      "- add_module\n",
      "- apply\n",
      "- bfloat16\n",
      "- buffers\n",
      "- call_super_init\n",
      "- children\n",
      "- codebert\n",
      "- compile\n",
      "- cpu\n",
      "- cuda\n",
      "- decode_embeddings\n",
      "- decoder\n",
      "- discriminator\n",
      "- double\n",
      "- dump_patches\n",
      "- eval\n",
      "- extra_repr\n",
      "- float\n",
      "- forward\n",
      "- generate_code\n",
      "- generator\n",
      "- get_buffer\n",
      "- get_extra_state\n",
      "- get_parameter\n",
      "- get_submodule\n",
      "- half\n",
      "- ipu\n",
      "- load_state_dict\n",
      "- modules\n",
      "- named_buffers\n",
      "- named_children\n",
      "- named_modules\n",
      "- named_parameters\n",
      "- parameters\n",
      "- register_backward_hook\n",
      "- register_buffer\n",
      "- register_forward_hook\n",
      "- register_forward_pre_hook\n",
      "- register_full_backward_hook\n",
      "- register_full_backward_pre_hook\n",
      "- register_load_state_dict_post_hook\n",
      "- register_module\n",
      "- register_parameter\n",
      "- register_state_dict_pre_hook\n",
      "- requires_grad_\n",
      "- set_extra_state\n",
      "- share_memory\n",
      "- state_dict\n",
      "- to\n",
      "- to_empty\n",
      "- tokenizer\n",
      "- train\n",
      "- training\n",
      "- transformer\n",
      "- type\n",
      "- xpu\n",
      "- zero_grad\n",
      "\n",
      "Model Structure:\n",
      "SmartContractVulnerabilityGAN(\n",
      "  (codebert): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): RobertaPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (transformer): SmartContractTransformer(\n",
      "    (transformer): TransformerEncoderLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (linear1): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (linear2): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (generator): Generator(\n",
      "    (main): Sequential(\n",
      "      (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=256, out_features=768, bias=True)\n",
      "      (7): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (discriminator): Discriminator(\n",
      "    (main): Sequential(\n",
      "      (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2)\n",
      "      (3): Dropout(p=0.3, inplace=False)\n",
      "      (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (6): LeakyReLU(negative_slope=0.2)\n",
      "      (7): Dropout(p=0.3, inplace=False)\n",
      "      (8): Linear(in_features=256, out_features=1, bias=True)\n",
      "      (9): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (decoder): CodeDecoder(\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-2): 3 x TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=1536, out_features=768, bias=True)\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(50000, 768)\n",
      "    (output_layer): Linear(in_features=768, out_features=50000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of model:\", type(model))\n",
    "\n",
    "# If it's a SmartContractVulnerabilityGAN object, we can inspect its components directly\n",
    "print(\"\\nModel Components:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Print model attributes\n",
    "print(\"\\nModel Attributes:\")\n",
    "for attr in dir(model):\n",
    "    if not attr.startswith('_'):  # Skip private attributes\n",
    "        print(f\"- {attr}\")\n",
    "\n",
    "# Print model structure\n",
    "print(\"\\nModel Structure:\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b9b5e4b-7ac0-4cdf-a029-11b68f2d6b00",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model State Dict:\n",
      "- codebert.embeddings.word_embeddings.weight\n",
      "- codebert.embeddings.position_embeddings.weight\n",
      "- codebert.embeddings.token_type_embeddings.weight\n",
      "- codebert.embeddings.LayerNorm.weight\n",
      "- codebert.embeddings.LayerNorm.bias\n",
      "- codebert.encoder.layer.0.attention.self.query.weight\n",
      "- codebert.encoder.layer.0.attention.self.query.bias\n",
      "- codebert.encoder.layer.0.attention.self.key.weight\n",
      "- codebert.encoder.layer.0.attention.self.key.bias\n",
      "- codebert.encoder.layer.0.attention.self.value.weight\n",
      "- codebert.encoder.layer.0.attention.self.value.bias\n",
      "- codebert.encoder.layer.0.attention.output.dense.weight\n",
      "- codebert.encoder.layer.0.attention.output.dense.bias\n",
      "- codebert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.0.intermediate.dense.weight\n",
      "- codebert.encoder.layer.0.intermediate.dense.bias\n",
      "- codebert.encoder.layer.0.output.dense.weight\n",
      "- codebert.encoder.layer.0.output.dense.bias\n",
      "- codebert.encoder.layer.0.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.0.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.1.attention.self.query.weight\n",
      "- codebert.encoder.layer.1.attention.self.query.bias\n",
      "- codebert.encoder.layer.1.attention.self.key.weight\n",
      "- codebert.encoder.layer.1.attention.self.key.bias\n",
      "- codebert.encoder.layer.1.attention.self.value.weight\n",
      "- codebert.encoder.layer.1.attention.self.value.bias\n",
      "- codebert.encoder.layer.1.attention.output.dense.weight\n",
      "- codebert.encoder.layer.1.attention.output.dense.bias\n",
      "- codebert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.1.intermediate.dense.weight\n",
      "- codebert.encoder.layer.1.intermediate.dense.bias\n",
      "- codebert.encoder.layer.1.output.dense.weight\n",
      "- codebert.encoder.layer.1.output.dense.bias\n",
      "- codebert.encoder.layer.1.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.1.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.2.attention.self.query.weight\n",
      "- codebert.encoder.layer.2.attention.self.query.bias\n",
      "- codebert.encoder.layer.2.attention.self.key.weight\n",
      "- codebert.encoder.layer.2.attention.self.key.bias\n",
      "- codebert.encoder.layer.2.attention.self.value.weight\n",
      "- codebert.encoder.layer.2.attention.self.value.bias\n",
      "- codebert.encoder.layer.2.attention.output.dense.weight\n",
      "- codebert.encoder.layer.2.attention.output.dense.bias\n",
      "- codebert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.2.intermediate.dense.weight\n",
      "- codebert.encoder.layer.2.intermediate.dense.bias\n",
      "- codebert.encoder.layer.2.output.dense.weight\n",
      "- codebert.encoder.layer.2.output.dense.bias\n",
      "- codebert.encoder.layer.2.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.2.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.3.attention.self.query.weight\n",
      "- codebert.encoder.layer.3.attention.self.query.bias\n",
      "- codebert.encoder.layer.3.attention.self.key.weight\n",
      "- codebert.encoder.layer.3.attention.self.key.bias\n",
      "- codebert.encoder.layer.3.attention.self.value.weight\n",
      "- codebert.encoder.layer.3.attention.self.value.bias\n",
      "- codebert.encoder.layer.3.attention.output.dense.weight\n",
      "- codebert.encoder.layer.3.attention.output.dense.bias\n",
      "- codebert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.3.intermediate.dense.weight\n",
      "- codebert.encoder.layer.3.intermediate.dense.bias\n",
      "- codebert.encoder.layer.3.output.dense.weight\n",
      "- codebert.encoder.layer.3.output.dense.bias\n",
      "- codebert.encoder.layer.3.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.3.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.4.attention.self.query.weight\n",
      "- codebert.encoder.layer.4.attention.self.query.bias\n",
      "- codebert.encoder.layer.4.attention.self.key.weight\n",
      "- codebert.encoder.layer.4.attention.self.key.bias\n",
      "- codebert.encoder.layer.4.attention.self.value.weight\n",
      "- codebert.encoder.layer.4.attention.self.value.bias\n",
      "- codebert.encoder.layer.4.attention.output.dense.weight\n",
      "- codebert.encoder.layer.4.attention.output.dense.bias\n",
      "- codebert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.4.intermediate.dense.weight\n",
      "- codebert.encoder.layer.4.intermediate.dense.bias\n",
      "- codebert.encoder.layer.4.output.dense.weight\n",
      "- codebert.encoder.layer.4.output.dense.bias\n",
      "- codebert.encoder.layer.4.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.4.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.5.attention.self.query.weight\n",
      "- codebert.encoder.layer.5.attention.self.query.bias\n",
      "- codebert.encoder.layer.5.attention.self.key.weight\n",
      "- codebert.encoder.layer.5.attention.self.key.bias\n",
      "- codebert.encoder.layer.5.attention.self.value.weight\n",
      "- codebert.encoder.layer.5.attention.self.value.bias\n",
      "- codebert.encoder.layer.5.attention.output.dense.weight\n",
      "- codebert.encoder.layer.5.attention.output.dense.bias\n",
      "- codebert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.5.intermediate.dense.weight\n",
      "- codebert.encoder.layer.5.intermediate.dense.bias\n",
      "- codebert.encoder.layer.5.output.dense.weight\n",
      "- codebert.encoder.layer.5.output.dense.bias\n",
      "- codebert.encoder.layer.5.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.5.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.6.attention.self.query.weight\n",
      "- codebert.encoder.layer.6.attention.self.query.bias\n",
      "- codebert.encoder.layer.6.attention.self.key.weight\n",
      "- codebert.encoder.layer.6.attention.self.key.bias\n",
      "- codebert.encoder.layer.6.attention.self.value.weight\n",
      "- codebert.encoder.layer.6.attention.self.value.bias\n",
      "- codebert.encoder.layer.6.attention.output.dense.weight\n",
      "- codebert.encoder.layer.6.attention.output.dense.bias\n",
      "- codebert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.6.intermediate.dense.weight\n",
      "- codebert.encoder.layer.6.intermediate.dense.bias\n",
      "- codebert.encoder.layer.6.output.dense.weight\n",
      "- codebert.encoder.layer.6.output.dense.bias\n",
      "- codebert.encoder.layer.6.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.6.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.7.attention.self.query.weight\n",
      "- codebert.encoder.layer.7.attention.self.query.bias\n",
      "- codebert.encoder.layer.7.attention.self.key.weight\n",
      "- codebert.encoder.layer.7.attention.self.key.bias\n",
      "- codebert.encoder.layer.7.attention.self.value.weight\n",
      "- codebert.encoder.layer.7.attention.self.value.bias\n",
      "- codebert.encoder.layer.7.attention.output.dense.weight\n",
      "- codebert.encoder.layer.7.attention.output.dense.bias\n",
      "- codebert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.7.intermediate.dense.weight\n",
      "- codebert.encoder.layer.7.intermediate.dense.bias\n",
      "- codebert.encoder.layer.7.output.dense.weight\n",
      "- codebert.encoder.layer.7.output.dense.bias\n",
      "- codebert.encoder.layer.7.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.7.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.8.attention.self.query.weight\n",
      "- codebert.encoder.layer.8.attention.self.query.bias\n",
      "- codebert.encoder.layer.8.attention.self.key.weight\n",
      "- codebert.encoder.layer.8.attention.self.key.bias\n",
      "- codebert.encoder.layer.8.attention.self.value.weight\n",
      "- codebert.encoder.layer.8.attention.self.value.bias\n",
      "- codebert.encoder.layer.8.attention.output.dense.weight\n",
      "- codebert.encoder.layer.8.attention.output.dense.bias\n",
      "- codebert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.8.intermediate.dense.weight\n",
      "- codebert.encoder.layer.8.intermediate.dense.bias\n",
      "- codebert.encoder.layer.8.output.dense.weight\n",
      "- codebert.encoder.layer.8.output.dense.bias\n",
      "- codebert.encoder.layer.8.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.8.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.9.attention.self.query.weight\n",
      "- codebert.encoder.layer.9.attention.self.query.bias\n",
      "- codebert.encoder.layer.9.attention.self.key.weight\n",
      "- codebert.encoder.layer.9.attention.self.key.bias\n",
      "- codebert.encoder.layer.9.attention.self.value.weight\n",
      "- codebert.encoder.layer.9.attention.self.value.bias\n",
      "- codebert.encoder.layer.9.attention.output.dense.weight\n",
      "- codebert.encoder.layer.9.attention.output.dense.bias\n",
      "- codebert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.9.intermediate.dense.weight\n",
      "- codebert.encoder.layer.9.intermediate.dense.bias\n",
      "- codebert.encoder.layer.9.output.dense.weight\n",
      "- codebert.encoder.layer.9.output.dense.bias\n",
      "- codebert.encoder.layer.9.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.9.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.10.attention.self.query.weight\n",
      "- codebert.encoder.layer.10.attention.self.query.bias\n",
      "- codebert.encoder.layer.10.attention.self.key.weight\n",
      "- codebert.encoder.layer.10.attention.self.key.bias\n",
      "- codebert.encoder.layer.10.attention.self.value.weight\n",
      "- codebert.encoder.layer.10.attention.self.value.bias\n",
      "- codebert.encoder.layer.10.attention.output.dense.weight\n",
      "- codebert.encoder.layer.10.attention.output.dense.bias\n",
      "- codebert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.10.intermediate.dense.weight\n",
      "- codebert.encoder.layer.10.intermediate.dense.bias\n",
      "- codebert.encoder.layer.10.output.dense.weight\n",
      "- codebert.encoder.layer.10.output.dense.bias\n",
      "- codebert.encoder.layer.10.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.10.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.11.attention.self.query.weight\n",
      "- codebert.encoder.layer.11.attention.self.query.bias\n",
      "- codebert.encoder.layer.11.attention.self.key.weight\n",
      "- codebert.encoder.layer.11.attention.self.key.bias\n",
      "- codebert.encoder.layer.11.attention.self.value.weight\n",
      "- codebert.encoder.layer.11.attention.self.value.bias\n",
      "- codebert.encoder.layer.11.attention.output.dense.weight\n",
      "- codebert.encoder.layer.11.attention.output.dense.bias\n",
      "- codebert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "- codebert.encoder.layer.11.intermediate.dense.weight\n",
      "- codebert.encoder.layer.11.intermediate.dense.bias\n",
      "- codebert.encoder.layer.11.output.dense.weight\n",
      "- codebert.encoder.layer.11.output.dense.bias\n",
      "- codebert.encoder.layer.11.output.LayerNorm.weight\n",
      "- codebert.encoder.layer.11.output.LayerNorm.bias\n",
      "- codebert.pooler.dense.weight\n",
      "- codebert.pooler.dense.bias\n",
      "- transformer.transformer.self_attn.in_proj_weight\n",
      "- transformer.transformer.self_attn.in_proj_bias\n",
      "- transformer.transformer.self_attn.out_proj.weight\n",
      "- transformer.transformer.self_attn.out_proj.bias\n",
      "- transformer.transformer.linear1.weight\n",
      "- transformer.transformer.linear1.bias\n",
      "- transformer.transformer.linear2.weight\n",
      "- transformer.transformer.linear2.bias\n",
      "- transformer.transformer.norm1.weight\n",
      "- transformer.transformer.norm1.bias\n",
      "- transformer.transformer.norm2.weight\n",
      "- transformer.transformer.norm2.bias\n",
      "- transformer.layer_norm.weight\n",
      "- transformer.layer_norm.bias\n",
      "- generator.main.0.weight\n",
      "- generator.main.0.bias\n",
      "- generator.main.1.weight\n",
      "- generator.main.1.bias\n",
      "- generator.main.3.weight\n",
      "- generator.main.3.bias\n",
      "- generator.main.4.weight\n",
      "- generator.main.4.bias\n",
      "- generator.main.6.weight\n",
      "- generator.main.6.bias\n",
      "- discriminator.main.0.weight\n",
      "- discriminator.main.0.bias\n",
      "- discriminator.main.1.weight\n",
      "- discriminator.main.1.bias\n",
      "- discriminator.main.4.weight\n",
      "- discriminator.main.4.bias\n",
      "- discriminator.main.5.weight\n",
      "- discriminator.main.5.bias\n",
      "- discriminator.main.8.weight\n",
      "- discriminator.main.8.bias\n",
      "- decoder.pos_encoder\n",
      "- decoder.decoder.layers.0.self_attn.in_proj_weight\n",
      "- decoder.decoder.layers.0.self_attn.in_proj_bias\n",
      "- decoder.decoder.layers.0.self_attn.out_proj.weight\n",
      "- decoder.decoder.layers.0.self_attn.out_proj.bias\n",
      "- decoder.decoder.layers.0.multihead_attn.in_proj_weight\n",
      "- decoder.decoder.layers.0.multihead_attn.in_proj_bias\n",
      "- decoder.decoder.layers.0.multihead_attn.out_proj.weight\n",
      "- decoder.decoder.layers.0.multihead_attn.out_proj.bias\n",
      "- decoder.decoder.layers.0.linear1.weight\n",
      "- decoder.decoder.layers.0.linear1.bias\n",
      "- decoder.decoder.layers.0.linear2.weight\n",
      "- decoder.decoder.layers.0.linear2.bias\n",
      "- decoder.decoder.layers.0.norm1.weight\n",
      "- decoder.decoder.layers.0.norm1.bias\n",
      "- decoder.decoder.layers.0.norm2.weight\n",
      "- decoder.decoder.layers.0.norm2.bias\n",
      "- decoder.decoder.layers.0.norm3.weight\n",
      "- decoder.decoder.layers.0.norm3.bias\n",
      "- decoder.decoder.layers.1.self_attn.in_proj_weight\n",
      "- decoder.decoder.layers.1.self_attn.in_proj_bias\n",
      "- decoder.decoder.layers.1.self_attn.out_proj.weight\n",
      "- decoder.decoder.layers.1.self_attn.out_proj.bias\n",
      "- decoder.decoder.layers.1.multihead_attn.in_proj_weight\n",
      "- decoder.decoder.layers.1.multihead_attn.in_proj_bias\n",
      "- decoder.decoder.layers.1.multihead_attn.out_proj.weight\n",
      "- decoder.decoder.layers.1.multihead_attn.out_proj.bias\n",
      "- decoder.decoder.layers.1.linear1.weight\n",
      "- decoder.decoder.layers.1.linear1.bias\n",
      "- decoder.decoder.layers.1.linear2.weight\n",
      "- decoder.decoder.layers.1.linear2.bias\n",
      "- decoder.decoder.layers.1.norm1.weight\n",
      "- decoder.decoder.layers.1.norm1.bias\n",
      "- decoder.decoder.layers.1.norm2.weight\n",
      "- decoder.decoder.layers.1.norm2.bias\n",
      "- decoder.decoder.layers.1.norm3.weight\n",
      "- decoder.decoder.layers.1.norm3.bias\n",
      "- decoder.decoder.layers.2.self_attn.in_proj_weight\n",
      "- decoder.decoder.layers.2.self_attn.in_proj_bias\n",
      "- decoder.decoder.layers.2.self_attn.out_proj.weight\n",
      "- decoder.decoder.layers.2.self_attn.out_proj.bias\n",
      "- decoder.decoder.layers.2.multihead_attn.in_proj_weight\n",
      "- decoder.decoder.layers.2.multihead_attn.in_proj_bias\n",
      "- decoder.decoder.layers.2.multihead_attn.out_proj.weight\n",
      "- decoder.decoder.layers.2.multihead_attn.out_proj.bias\n",
      "- decoder.decoder.layers.2.linear1.weight\n",
      "- decoder.decoder.layers.2.linear1.bias\n",
      "- decoder.decoder.layers.2.linear2.weight\n",
      "- decoder.decoder.layers.2.linear2.bias\n",
      "- decoder.decoder.layers.2.norm1.weight\n",
      "- decoder.decoder.layers.2.norm1.bias\n",
      "- decoder.decoder.layers.2.norm2.weight\n",
      "- decoder.decoder.layers.2.norm2.bias\n",
      "- decoder.decoder.layers.2.norm3.weight\n",
      "- decoder.decoder.layers.2.norm3.bias\n",
      "- decoder.embedding.weight\n",
      "- decoder.output_layer.weight\n",
      "- decoder.output_layer.bias\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel State Dict:\")\n",
    "for key in model.state_dict().keys():\n",
    "    print(f\"- {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a484d444-0ca8-4797-8cb4-bc6d43761d32",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameter Shapes:\n",
      "- codebert.embeddings.word_embeddings.weight: torch.Size([50265, 768])\n",
      "- codebert.embeddings.position_embeddings.weight: torch.Size([514, 768])\n",
      "- codebert.embeddings.token_type_embeddings.weight: torch.Size([1, 768])\n",
      "- codebert.embeddings.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.embeddings.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.0.attention.self.query.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.0.attention.self.query.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.0.attention.self.key.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.0.attention.self.key.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.0.attention.self.value.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.0.attention.self.value.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.0.attention.output.dense.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.0.attention.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.0.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.0.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.0.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "- codebert.encoder.layer.0.intermediate.dense.bias: torch.Size([3072])\n",
      "- codebert.encoder.layer.0.output.dense.weight: torch.Size([768, 3072])\n",
      "- codebert.encoder.layer.0.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.0.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.0.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.1.attention.self.query.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.1.attention.self.query.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.1.attention.self.key.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.1.attention.self.key.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.1.attention.self.value.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.1.attention.self.value.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.1.attention.output.dense.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.1.attention.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.1.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.1.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.1.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "- codebert.encoder.layer.1.intermediate.dense.bias: torch.Size([3072])\n",
      "- codebert.encoder.layer.1.output.dense.weight: torch.Size([768, 3072])\n",
      "- codebert.encoder.layer.1.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.1.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.1.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.2.attention.self.query.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.2.attention.self.query.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.2.attention.self.key.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.2.attention.self.key.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.2.attention.self.value.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.2.attention.self.value.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.2.attention.output.dense.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.2.attention.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.2.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.2.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.2.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "- codebert.encoder.layer.2.intermediate.dense.bias: torch.Size([3072])\n",
      "- codebert.encoder.layer.2.output.dense.weight: torch.Size([768, 3072])\n",
      "- codebert.encoder.layer.2.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.2.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.2.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.3.attention.self.query.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.3.attention.self.query.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.3.attention.self.key.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.3.attention.self.key.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.3.attention.self.value.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.3.attention.self.value.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.3.attention.output.dense.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.3.attention.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.3.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.3.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.3.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "- codebert.encoder.layer.3.intermediate.dense.bias: torch.Size([3072])\n",
      "- codebert.encoder.layer.3.output.dense.weight: torch.Size([768, 3072])\n",
      "- codebert.encoder.layer.3.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.3.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.3.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.4.attention.self.query.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.4.attention.self.query.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.4.attention.self.key.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.4.attention.self.key.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.4.attention.self.value.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.4.attention.self.value.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.4.attention.output.dense.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.4.attention.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.4.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.4.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.4.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "- codebert.encoder.layer.4.intermediate.dense.bias: torch.Size([3072])\n",
      "- codebert.encoder.layer.4.output.dense.weight: torch.Size([768, 3072])\n",
      "- codebert.encoder.layer.4.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.4.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.4.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.5.attention.self.query.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.5.attention.self.query.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.5.attention.self.key.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.5.attention.self.key.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.5.attention.self.value.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.5.attention.self.value.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.5.attention.output.dense.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.5.attention.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.5.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.5.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.5.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "- codebert.encoder.layer.5.intermediate.dense.bias: torch.Size([3072])\n",
      "- codebert.encoder.layer.5.output.dense.weight: torch.Size([768, 3072])\n",
      "- codebert.encoder.layer.5.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.5.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.5.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.6.attention.self.query.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.6.attention.self.query.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.6.attention.self.key.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.6.attention.self.key.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.6.attention.self.value.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.6.attention.self.value.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.6.attention.output.dense.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.6.attention.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.6.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.6.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.6.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "- codebert.encoder.layer.6.intermediate.dense.bias: torch.Size([3072])\n",
      "- codebert.encoder.layer.6.output.dense.weight: torch.Size([768, 3072])\n",
      "- codebert.encoder.layer.6.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.6.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.6.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.7.attention.self.query.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.7.attention.self.query.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.7.attention.self.key.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.7.attention.self.key.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.7.attention.self.value.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.7.attention.self.value.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.7.attention.output.dense.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.7.attention.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.7.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.7.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.7.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "- codebert.encoder.layer.7.intermediate.dense.bias: torch.Size([3072])\n",
      "- codebert.encoder.layer.7.output.dense.weight: torch.Size([768, 3072])\n",
      "- codebert.encoder.layer.7.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.7.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.7.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.8.attention.self.query.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.8.attention.self.query.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.8.attention.self.key.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.8.attention.self.key.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.8.attention.self.value.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.8.attention.self.value.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.8.attention.output.dense.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.8.attention.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.8.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.8.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.8.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "- codebert.encoder.layer.8.intermediate.dense.bias: torch.Size([3072])\n",
      "- codebert.encoder.layer.8.output.dense.weight: torch.Size([768, 3072])\n",
      "- codebert.encoder.layer.8.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.8.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.8.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.9.attention.self.query.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.9.attention.self.query.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.9.attention.self.key.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.9.attention.self.key.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.9.attention.self.value.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.9.attention.self.value.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.9.attention.output.dense.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.9.attention.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.9.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.9.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.9.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "- codebert.encoder.layer.9.intermediate.dense.bias: torch.Size([3072])\n",
      "- codebert.encoder.layer.9.output.dense.weight: torch.Size([768, 3072])\n",
      "- codebert.encoder.layer.9.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.9.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.9.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.10.attention.self.query.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.10.attention.self.query.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.10.attention.self.key.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.10.attention.self.key.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.10.attention.self.value.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.10.attention.self.value.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.10.attention.output.dense.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.10.attention.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.10.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.10.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.10.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "- codebert.encoder.layer.10.intermediate.dense.bias: torch.Size([3072])\n",
      "- codebert.encoder.layer.10.output.dense.weight: torch.Size([768, 3072])\n",
      "- codebert.encoder.layer.10.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.10.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.10.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.11.attention.self.query.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.11.attention.self.query.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.11.attention.self.key.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.11.attention.self.key.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.11.attention.self.value.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.11.attention.self.value.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.11.attention.output.dense.weight: torch.Size([768, 768])\n",
      "- codebert.encoder.layer.11.attention.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.11.attention.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.11.attention.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.11.intermediate.dense.weight: torch.Size([3072, 768])\n",
      "- codebert.encoder.layer.11.intermediate.dense.bias: torch.Size([3072])\n",
      "- codebert.encoder.layer.11.output.dense.weight: torch.Size([768, 3072])\n",
      "- codebert.encoder.layer.11.output.dense.bias: torch.Size([768])\n",
      "- codebert.encoder.layer.11.output.LayerNorm.weight: torch.Size([768])\n",
      "- codebert.encoder.layer.11.output.LayerNorm.bias: torch.Size([768])\n",
      "- codebert.pooler.dense.weight: torch.Size([768, 768])\n",
      "- codebert.pooler.dense.bias: torch.Size([768])\n",
      "- transformer.transformer.self_attn.in_proj_weight: torch.Size([2304, 768])\n",
      "- transformer.transformer.self_attn.in_proj_bias: torch.Size([2304])\n",
      "- transformer.transformer.self_attn.out_proj.weight: torch.Size([768, 768])\n",
      "- transformer.transformer.self_attn.out_proj.bias: torch.Size([768])\n",
      "- transformer.transformer.linear1.weight: torch.Size([768, 768])\n",
      "- transformer.transformer.linear1.bias: torch.Size([768])\n",
      "- transformer.transformer.linear2.weight: torch.Size([768, 768])\n",
      "- transformer.transformer.linear2.bias: torch.Size([768])\n",
      "- transformer.transformer.norm1.weight: torch.Size([768])\n",
      "- transformer.transformer.norm1.bias: torch.Size([768])\n",
      "- transformer.transformer.norm2.weight: torch.Size([768])\n",
      "- transformer.transformer.norm2.bias: torch.Size([768])\n",
      "- transformer.layer_norm.weight: torch.Size([768])\n",
      "- transformer.layer_norm.bias: torch.Size([768])\n",
      "- generator.main.0.weight: torch.Size([512, 768])\n",
      "- generator.main.0.bias: torch.Size([512])\n",
      "- generator.main.1.weight: torch.Size([512])\n",
      "- generator.main.1.bias: torch.Size([512])\n",
      "- generator.main.3.weight: torch.Size([256, 512])\n",
      "- generator.main.3.bias: torch.Size([256])\n",
      "- generator.main.4.weight: torch.Size([256])\n",
      "- generator.main.4.bias: torch.Size([256])\n",
      "- generator.main.6.weight: torch.Size([768, 256])\n",
      "- generator.main.6.bias: torch.Size([768])\n",
      "- discriminator.main.0.weight: torch.Size([512, 768])\n",
      "- discriminator.main.0.bias: torch.Size([512])\n",
      "- discriminator.main.1.weight: torch.Size([512])\n",
      "- discriminator.main.1.bias: torch.Size([512])\n",
      "- discriminator.main.4.weight: torch.Size([256, 512])\n",
      "- discriminator.main.4.bias: torch.Size([256])\n",
      "- discriminator.main.5.weight: torch.Size([256])\n",
      "- discriminator.main.5.bias: torch.Size([256])\n",
      "- discriminator.main.8.weight: torch.Size([1, 256])\n",
      "- discriminator.main.8.bias: torch.Size([1])\n",
      "- decoder.pos_encoder: torch.Size([1, 512, 768])\n",
      "- decoder.decoder.layers.0.self_attn.in_proj_weight: torch.Size([2304, 768])\n",
      "- decoder.decoder.layers.0.self_attn.in_proj_bias: torch.Size([2304])\n",
      "- decoder.decoder.layers.0.self_attn.out_proj.weight: torch.Size([768, 768])\n",
      "- decoder.decoder.layers.0.self_attn.out_proj.bias: torch.Size([768])\n",
      "- decoder.decoder.layers.0.multihead_attn.in_proj_weight: torch.Size([2304, 768])\n",
      "- decoder.decoder.layers.0.multihead_attn.in_proj_bias: torch.Size([2304])\n",
      "- decoder.decoder.layers.0.multihead_attn.out_proj.weight: torch.Size([768, 768])\n",
      "- decoder.decoder.layers.0.multihead_attn.out_proj.bias: torch.Size([768])\n",
      "- decoder.decoder.layers.0.linear1.weight: torch.Size([1536, 768])\n",
      "- decoder.decoder.layers.0.linear1.bias: torch.Size([1536])\n",
      "- decoder.decoder.layers.0.linear2.weight: torch.Size([768, 1536])\n",
      "- decoder.decoder.layers.0.linear2.bias: torch.Size([768])\n",
      "- decoder.decoder.layers.0.norm1.weight: torch.Size([768])\n",
      "- decoder.decoder.layers.0.norm1.bias: torch.Size([768])\n",
      "- decoder.decoder.layers.0.norm2.weight: torch.Size([768])\n",
      "- decoder.decoder.layers.0.norm2.bias: torch.Size([768])\n",
      "- decoder.decoder.layers.0.norm3.weight: torch.Size([768])\n",
      "- decoder.decoder.layers.0.norm3.bias: torch.Size([768])\n",
      "- decoder.decoder.layers.1.self_attn.in_proj_weight: torch.Size([2304, 768])\n",
      "- decoder.decoder.layers.1.self_attn.in_proj_bias: torch.Size([2304])\n",
      "- decoder.decoder.layers.1.self_attn.out_proj.weight: torch.Size([768, 768])\n",
      "- decoder.decoder.layers.1.self_attn.out_proj.bias: torch.Size([768])\n",
      "- decoder.decoder.layers.1.multihead_attn.in_proj_weight: torch.Size([2304, 768])\n",
      "- decoder.decoder.layers.1.multihead_attn.in_proj_bias: torch.Size([2304])\n",
      "- decoder.decoder.layers.1.multihead_attn.out_proj.weight: torch.Size([768, 768])\n",
      "- decoder.decoder.layers.1.multihead_attn.out_proj.bias: torch.Size([768])\n",
      "- decoder.decoder.layers.1.linear1.weight: torch.Size([1536, 768])\n",
      "- decoder.decoder.layers.1.linear1.bias: torch.Size([1536])\n",
      "- decoder.decoder.layers.1.linear2.weight: torch.Size([768, 1536])\n",
      "- decoder.decoder.layers.1.linear2.bias: torch.Size([768])\n",
      "- decoder.decoder.layers.1.norm1.weight: torch.Size([768])\n",
      "- decoder.decoder.layers.1.norm1.bias: torch.Size([768])\n",
      "- decoder.decoder.layers.1.norm2.weight: torch.Size([768])\n",
      "- decoder.decoder.layers.1.norm2.bias: torch.Size([768])\n",
      "- decoder.decoder.layers.1.norm3.weight: torch.Size([768])\n",
      "- decoder.decoder.layers.1.norm3.bias: torch.Size([768])\n",
      "- decoder.decoder.layers.2.self_attn.in_proj_weight: torch.Size([2304, 768])\n",
      "- decoder.decoder.layers.2.self_attn.in_proj_bias: torch.Size([2304])\n",
      "- decoder.decoder.layers.2.self_attn.out_proj.weight: torch.Size([768, 768])\n",
      "- decoder.decoder.layers.2.self_attn.out_proj.bias: torch.Size([768])\n",
      "- decoder.decoder.layers.2.multihead_attn.in_proj_weight: torch.Size([2304, 768])\n",
      "- decoder.decoder.layers.2.multihead_attn.in_proj_bias: torch.Size([2304])\n",
      "- decoder.decoder.layers.2.multihead_attn.out_proj.weight: torch.Size([768, 768])\n",
      "- decoder.decoder.layers.2.multihead_attn.out_proj.bias: torch.Size([768])\n",
      "- decoder.decoder.layers.2.linear1.weight: torch.Size([1536, 768])\n",
      "- decoder.decoder.layers.2.linear1.bias: torch.Size([1536])\n",
      "- decoder.decoder.layers.2.linear2.weight: torch.Size([768, 1536])\n",
      "- decoder.decoder.layers.2.linear2.bias: torch.Size([768])\n",
      "- decoder.decoder.layers.2.norm1.weight: torch.Size([768])\n",
      "- decoder.decoder.layers.2.norm1.bias: torch.Size([768])\n",
      "- decoder.decoder.layers.2.norm2.weight: torch.Size([768])\n",
      "- decoder.decoder.layers.2.norm2.bias: torch.Size([768])\n",
      "- decoder.decoder.layers.2.norm3.weight: torch.Size([768])\n",
      "- decoder.decoder.layers.2.norm3.bias: torch.Size([768])\n",
      "- decoder.embedding.weight: torch.Size([50000, 768])\n",
      "- decoder.output_layer.weight: torch.Size([50000, 768])\n",
      "- decoder.output_layer.bias: torch.Size([50000])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nParameter Shapes:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"- {name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4c1baab-ba74-4351-ad40-73e789233402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Configuration:\n",
      "- d_model: N/A\n",
      "- vocab_size: 50000\n",
      "- max_length: 512\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel Configuration:\")\n",
    "print(f\"- d_model: {model.d_model if hasattr(model, 'd_model') else 'N/A'}\")\n",
    "print(f\"- vocab_size: {model.decoder.vocab_size if hasattr(model, 'decoder') else 'N/A'}\")\n",
    "print(f\"- max_length: {model.decoder.max_length if hasattr(model, 'decoder') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7fe1a1c-e84e-4c4c-a0dd-584d27020773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generator Architecture:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SmartContractVulnerabilityGAN' object has no attribute 'CodeDecoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[33m'\u001b[39m\u001b[33mgenerator\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mGenerator Architecture:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCodeDecoder\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1688\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1687\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'SmartContractVulnerabilityGAN' object has no attribute 'CodeDecoder'"
     ]
    }
   ],
   "source": [
    "if hasattr(model, 'generator'):\n",
    "    print(\"\\nGenerator Architecture:\")\n",
    "    print(model.CodeDecoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeeee1b-7d47-43c7-b359-156adc04026c",
   "metadata": {},
   "source": [
    "### This is a GAN (Generative Adversarial Network) combined with a Transformer architecture for smart contract vulnerability detection.\n",
    "\n",
    "#### Here's the technical breakdown:\n",
    "#### 1. Architecture Components:\n",
    "-Transformer Encoder: Processes smart contract code using self-attention\n",
    "-Generator: Creates synthetic vulnerable code patterns\n",
    "-Discriminator: Distinguishes between real and synthetic vulnerabilities\n",
    "\n",
    "#### 2. Input Processing:\n",
    "-Takes smart contract code and its AST (Abstract Syntax Tree) paths\n",
    "-Uses CodeBERT to generate embeddings (768-dimensional vectors)\n",
    "-Processes both contract code and path information\n",
    "\n",
    "#### 3. Training Process:\n",
    "3.1. Generator Training:\n",
    "-Takes random noise and contract embeddings\n",
    "-Generates synthetic vulnerable code patterns\n",
    "-Tries to fool the discriminator\n",
    "\n",
    "3.2. Discriminator Training:\n",
    "-Takes real contract embeddings and generator outputs\n",
    "-Learns to distinguish real from synthetic vulnerabilities\n",
    "-Uses binary classification (real/fake)\n",
    "\n",
    "#### 4. Output:\n",
    "-Vulnerability scores for input contracts\n",
    "-Synthetic vulnerable code patterns for training\n",
    "-Binary classification of real vs. synthetic vulnerabilities\n",
    "\n",
    "#### The model essentially learns to:\n",
    "-Understand code patterns through the transformer\n",
    "-Generate realistic vulnerable code examples\n",
    "-Detect vulnerabilities in real contracts\n",
    "-Improve detection through adversarial training\n",
    "\n",
    "#### This approach combines the strengths of:\n",
    "Transformers for code understanding\n",
    "GANs for synthetic data generation\n",
    "Binary classification for vulnerability detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7bafd2-5e74-4e56-ad5f-2de3d7c88431",
   "metadata": {},
   "source": [
    "# 3. Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9a39804-39cc-434c-9387-0aaffb46e1e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SmartContractTrainer' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# For a single contract\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m results = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m(validation_dataset[\u001b[32m0\u001b[39m])  \u001b[38;5;66;03m# Pass a single contract's data\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVulnerability Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[33m'\u001b[39m\u001b[33mvulnerability_score\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSynthetic Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[33m'\u001b[39m\u001b[33msynthetic_score\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'SmartContractTrainer' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# For a single contract\n",
    "results = trainer.predict(validation_dataset[0])  # Pass a single contract's data\n",
    "\n",
    "print(f\"Vulnerability Score: {results['vulnerability_score']:.4f}\")\n",
    "print(f\"Synthetic Score: {results['synthetic_score']:.4f}\")\n",
    "print(f\"Is Vulnerable: {results['is_vulnerable']}\")\n",
    "print(f\"Is Synthetic: {results['is_synthetic']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b71c6de-dd38-4a48-9d16-dc9fa7b1966e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0523c01a-e501-427d-8e76-23a25e6f5210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import SmartContractTransformer\n",
    "from train import Discriminator\n",
    "\n",
    "def load_trained_model(checkpoint_path, device='cuda:1'):\n",
    "    \"\"\"\n",
    "    Load the trained model and discriminator from checkpoint\n",
    "    \"\"\"\n",
    "    # Initialize model and discriminator\n",
    "    model = SmartContractTransformer()\n",
    "    discriminator = Discriminator()\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    # Load state dicts\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
    "    \n",
    "    # Move to device\n",
    "    model = model.to(device)\n",
    "    discriminator = discriminator.to(device)\n",
    "    \n",
    "    # Set to eval mode\n",
    "    model.eval()\n",
    "    discriminator.eval()\n",
    "    \n",
    "    return model, discriminator\n",
    "\n",
    "def analyze_contract(contract_data, model, discriminator, tokenizer=None, device='cuda:1'):\n",
    "    \"\"\"\n",
    "    Analyze a smart contract for vulnerabilities and generate synthetic version\n",
    "    \"\"\"\n",
    "    # Move input data to device\n",
    "    input_ids = contract_data['input_ids'].unsqueeze(0).to(device)\n",
    "    attention_mask = contract_data['attention_mask'].unsqueeze(0).to(device)\n",
    "    path_input_ids = contract_data['path_input_ids'].unsqueeze(0).to(device)\n",
    "    path_attention_mask = contract_data['path_attention_mask'].unsqueeze(0).to(device)\n",
    "    \n",
    "    # Decode original contract if tokenizer is provided\n",
    "    original_text = None\n",
    "    if tokenizer is not None:\n",
    "        original_text = tokenizer.decode(input_ids[0].cpu().tolist())\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get vulnerability score\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            path_input_ids=path_input_ids,\n",
    "            path_attention_mask=path_attention_mask,\n",
    "            target_ids=None\n",
    "        )\n",
    "        \n",
    "        # Get discriminator predictions\n",
    "        vuln_pred, synth_pred = discriminator(outputs['encoder_output'])\n",
    "        vulnerability_score = torch.sigmoid(vuln_pred).item()\n",
    "        synthetic_score = torch.sigmoid(synth_pred).item()\n",
    "        \n",
    "        result = {\n",
    "            'vulnerability_score': vulnerability_score,\n",
    "            'synthetic_score': synthetic_score,\n",
    "            'is_vulnerable': vulnerability_score > 0.5,\n",
    "            'is_synthetic': synthetic_score > 0.5,\n",
    "            'original_contract': {\n",
    "                'text': original_text,\n",
    "                'input_ids': input_ids[0].cpu().tolist()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Generate synthetic contract\n",
    "        synthetic_outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            path_input_ids=path_input_ids,\n",
    "            path_attention_mask=path_attention_mask,\n",
    "            target_ids=None\n",
    "        )\n",
    "        \n",
    "        # Get the generated sequence\n",
    "        generated_sequence = synthetic_outputs['generated_sequence']\n",
    "        \n",
    "        # Get discriminator predictions for synthetic contract\n",
    "        synth_vuln_pred, synth_synth_pred = discriminator(synthetic_outputs['encoder_output'])\n",
    "        synth_vulnerability_score = torch.sigmoid(synth_vuln_pred).item()\n",
    "        synth_synthetic_score = torch.sigmoid(synth_synth_pred).item()\n",
    "        \n",
    "        result['synthetic_contract'] = {\n",
    "            'sequence': generated_sequence[0].cpu().tolist(),\n",
    "            'vulnerability_score': synth_vulnerability_score,\n",
    "            'synthetic_score': synth_synthetic_score,\n",
    "            'is_vulnerable': synth_vulnerability_score > 0.5,\n",
    "            'is_synthetic': synth_synthetic_score > 0.5\n",
    "        }\n",
    "        \n",
    "        # If tokenizer is provided, decode the synthetic contract\n",
    "        if tokenizer is not None:\n",
    "            synthetic_tokens = result['synthetic_contract']['sequence']\n",
    "            result['synthetic_contract']['text'] = tokenizer.decode(synthetic_tokens)\n",
    "        \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d10b5e58-9742-416c-9cd8-38089f60f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "checkpoint_path = 'checkpoints_v1/latest_model.pt'  # or 'best_model_epoch_X.pt'\n",
    "model_loaded, discriminator = load_trained_model(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "280ba2f6-c926-4fd4-bcd9-dd6720bb44ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_data = val_dataset[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "530e0dbd-3fe7-4191-922e-d9fd9f1cf971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contract Analysis Results:\n",
      "--------------------------------------------------\n",
      "Vulnerability Score: 0.0151\n",
      "Synthetic Score: 0.7673\n",
      "Vulnerability Status: Safe\n",
      "Synthetic Status: Synthetic\n",
      "\n",
      "Original Contract:\n",
      "--------------------------------------------------\n",
      "<s>/**\n",
      " *Submitted for verification at Etherscan.io on 2020-11-22\n",
      "*/\n",
      "\n",
      "// SPDX-License-Identifier: MIT + WTFPL\n",
      "// File: contracts/uniswapv2/interfaces/IUniswapV2Factory.sol\n",
      "\n",
      "pragma solidity >=0.5.0;\n",
      "\n",
      "interface IUniswapV2Factory {\n",
      "    event PairCreated(address indexed token0, address indexed token1, address pair, uint);\n",
      "\n",
      "    function feeTo() external view returns (address);\n",
      "    function feeToSetter() external view returns (address);\n",
      "    function migrator() external view returns (address);\n",
      "\n",
      "    function getPair(address tokenA, address tokenB) external view returns (address pair);\n",
      "    function allPairs(uint) external view returns (address pair);\n",
      "    function allPairsLength() external view returns (uint);\n",
      "\n",
      "    function createPair(address tokenA, address tokenB) external</s>\n",
      "\n",
      "Synthetic Contract Analysis:\n",
      "--------------------------------------------------\n",
      "Vulnerability Score: 0.0151\n",
      "Synthetic Score: 0.7673\n",
      "Vulnerability Status: Safe\n",
      "Synthetic Status: Synthetic\n",
      "\n",
      "Generated Synthetic Contract:\n",
      "--------------------------------------------------\n",
      "<s>/**\n",
      " *Submitted for verification at Etherscan.io on 2020-09-12\n",
      "*/\n",
      "\n",
      "pragma solidity 0.6.6;\n",
      "\n",
      "\n",
      "/**\n",
      " * @dev Wrappers over Solidity's arithmetic operations with added overflow\n",
      " * checks.\n",
      " *\n",
      " * Arithmetic operations in Solidity wrap on overflow. This can easily result\n",
      " * in bugs, because programmers usually assume that an overflow raises an\n",
      " * error, which is the standard behavior in high level programming languages.\n",
      " * `SafeMath` restores this intuition by reverting the transaction when an\n",
      " * operation overflows.\n",
      " *\n",
      " * Using this library instead of the unchecked operations eliminates an entire\n",
      " * class of bugs, so it's recommended to use it always.\n",
      " */\n",
      "library SafeMath {\n",
      "  /**\n",
      "    * @dev Returns the addition of two unsigned integers, reverting on\n",
      "    * overflow.\n",
      "    *\n",
      "    * Counterpart to Solidity's `+` operator.\n",
      "    *\n",
      "    * Requirements:\n",
      "    * - Addition cannot overflow.\n",
      "    */\n",
      "  function add(uint256 a, uint256 b</s>\n"
     ]
    }
   ],
   "source": [
    "# Analyze the contract\n",
    "results = analyze_contract(contract_data, model_loaded, discriminator, tokenizer)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nContract Analysis Results:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Vulnerability Score: {results['vulnerability_score']:.4f}\")\n",
    "print(f\"Synthetic Score: {results['synthetic_score']:.4f}\")\n",
    "print(f\"Vulnerability Status: {'Vulnerable' if results['is_vulnerable'] else 'Safe'}\")\n",
    "print(f\"Synthetic Status: {'Synthetic' if results['is_synthetic'] else 'Real'}\")\n",
    "\n",
    "# Print original contract\n",
    "if results['original_contract']['text']:\n",
    "    print(\"\\nOriginal Contract:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(results['original_contract']['text'])\n",
    "    \n",
    "\n",
    "print(\"\\nSynthetic Contract Analysis:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Vulnerability Score: {results['synthetic_contract']['vulnerability_score']:.4f}\")\n",
    "print(f\"Synthetic Score: {results['synthetic_contract']['synthetic_score']:.4f}\")\n",
    "print(f\"Vulnerability Status: {'Vulnerable' if results['synthetic_contract']['is_vulnerable'] else 'Safe'}\")\n",
    "print(f\"Synthetic Status: {'Synthetic' if results['synthetic_contract']['is_synthetic'] else 'Real'}\")\n",
    "\n",
    "if 'text' in results['synthetic_contract']:\n",
    "    print(\"\\nGenerated Synthetic Contract:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(results['synthetic_contract']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdadd5d6-6f7d-4f52-8f69-b912bc30d5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aee0c4-4061-4050-aed3-144a0c775e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385b59e7-1f96-49ad-8d2a-0485b2ff953f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e94209-f5b9-4eea-bb24-2482d771a1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
